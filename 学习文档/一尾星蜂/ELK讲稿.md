#### 基础简介

**为什么要用ES？**

世界被数据淹没。但是，大部分数据库在从大量数据中提取可用知识时较为低效，不能满足需求，比如：在一般数据库中，我们只能通过时间戳或精确值进行过滤，但是高效地进行全文检索、同义词处理、通过相关性给查询结果评分，从原始数据中生成分析与聚合数据都比较困难，这就是ES脱颖而出的地方：不经过大型批处理任务就近实时（Near Realtime：简写NRT）的做到这些操作！

所以 ES 鼓励用户去探索与利用数据，不因为查询数据太困难，就让它们烂在数据仓库里。

ES有3个主要的使用场景：

**ES使用场景**

1. 存储

   ES 天然支持分布式，具备存储海量数据的能力，搜索和数据分析其实都是建立在 ES 存储的海量的数据之上。

2. 搜索

   ES 中使用了倒排索引，每个字段都能被索引且可用于搜索，它提供了丰富的搜索api，在海量数据下近实时实现近秒级的响应。我们常用的技术网站:

   - Stack Overflow（国外的程序异常讨论论坛），IT问题，程序的报错，提交上去，有人会跟你讨论和回答，全文检索，搜索相关问题和答案，程序报错了，就会将报错信息粘贴到里面去，搜索有没有对应的答案；
   - GitHub（开源代码管理），搜索上千亿行代码；
   - 日志数据分析，logstash采集日志，ElasticSearch进行复杂的数据分析（ELK技术，elasticsearch+logstash+kibana）；

3. 数据分析
   ES中也提供了大量数据分析的api和丰富的聚合能力，支持在海量数据的基础上进行数据的分析和处理。比如说：使用爬虫爬取不同电商平台的某个商品的数据，通过 ES 进行各个平台的历史价格、购买力等等的数据分析。

**定义**

ES是一个开源的搜索引擎，建立在一个全文搜索引擎库 [Apache Lucene™](https://lucene.apache.org/core/) 基础之上。 Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库。

ES 使用 Java 编写，内部使用 Lucene 做索引与搜索，它的目的是使全文检索变得简单，所以通过封装隐藏了 Lucene 的复杂性，取而代之的是一套简单一致的 RESTful API。

当然ES不仅仅只是一个全文搜索引擎。 它可以被下面这样准确的形容：

- 一个分布式的实时文档存储，每个字段可以被索引与搜索
- 一个分布式实时分析搜索引擎
- 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据

ES 将所有的功能打包成单独的服务，这样我们可以通过程序与它提供的简单的 RESTful API 进行通信，可以使用自己喜欢的编程语言充当 web 客户端。

**起源**

回忆时光，这是一个关于ES起源的传奇故事，描述了ES的诞生过程，有兴趣的可以在文档中看一下。

**流行度**

在开源搜索引擎中，ES的流行程度是傲视群雄的，这是一张各个搜索引擎流行度评分的列表，可以看到ES几乎稳坐第一名宝座。

**ES核心概念**

1）Cluster：集群

ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。

2）Node：节点

形成集群的每个服务器就是节点。ES集群中有多个节点，其中有一个为主节点，这个主节点通过选举产生。当然，主从节点是对于集群内部来说的；es 的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es 集群，在逻辑上是个整体，与任何一个节点的通信就等价于和整个es 集群通信。

3）Shard：分片

当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片，每个分片放到不同的服务节点上。

当查询的数据分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。

通过分片机制，ES实现了分布式搜索。

4）Replia：副本

为提高查询吞吐量或实现高可用性，ES提供了分片副本机制。副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一会被选择为优先进行写入的操作，这种特殊的分片称为主分片。

当主分片丢失时，比如该分片所在的数据不可用时，集群会将其中一个副本提升为新的主分片。

ES 禁止同一个分片的主分片和副本分片在同一个节点上，为什么呢？因为它要在主分片节点请求失败的情况下提供高可用性；所以，副本分片永远不会分配到与主分片相同的节点上，所以如果ES部署的是单节点，是不能有副本的。

**简单类比**

- 关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）

- 一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type）

- 一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。

  一个索引是一个文档的集合。每个索引有唯一的名字（必须全部是小写字母的），通过这个名字来操作它。一个集群中可以有任意多个索引。
  
  Type 类型：指在一个索引中，可以索引不同类型的文档，如用户数据、博客数据。从6.0.0 版本起已废弃，一个索引中只存放一类数据。
  
  ES概念里的索引，是名词，一个索引就是一个拥有相似特征的文档的集合。比如说，可以有一个客户数据的索引，另外有一个产品目录的索引。索引也可以用作动词，指索引数据、索引文档，或者对数据进行索引、对文档进行索引等。
  
  文档：是被索引的一条数据，索引的基本信息单元，以JSON格式来表示。比如，可以查询某一个客户的文档、某一个产品的一个文档等。这里的文档就是一条JSON格式的记录，而JSON是一个到处存在的数据交互格式，所以很容易解析和传播。在一个index/type里面，你可以存储任意多的文档。（注意，一个文档物理上存在于一个索引之中，但文档必须被索引/赋予一个索引的type）。

- 在一个关系型数据库里面，schema（模式）定义了表、每个表的字段，还有表和字段之间的关系。与之对应的，在 ES 中：Mapping 定义索引下的 Type 的字段处理规则，即索引如何建立、索引类型、是否保存原始索引 JSON 文档、是否压缩原始 JSON 文档、是否需要分词处理、如何进行分词处理等。


**逻辑架构**

这是一张ES的逻辑架构图，可以帮助我们了解ES系统的组成部分，我们从底层往上层看：

1. Gateway是ES用来存储索引的文件系统，支持多种类型。

2. Gateway的上层是一个分布式的Lucene框架。Lucene被称为目前市场上开源的最好全文检索引擎工具。

3. Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块等

4. ES模块之上是 Discovery、Scripting和第三方插件。

   Discovery是ES的节点发现模块，不同机器上的ES节点要组成集群需要进行消息通信，集群内部需要选举master节点，这些工作都是由Discovery模块完成。支持多种发现机制，如 Zen 、EC2、gce、Azure。

   Scripting用来支持在查询语句中插入javascript、python等脚本语言，scripting模块负责解析这些脚本。

5. 再上层是ES的传输模块和JMX。传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX 是 java 的管理框架，用来管理 ES 应用。

6. 最上层是 ES 提供给用户的接口，可以通过 RESTful 接口和 ES 集群进行交互。



---

#### 简单示例

了解了ES的基本概念后，我们来看一个简单的示例：假设世界上有一个叫武林的世界，这里就把武林当做是一个索引Index；武林中有一群能飞檐走壁，高来高去的人，称为侠客，这里的侠客是武林中的一类人，所以，就是索引下的一个类型Type；一个文档就代表一个具体的侠客。

存储数据到 ES 的行为也叫做索引，这时的索引是个动词。我们说过，索引在ES里面既有动词的意思，也有名词的意思。一个 ES 集群可以包含多个索引，这时的索引就是个名词，每个索引可以包含多个类型，这些不同的类型里又存储着多个文档，每个文档又有多个属性 。

我们可以先索引一个侠客的文档，这个文档包含该侠客的所有属性。我们示例中的文档都是 `xiake` 类型 。位于索引 `wulin` 内。

我们可以看到在路由中包含了3部分的信息：索引名称、类型名称、文档的ID。现在我们已经在 ES 中存储了一些数据， 接下来就能尝试一下查询了。

我们首先检索单个侠客的数据，这在 ES 中很简单，执行 一个 HTTP `GET` 请求并指定文档的地址就行。我们看到，返回结果是 JSON 格式的，不仅告知匹配了哪些文档，还包含了整个文档本身。

接下来，我们试一下搜索名字中包含“张“的侠客。这个一般涉及到一个查询字符串（query-string），我们通过一个URL参数来传递查询信息给搜索接口。

Query-string 搜索可以非常方便地进行临时搜索 ，但它有自身的局限性。ES 提供了一种丰富灵活的查询语言（查询表达式）来构建更加复杂和健壮的查询。

这就是领域特定语言（DSL）：使用 JSON 在请求体里面构造一个请求。我们可以像这样重写之前的检索所有名字中包含 “张” 的侠客。可以看到搜索结果与刚才轻量级搜索一致！

接下下我们试着搜索下描述中包含“兄弟”的文档，通过结果可以看到：ES 默认按照相关性得分排序，即每个文档跟查询的匹配程度。第一个最高得分的结果很明显：张三 的 `about` 属性清楚地写着 “兄弟” 。

但为什么 张三丰 也作为结果返回了呢？原因是他的 `about` 属性里提到了 “弟” 。因为只有 “弟” 而没有 “兄” ，所以他的相关性得分低于张三的。

这个案例，阐明了 ES 是如何在全文属性上搜索并返回相关性最强的结果。ES 中，**相关性**概念非常重要，也是完全区别于传统关系型数据库的一个概念，在传统数据库中的一条记录要么匹配要么不匹配，而ES中就多了这个相关性的维度。

找出一个属性中的独立单词是没有问题的，但有时候想要精确匹配一系列单词或者短语，比如，刚才查询的“兄弟”，我们不希望 ES 既查“兄”又查“弟”，我们只想检索“兄弟”，也就是短语搜索，为此，我们可以用另一个关键字 `match_phrase` 进行检索 ，这样，返回结果中就没有“张三丰”的文档了。



---

#### 分片原理

我们现在知道 ES 是分布式的，一个运行中的 ES 实例称为一个节点，而集群由一个或者多个拥有相同"集群名称"的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。

当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。

作为用户，我们可以将请求发送到 集群中的任何节点。每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。

我们可以用 ES 提供的 API 查看集群信息，可以看到 ES 的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是集群健康状态，它用 `status` 字段表示。

这个字段指示当前集群在总体上是否工作正常。有三种颜色含义：

- **`green`**

  所有的主分片和副本分片都正常运行。

- **`yellow`**

  所有的主分片都正常运行，但不是所有的副本分片都正常运行。

- **`red`**

  有主分片没能正常运行。

我们往 ES 添加数据时需要用到索引 。索引实际上是指向一个或者多个物理分片的逻辑命名空间。

一个分片是一个底层的工作单元，它仅保存了全部数据中的一部分。我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。

ES 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。当集群规模扩大或者缩小时，ES 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。

一个分片可以是主分片或者副本分片。索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。

一个副本分片只是一个主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。

在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。

我们在包含一个空节点的集群内创建名为 `projects` 的索引。 (索引在默认情况下会被分配5个主分片）为了演示，我们给它分配3个主分片和一份副本（一份副本的意思是：每个主分片都拥有一个副本分片）。

集群的健康状况为 `yellow` 则表示全部 主分片都正常运行（集群可以正常服务所有请求），但是副本分片没有全部处在正常状态。实际上，所有3个副本分片都是 `unassigned` —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。

所以当集群中只有一个节点在运行时，会有单点故障问题。我们需再启动一个节点加入集群防止数据丢失。

当第二个节点加入到集群后，3个副本分片将会分配到新节点上——每个主分片对应一个副本分片。 这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。

所有（新近）被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档。

集群健康状态现在是`green`，这表示所有6个分片（包括3个主分片和3个副本分片）都在正常运行。此时的集群不仅正常运行，而且高可用。

我们的也可以为正在增长中的应用程序按需扩容。当启动第三个节点并加入集群时，`Node 1` 和 `Node 2` 上各有一个分片被迁移到了新的 `Node 3` 节点，现在每个节点上都拥有2个分片。这表示每个节点的硬件资源（CPU, RAM, I/O）将被更少的分片所共享，每个分片的性能将会得到提升。

分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。

在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2，那么现在`projects` 索引拥有9个分片：3个主分片和6个副本分片。这表示我们可以将集群扩容到9个节点，每个节点上一个分片。相比原来3个节点时，集群搜索性能可以提升3倍。但是更多的副本分片数也提高了数据冗余量，占用了更多硬件资源。按照现在3个节点9个分片的配置，我们可以在失去任意2个节点的情况下不丢失任何数据。

现在我们模拟一个节点故障，关闭一个主节点。而集群必须拥有一个主节点来保证正常工作，所以集群情首先会选举一个新的主节点：Node 2 。

在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。

幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为 yellow 。 这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。

为什么我们集群状态是 yellow 而不是 green 呢？ 虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应2份副本分片，而此时只存在一份副本分片。 所以集群不能为 green 的状态。

如果我们重新启动 Node 1 ，集群可以将缺失的副本分片再次进行分配。如果 Node 1 依然拥有着之前的分片，ES会去重用它们，同时仅从主分片复制发生了修改的数据文件，这时候集群的状态也恢复为"green"。



---

#### 读写流程

一个文档不仅仅包含业务数据 ，也包含元数据 —— 元数据就是有关文档本身的一些信息。这是三个元数据元素：

- **`_index`**

  索引，表示文档在哪存放

- **`_type`**

  文档表示的对象类别

- **`_id`**

  文档唯一标识

接下来我们看一下索引文档的过程：

当索引一个文档的时候，文档会被存储到一个主分片中。ES 如何知道一个文档应该存放到哪个主分片中呢？这个过程是根据一个哈希公式决定的：

```sh
shard = hash(routing) % number_of_primary_shards
```

> `routing` 是一个可变值，默认是文档的 `_id` ，也可以设置成一个自定义的值。 `routing` 通过 hash 函数生成一个数字，然后这个数字再除以 `number_of_primary_shards` （主分片的数量）后得到 **余数** 。这个分布在 `0` 到 `number_of_primary_shards-1` 之间的余数，就是我们所寻求的文档所在分片的位置。

这就解释了为什么我们要在创建索引的时候就确定好主分片的数量，并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也就找不到了。

我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。

一般我们将客户端直接请求的节点称为**协调节点(coordinating node)** 。新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片，所以协调节点首先会将请求转发到主分片所在节点。主分片保存数据并将数据发送给副本，一旦所有的副本分片都报告成功，主分片节点将向协调节点报告成功，协调节点向客户端报告成功。在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，所以变更是安全的，这就是整个写入的过程。

下面这个是检索文档的步骤顺序，其中重要的一个环节是：在处理读取请求时，协调结点都会通过轮询所有的副本分片来达到负载均衡的效果，提高检索性能。

接下来看一下更新文档的步骤：

1. 客户端向协调节点发送更新请求。
2. 协调节点将请求转发到主分片所在的节点。
3. 主分片检索出待更新的文档，修改（ `_source` 字段中的 JSON），并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改，它会进行重试，超过指定（`retry_on_conflict`）次数后放弃。
4. 如果主分片成功更新了文档，它会将新版本的文档并行转发到所有副本分片上，各个副本分片重新索引文档。 一旦所有副本分片都返回成功，主分片向协调节点也返回成功，协调节点也向客户端返回成功。

这就是整个更新文档的过程。



---

#### 基本搜索

ES 真正强大之处在于可以从无规律的数据中找出有意义的信息（从“大数据”到“大信息”）。它在存储文档时，为了方便搜索，会为文档添加索引，这也是为什么要使用结构化的 JSON 文档。文档中的每个字段都会被索引并且可以被查询。

搜索 API 的最基础的形式是没有指定任何查询的空搜索，它简单地返回集群中所有索引下的所有文档，我们先看一下它返回的数据结构：

**hits**

返回结果中最重要的部分是 `hits` ，它包含一个 `total` 字段来表示匹配到的文档总数，并且一个 `hits` 数组包含所查询结果的前十个文档。

在 `hits` 数组中每个结果包含文档的 `_index` 、 `_type` 、 `_id` ，加上 `_source` 字段。这意味着我们可以直接从返回的搜索结果中使用整个文档。

每个结果还有一个 `_score` ，它衡量了文档与查询的匹配程度。默认情况下，首先返回最相关的文档结果，就是说，返回的文档是按照 `_score` 降序排列的。在这个例子中，我们没有指定任何查询，故所有的文档具有相同的相关性，因此对所有的结果而言 `1` 是中性的 `_score` 。

`max_score` 就是查询到的文档的最大`_score` 值。

**took**

`took` 值告诉我们执行整个搜索请求耗费了多少毫秒。

**shards**

`_shards` 部分告诉我们在查询中参与分片的总数，以及这些分片成功了多少个失败了多少个。

**timeout**

`timed_out` 值告诉我们查询是否超时。

常见情况下，我们想在一个或多个特殊的索引中进行搜索。我们可以通过在URL中指定特殊的索引和类型达到这种效果，这是一些基本的查询API。

我们看一个查询，从查询结果看到，只要字段中包含查询值，ES就能检索出来。那么 ES 不指定字段，是如何在多个不同的字段中查找到结果的呢？

当索引一个文档的时候，ES 取出所有字段的值拼接成一个大的字符串，作为 `_all` 字段进行索引。所以，当索引文档时，就好似增加了一个名叫 `_all` 的额外字段，这个字段是所有字段值拼接而成。除非设置特定字段，否则查询字符串就使用 `_all` 字段进行搜索。

> 当测试索引里面的数据时，我们发现一些奇怪的事情：在我们的索引中有12条推文，其中只有一条包含日期 `2014-09-15` ，但是看一看下面查询命中的总数（total）：
>
> 为什么在 `_all` 字段查询日期返回所有推文，而在 `date` 字段只查询年份却没有返回结果？为什么我们在 `_all` 字段和 `date` 字段的查询结果有差别？
>
> 这是因为数据在 `_all` 字段与 `date` 字段的索引方式不同。所以，通过请求 `gb` 索引中 `tweet` 类型的映射，让我们看一看 ES 是如何解释我们文档结构的：
>
> 什么是**映射（Mapping）**？就是描述数据在每个字段内如何存储。
>
> 查询结果告诉我们 `date` 字段被认为是 `date` 类型的。由于 `_all` 是默认字段，所以没有提及它，但是我们知道 `_all` 字段是拼接的字符串，所以必然是 `string` 类型的。`date` 字段和 `string` 字段索引方式不同，因此搜索结果也不一样。

ES 中的数据可以概括的分为两类：精确值和全文。

精确值，例如日期或者用户 ID，字符串也可以表示精确值，例如用户名或邮箱地址。对于精确值来讲，`Foo` 和 `foo` 是不同的，年份`2021` 和 日期`2021-06-18` 也是不同的。

另一方面，全文是指文本数据（通常以人类容易识别的语言书写），例如一个博客的内容或一封邮件的内容。

精确值很容易查询：要么匹配，要么不匹配。这种查询很容易用 SQL 表示。

查询全文数据时，一般我们问的不只是“匹配查询”，而是“匹配查询的程度有多大？”换句话说，该文档与给定查询的相关性如何？

> 比如说
>
> - 搜索 `UK` ，会返回包含 `United Kindom` 的文档。
> - 搜索 `jump` ，会匹配 `jumped` ， `jumps` ， `jumping` ，甚至是 `leap` 。

所以为了进行检索，ES 首先分析文档。什么是分析？就是全文如何处理使之可以被搜索。分析之后根据结果创建**倒排索引** 。

**倒排索引**适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。

例如，假设我们有两个文档，每个文档的 `content` 域包含如下内容，

为了创建倒排索引，ES 首先将每个文档的 `content` 域拆分成单独的 词（称为 `词条` 或 `tokens` ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示：

现在，如果我们想搜索 `quick brown` ，我们只需要查找包含每个词条的文档。

> 在这个倒排索引里：
>
> - `Quick` 和 `quick` 以独立的词条出现，然而用户可能认为它们是相同的词。
> - `fox` 和 `foxes` 非常相似, 就像 `dog` 和 `dogs` ；他们有相同的词根。
> - `jumped` 和 `leap`, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。

因为只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。分词和标准化的过程称为**分析**。 

分析包含下面的过程：

- 首先，将一块文本分成适合于倒排索引的独立的词条，
- 之后，将这些词条统一化为标准格式以提高它们的“可搜索性”

分析器执行这些工作，实际上是将三个功能封装到了一个包里：

- **字符过滤器**

  首先，字符串按顺序通过每个字符过滤器，它们的任务就是在分词前整理字符串，比如用来去掉HTML标签，转换特殊符号（将 `&` 转化成 `and`）等。

- **分词器**

  其次，字符串被分词器分为单个的词条。比如：一个简单的分词器在遇到空格和标点的时候，就可能会将文本拆分成词条。

- **词条（Token）过滤器**

  最后，词条按顺序通过每个 token 过滤器。这个过程可能会改变词条，例如，统一大小写，删除无用词条（例如， 像 `a`， `and`， `the` 等）等（增加词条，例如，像`jump` 和 `leap` 这种同义词）。

ES 中提供了开箱即用的字符过滤器、分词器和 token 过滤器。

**什么时候使用分析器？**

当我们索引一个文档，它的全文字段就被分析成词条以用来创建倒排索引。当我们在全文字段搜索的时候，需要将查询字符串通过相同的分析过程，以保证我们搜索的词条格式与索引中的词条格式一致。

> 全文查询，理解每个字段是如何定义的，因此它们可以做正确的事：
>
> - 当你查询一个全文字段时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。
> - 当你查询一个精确值字段时，不会分析查询字符串，而是搜索指定的精确值。
>
> 现在我们可以理解在开始的查询中为什么返回那样的结果：
>
> - `date` 字段包含一个精确值：单独的词条 `2014-09-15`。
> - `_all` 字段是一个全文字段，所以分词进程将日期转化为三个词条： `2014`， `09`， 和 `15`。

为了能够将时间字段视为时间，数字字段视为数字，字符串字段视为全文或精确值字符串， ES 需要知道每个字段中数据的类型。这个信息包含在映射中。

ES 支持这些简单字段类型，当索引一个包含新字段的文档（之前未曾出现）时ES 会使用动态映射，通过 JSON 中的基本数据类型，尝试猜测字段类型。

通过 `/_mapping` ，我们可以查看映射信息。

`string` 字段，有两种映射方式：

- keyword：精确匹配，不分析
- text：全文匹配，分析

在各个类型中一般都有`index` 属性，它是个bool值，默认是 true ，代表需要索引，这样它才能被检索到。

对于 text 全文索引，用 `analyzer` 属性指定在搜索和索引时使用的分析器。

我们可以更新一个映射来添加一个新字段，但不能改一个字段的映射。因为如果一个字段的映射已经存在，那么该字段的数据可能已经被索引。如果你修改这个字段的映射，索引的数据很可能出错，不能被正常的搜索。

ES 中有两种形式的搜索API：

- 一种是 “轻量的” 查询字符串版本，要求在查询字符串中传递所有的参数
- 另一种是更完整的请求体版本，要求使用 JSON 格式和更丰富的查询表达式作为搜索语言。

一个带请求体的查询允许我们使用**查询领域特定语言（query domain-specific language，Query DSL ）**来写查询语句。

DSL中区分了查询与过滤：

- 过滤：简单的检查包含或者排除，不计算相关性评分。
- 查询：不仅仅要找出匹配的文档，还要计算每个匹配文档的相关性评分。

通常的使用规则是，用查询（query）来进行全文搜索或者任何需要影响相关性得分的搜索。除此以外的都使用过滤（filters)。

ES 自带了很多的查询，经常用到的是这么几个：

- `match_all`：匹配所有文档。在没有指定查询方式时，它是默认的查询

- `match`：无论你在任何字段上进行的是全文搜索还是精确查询，`match` 查询都是可用的标准查询。如果在一个全文字段上使用 `match` 查询，在执行查询前，它会用正确的分析器去分析查询字符串；如果在一个精确值的字段上使用它，例如数字、日期、布尔或者一个 `keyword` 字符串字段，那么它将会精确匹配给定的值。

- `multi_match`：可以在多个字段上执行相同的 `match` 查询

- `range`：找出那些落在指定区间内的数字或者时间。允许的操作符如下：
  - **`gt`**：大于
  - **`gte`**：大于等于
  - **`lt`**：小于
  - **`lte`**：小于等于

- `term`：被用于精确值匹配，对于输入的文本不分析。这些精确值可能是数字、时间、布尔或者那些 `keyword` 的字符串。

- `terms`：和 `term` 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件。类似SQL语句中的in

- `exists`和 `missing` 查询被用于查找那些指定字段中有值 (`exists`) 或无值 (`missing`) 的文档。与SQL中的 `IS_NULL` (`missing`) 和 `NOT IS_NULL` (`exists`) 类似

如果需要在多个字段上查询多种文本，并且根据一系列的标准来过滤。那么为了构建类似的高级查询，就需要一种能够将多查询组合成单一查询的方法。

ES 中可以用 `bool` 来实现这个需求，它将多查询组合在一起，接收这些参数：

- **`must`**：文档 必须匹配这些条件才能被包含进来。
- **`must_not`**：文档必须不匹配这些条件才能被包含进来。
- **`should`**：如果满足这些语句中的任意语句，将增加 `_score` ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。
- **`filter`**：必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。

我们看一个示例：......

通过混合布尔查询，我们可以在查询请求中灵活地编写查询逻辑，实现复杂的查询，但是查询变复杂时，理解起来就有点困难。不过 ES 提供了专门的`validate-query` API 来验证查询是否合法。

我们可以将 `explain` 参数加到查询字符串中，找出查询不合法的原因；对于合法查询，使用 `explain` 参数将返回可读的描述，这对理解 ES 是如何解析 query 是非常有用。

从 `explanation` 中可以看出，匹配 `张三` 的 `match` 查询被重写为两个针对 `name` 字段的 single-term 查询，一个single-term查询对应查询字符串分出来的一个term，也就是一个`张`，一个`三`。

要在ES查询时自定义分页信息怎么办呢？和 MYSQL 使用 `LIMIT` 关键字返回单个 `page` 结果的方法相同，ES 接受 `from` 和 `size` 参数：

- **`size`**

  显示应该返回的结果数量，默认是 `10`

- **`from`**

  显示应该跳过的初始结果数量，默认是 `0`

如果每页展示 5 条结果，可以用下面方式请求得到 1 到 3 页的结果。

一般分页时我们会先指定结果的排序顺序，这在 ES 中是通过"sort"这个关键词实现的。

最后我们看一个分页的示例。


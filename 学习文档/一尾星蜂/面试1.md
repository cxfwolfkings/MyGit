# 面试

- 数据库
  - [MySQL](#MySQL)
- 缓存
  - [Redis](#Redis)
- API网关
  - [1. 为什么需要API网关？](#1. 为什么需要API网关？)
- 设计模式

  - [1. 代理模式](#代理模式)

  - [2. 消费者模式](#2. 消费者模式)
- 前端
  - [1. JS闭包](#1. JS闭包)
- 后端
  - [1. NET多线程](1. NET多线程)
  - [2. 如何实现一个.Net5 IOC框架？](#2. 如何实现一个.Net5 IOC框架？)
  - [3. DotNetty能够实现高性能的I/O机制是如何工作的？](#3. DotNetty能够实现高性能的I/O机制是如何工作的？)
  - [4. Saga分布式事务方案如何通过.Net5实现？](#4. Saga分布式事务方案如何通过.Net5实现？)
  - [5. 如何通过设计模式手写.Net5的Middleware中间件源码？](#5. 如何通过设计模式手写.Net5的Middleware中间件源码？)
- 架构

  - [1. 如何设计一个高并发系统？](#1. 如何设计一个高并发系统？)
  - [2. 如何实现负载均衡Hash一致性算法？](#2. 如何实现负载均衡Hash一致性算法？)
  - [3. 在分布式系统中，服务之间故障转移机制该如何实现？](#3. 在分布式系统中，服务之间故障转移机制该如何实现？)
  - [4. 设计一个通用的缓存框架需要具备哪些条件？](#4. 设计一个通用的缓存框架需要具备哪些条件？)



## MySQL

1. [MySQL日志](#1. MySQL日志)
2. [MySQL锁和事务](#2. MySQL锁和事务)
   - [SQL事务隔离级别](#SQL事务隔离级别)
   - [MySQL中的锁](#MySQL中的锁)
   - [MVCC](#MVCC)
3. [SQL语句执行流程](#3. SQL语句执行流程)
4. [MySQL索引](#4. MySQL索引)



### 1. MySQL日志

参考：

1. https://blog.csdn.net/u013378306/article/details/106743331/
2. https://www.cnblogs.com/f-ck-need-u/p/9001061.html
3. https://www.jianshu.com/p/f72e402399d8

MySQL中有以下日志文件，分别是：

1. 重做日志（redo log）
2. 回滚日志（undo log）
3. 二进制日志（binlog）
4. 错误日志（errorlog）
5. 慢查询日志（slow query log）
6. 一般查询日志（general log）
7. 中继日志（relay log）

其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系，这三种日志，对理解MySQL中的事务操作有着重要的意义。

```ini
# binlog配置
lob_bin = E:\\data\\mysql5.7\\log\\binlog
binlog-format = Row
server-id = 123454
# 错误日志
log-error = E:\\data\\mysql5.7\\log\\error
# 普通日志
general_log = on
general_log_file = E:\\data\\mysql5.7\\log\\general\\general.log
# 慢查询日志
```

#### BinLog

**作用：**

用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。用于数据库的基于时间点的还原。

**内容：**

逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。

在使用mysql binlog解析binlog之后一些都会真相大白。因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。

**什么时候产生：**

事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。

这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

**什么时候释放：**

binlog的默认保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。

```sql
show variables like '%expire_logs_days%';
```

**对应的物理文件：**

配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。对于每个binlog日志文件，通过一个统一的index文件来组织。

```sql
show variables like '%log_bin_basename%';
```

**其他：**

二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同

**作用不同**：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。

**内容不同**：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句。另外，两者产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。

恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。

`BinLog`是记录所有数据库表结构变更（例如create、alter table）以及表数据修改(insert、update、delete)的二进制日志，主从数据库同步用到的都是BinLog文件。BinLog日志文件有三种模式。

**STATEMENT 模式**

> `内容`：binlog 只会记录可能引起数据变更的 sql 语句
>
> `优势`：该模式下，因为没有记录实际的数据，所以日志量和 IO 都消耗很低，性能是最优的
>
> `劣势`：但有些操作并不是确定的，比如 uuid() 函数会随机产生唯一标识，当依赖 binlog 回放时，该操作生成的数据与原数据必然是不同的，此时可能造成无法预料的后果。

**ROW 模式**

> `内容`：在该模式下，binlog 会**记录每次操作的源数据与修改后的目标数据**，StreamSets就要求该模式。
>
> `优势`：可以绝对精准的还原，从而保证了数据的安全与可靠，并且复制和数据恢复过程可以是并发进行的
>
> `劣势`：缺点在于 binlog 体积会非常大，同时，对于修改记录多、字段长度大的操作来说，记录时性能消耗会很严重。阅读的时候也需要特殊指令来进行读取数据。

**MIXED 模式**

> `内容`：是对上述STATEMENT 跟 ROW  两种模式的混合使用。
>
> `细节`：对于绝大部分操作，都使用 STATEMENT 来进行 binlog 的记录，只有以下操作使用 ROW 来实现：表的存储引擎为 NDB，使用了uuid() 等不确定函数，使用了 insert delay 语句，使用了临时表

![x](D:/WorkingDir/Office/Resources/tbms0024.png)

**主从同步流程**：

> 1、主节点必须启用二进制日志，记录任何修改了数据库数据的事件。
>
> 2、从节点开启一个线程（I/O Thread）把自己扮演成 mysql 的客户端，通过 mysql 协议，请求主节点的二进制日志文件中的事件 。
>
> 3、主节点启动一个线程（dump Thread），检查自己二进制日志中的事件，跟对方请求的位置对比，如果不带请求位置参数，则主节点就会从第一个日志文件中的第一个事件一个一个发送给从节点。
>
> 4、从节点接收到主节点发送过来的数据把它放置到中继日志（Relay log）文件中。并记录该次请求到主节点的具体哪一个二进制日志文件内部的哪一个位置（主节点中的二进制文件会有多个）。
>
> 5、从节点启动另外一个线程（sql Thread ），把 Relay log 中的事件读取出来，并在本地再执行一次。

mysql默认的复制方式是`异步`的，并且复制的时候是有`并行复制能力`的。主库把日志发送给从库后不管了，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，**日志就丢失了**。由此产生两个概念。

1. 全同步复制

   > 主库写入binlog后强制同步日志到从库，**所有的从库都执行完成后才返回给客户端**，但是很显然这个方式的话性能会受到严重影响。

2. 半同步复制

   > 半同步复制的逻辑是这样，从库写入日志成功后返回`ACK`确认给主库，主库收到至少一个从库的确认就认为写操作完成。

还可以延伸到由于主从配置不一样、主库大事务、从库压力过大、网络震荡等造成`主备延迟`，如何避免这个问题？主备切换的时候用`可靠性优先原则`还是`可用性优先原则`？如何判断主库Crash了？互为主备情况下如何避免主备循环复制？被删库跑路了如何正确恢复？(⊙o⊙)… 。

#### RedoLog

可以先通过下面demo理解：饭店记账可以把账单写在账本上也可以写在粉板上。有人赊账或者还账的话，一般有两种做法：

1. 直接把账本翻出来，把这次赊的账加上去或者扣除掉。
2. 先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。

生意忙时选后者，因为前者太麻烦了：得在密密麻麻的记录中找到这个人的赊账总额信息，找到之后再拿出算盘计算，最后再将结果写回到账本上。

同样在 MySQL 中如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。而粉板和账本配合的整个过程就是 MySQL 用到的 Write-Ahead Logging 技术，它的关键点就是**先写日志，再写磁盘**。此时账本 = BinLog，粉板 = RedoLog。

1.  记录更新时，InnoDB引擎就会先把记录写到RedoLog（粉板）里面，并更新内存。同时，InnoDB引擎会在空闲时将这个操作记录更新到磁盘里面。
2.  如果更新太多，RedoLog处理不了的时候，需先将RedoLog部分数据写到磁盘，然后擦除RedoLog的部分数据。RedoLog类似转盘。

**作用：**

确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启[mysql](https://www.2cto.com/database/MySQL/)服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

**内容：**

物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。

**什么时候产生：**

事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。

**什么时候释放：**

当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

**对应的物理文件：**

默认情况下，对应的物理文件位于[数据库](https://www.2cto.com/database/)的data目录下的 ib_logfile1 & ib_logfile2

- innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。

- innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2

**关于文件的大小和数量，由以下两个参数配置：**

- innodb_log_file_size 重做日志文件的大小。

- innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1

RedoLog有 `write pos` 跟 `checkpoint`

- `write pos` ：是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。
- `check point`：是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

`write pos` 和 `check point` 之间的是粉板上还空着的部分，可以用来记录新的操作。如果 `write pos` 追上 `checkpoint`，表示粉板满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 `checkpoint` 推进一下。

有了 `redo log`，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe**。

![x](D:/WorkingDir/Office/Resources/tbms0025.png)

**redo log是什么时候写盘的？**

之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M，Innodb存储引擎先将重做日志写入innodb_log_buffer中。

```sql
show variables like '%innodb_log_buffer_size'
```

然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘

1. Master Thread 每秒一次执行，刷新Innodb_log_buffer到重做日志文件。
2. 每个事务提交时会将重做日志刷新到重做日志文件。
3. 当重做日志缓存可用空间少于一半时，重做日志缓存被刷新到重做日志文件

由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是第一种方式，`Innodb_log_buffer -> 重做日志文件`是Master Thread线程的定时任务。因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。

另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：

> 即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。

这一点可以很好地解释：再大的事务的提交（commit）时间也是很短暂的。

**redolog两阶段提交**：为了让 binlog 跟 redolog 两份日志之间的逻辑一致。提交流程大致如下：

> 1 prepare阶段 --> 2 写binlog --> 3 commit

1. 当在2之前崩溃时，重启恢复后发现没有commit，回滚。备份恢复：没有binlog 。一致
2. 当在3之前崩溃时，重启恢复发现虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog，一致

**binlog跟redolog区别**：

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是在某个数据页上做了什么修改；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如给 ID=2 这一行的 c 字段加1。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。追加写是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

#### UndoLog

UndoLog 一般是逻辑日志，主要分为两种：

1. insert undo log

   > 代表事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃

2. update undo log

   > 事务在进行 update 或 delete 时产生的 undo log；不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除

**作用：**

保证数据的原子性，保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

**内容：**

逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

**什么时候产生：**

事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

**什么时候释放：**

当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

**对应的物理文件：**

MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。

MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数，如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。

**关于MySQL5.7之后的独立undo 表空间配置参数如下：**

```ini
innodb_undo_directory = /data/undospace/  # undo独立表空间的存放目录
innodb_undo_logs = 128  # 回滚段为128KB
innodb_undo_tablespaces = 4  # 指定有4个undo log文件
```

如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间默认为在MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。

```sql
show variables like 'innodb_data_file_path%'
```

**其他：**

undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。

默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，因此共享表空间可能会变的很大，默认情况下，也就是undo日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。

因此，mysql5.7之后的**独立undo表空间**的配置就显得很有必要了。



### 2. MySQL锁和事务

#### SQL事务隔离级别

**ACID的四个特性**

1. **原子性（Atomicity）**：把多个操作放到一个事务中，保证这些操作要么都成功，要么都不成功
2. **一致性（Consistency）**：理解成一串对数据进行操作的程序执行下来，不会对数据产生不好的影响，比如凭空产生，或消失
3. **隔离性（Isolation，又称独立性）**：隔离性的意思就是多个事务之间互相不干扰，即使是并发事务的情况下，他们只是两个并发执行没有交集，互不影响的东西；当然实现中，也不一定需要这么完整隔离性，即不一定需要这么的互不干扰，有时候还是允许有部分干扰的。所以MySQL可以支持4种事务隔离性
4. **持久性（Durability）**：当某个操作操作完毕了，那么结果就是这样了，并且这个操作会持久化到日志记录中

PS：ACID中C与CAP定理中C的区别

> ACID的C着重强调单数据库事务操作时，要保证数据的完整和正确性，数据不会凭空消失跟增加。[CAP](https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&mid=2247485515&idx=1&sn=60763ddda77928943bfd3d57e0c9256e&scene=21#wechat_redirect) 理论中的C指的是对一个数据多个备份的读写一致性

**事务操作可能会出现的数据问题**

> 1、**脏读(dirty read)**：B事务更改数据还未提交，A事务已经看到并且用了。B事务如果回滚，则A事务做错了 
>
> 2、 **不可重复读(non-repeatable read)**：不可重复读的重点是修改: 同样的条件, 你读取过的数据, 再次读取出来发现值不一样了，只需要锁住满足条件的记录 
>
> 3、 **幻读(phantom read)**：事务A先修改了某个表的所有纪录的状态字段为已处理，未提交；事务B也在此时新增了一条未处理的记录，并提交了；事务A随后查询记录，却发现有一条记录是未处理的造成幻读现象，幻读仅专指***新插入的行***。幻读会造成语义上的问题跟数据一致性问题。
>
> 4、 在可重复读RR隔离级别下，普通查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在当前读下才会出现。要用间隙锁解决此问题。

在说隔离级别之前，你首先要知道，***你隔离得越严实，效率就会越低***。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别由低到高如下：

![x](D:/WorkingDir/Office/Resources/tbms0027.png)

上图从上到下的模式会导致系统的并行性能依次降低，安全性依次提高。

> 读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
>
> 读已提交（Oracle默认）：别人改数据的事务已经提交，我在我的事务中才能读到。
>
> 可重复读（MySQL默认）：别人改数据的事务已经提交，我在我的事务中也不去读，以此保证重复读一致性。
>
> 串行：我的事务尚未提交，别人就别想改数据。

标准跟实现：上面都是关于事务的标准，但是每一种数据库都有不同的实现，比如`MySQL InnDB` 默认为`RR`级别，但是**不会出现幻读**。因为当事务A更新了所有记录的某个字段，此时事务A会获得对这个表的**表锁**，因为事务A还没有提交，所以事务A获得的锁没有释放，此时事务B在该表插入新记录，会因为无法获得该表的锁，则导致插入操作被阻塞。只有事务A提交了事务后，释放了锁，事务B才能进行接下去的操作。所以可以说  **MySQL的RR级别的隔离是已经实现解决了脏读，不可重复读和幻读的**。

#### MySQL中的锁

无论是Java的并发编程还是数据库的并发操作都会涉及到锁，研发人员引入了**悲观锁**跟**乐观锁**这样一种锁的设计思想。

**悲观锁**：

> `优点`：适合在写多读少的并发环境中使用，虽然无法维持非常高的性能，但是在乐观锁无法提更好的性能前提下，可以做到数据的安全性
>
> `缺点`：加锁会增加系统开销，虽然能保证数据的安全，但数据处理吞吐量低，不适合在读多写少的场合下使用

**乐观锁**：

> `优点`：在读多写少的并发场景下，可以避免数据库加锁的开销，提高DAO层的响应性能，很多情况下ORM工具都带有乐观锁的实现，所以这些方法不一定需要我们人为的去实现。
>
> `缺点`：在写多读少的并发场景下，即在写操作竞争激烈的情况下，会导致CAS多次重试，冲突频率过高，导致开销比悲观锁更高。
>
> `实现`：数据库层面的乐观锁其实跟`CAS`思想类似， 通过`数据版本号`或者`时间戳`也可以实现。

数据库并发场景主要有三种：

> `读-读`：不存在任何问题，也不需要并发控制
>
> `读-写`：有隔离性问题，可能遇到脏读，幻读，不可重复读
>
> `写-写`：可能存更新丢失问题，比如第一类更新丢失，第二类更新丢失

两类更新丢失问题：

> 第一类更新丢失：事务A的事务回滚覆盖了事务B已提交的结果 
>
> 第二类更新丢失：事务A的提交覆盖了事务B已提交的结果

为了合理贯彻落实锁的思想，MySQL中引入了杂七杂八的各种锁：

![x](D:/WorkingDir/Office/Resources/tbms0028.png)

##### 锁分类

MySQL支持三种层级的锁定，分别为

1. 表级锁定

   > MySQL中锁定粒度最大的一种锁，最常使用的MYISAM与INNODB都支持表级锁定。

2. 页级锁定

   > 是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁，表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。

3. 行级锁定

   > Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。
   >
   > 行级锁不一定比表级锁要好：锁的粒度越细，代价越高，相比表级锁在表的头部直接加锁，行级锁还要扫描找到对应的行对其上锁，这样的代价其实是比较高的，所以表锁和行锁各有所长。

##### MyISAM中的锁

1. 虽然MySQL支持表，页，行三级锁定，但MyISAM存储引擎**只支持表锁**。所以MyISAM的加锁相对比较开销低，但数据操作的并发性能相对就不高。但如果写操作都是尾插入，那还是可以支持一定程度的读写并发
2. 从MyISAM所支持的锁中也可以看出，MyISAM是一个支持读读并发，但不支持通用读写并发，写写并发的数据库引擎，所以它更适合用于读多写少的应用场合，一般工程中也用的较少。

##### InnoDB中的锁

该模式下支持的锁实在是太多了，具体如下：

1. 共享锁（Shared Locks）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁，也就是我读取的行，你不能修改；
2. 排他锁（Exclusive Locks）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。也就是我更新的行，不允许其他的事务读取和更新相同的行；

另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种**内部使用的意向锁（Intention Locks）**，这两种意向锁都是**表锁**。

1. 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
2. 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

意向锁是InnoDB自动加的，不需用户干预。对于 UPDATE、DELETE 和 INSERT 语句，InnoDB会自动给涉及数据集加**排他锁（X)**；对于普通 SELECT 语句，InnoDB不会加任何锁；**事务**可以通过以下语句显示给记录集加共享锁或排他锁。

```sql
-- 共享锁（S）：
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE；
-- 排他锁（X)：
SELECT * FROM table_name WHERE ... FOR UPDATE；
```

如果一个**事务**请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。

索引分为**主键**索引和**二级索引【也就是非主键索引】**两种，**如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了二级索引，MySQL会先锁定该二级索引，再锁定相关的主键索引。**

然后innodb行锁分为三种情形：

1）Record lock ：对索引项加锁，即锁定一条记录。

2）Gap lock：对索引项之间的“间隙”、对第一条记录前的间隙或最后一条记录后的间隙加锁，即**锁定一个范围的记录，不包含记录本身**

3）Next-key Lock：锁定一个范围的记录并包含记录本身（上面两者的结合）。

注意：**InnoDB默认级别是repeatable-read级别，所以下面说的都是在RR级别中的**。https://www.cnblogs.com/my_life/articles/10219298.html 【数据库事务隔离级别】

```sql
-- 默认事务隔离级别
select @@global.tx_isolation;
```

Next-Key Lock是行锁与间隙锁的组合，这样，当InnoDB扫描索引记录的时候，会首先对选中的索引记录加上行锁（Record Lock），再对索引记录两边的间隙加上间隙锁（Gap Lock）。

如果一个间隙被事务T1加了锁，其它事务是不能在这个间隙**插入**记录的。

示例1：

```sql
-- 表结构
CREATE TABLE `demo1` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `age` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),           -- 主键索引
  KEY `keyname` (`age`)         -- 二级索引
) ENGINE=InnoDB AUTO_INCREMENT=302 DEFAULT CHARSET=utf8mb4;

-- 数据
| id | age |
+----+-----+
| 1 | 3 |
| 2 | 6 |
| 3 | 9 |

这样我们age段的索引就分为
(negative infinity, 3],
(3,6],
(6,9],
(9,positive infinity)；
 
我们来看一下几种情况：
1）当事务A执行以下语句：
select * from demo1 where age=6 for update;
-- 不仅使用行锁锁住了相应的数据行，同时也在两边的区间，(3,6] 和 (6，9] 都加入了gap锁。
这样事务B就无法在这两个区间insert进新数据，同时也不允许 
update demo1 set age=5 where id=1
-- 因为这也类似于在(3,6]范围新增，但是事务B可以在两个区间外的区间插入数据。实验如下：
事务A:
set autocommit=0;
select * from demo1; -- age上有索引
+----+------+
| id | age |
+----+------+
| 1  | 3 |
| 2  | 6 |
| 3  | 9 |
select * from demo1 where age=6 for update;
+----+------+
| id | age |
+----+------+
| 2 | 6 |
+----+------+
事务B：
尝试insert age=5的数据，确实有锁等待，说明确实(3,6]上有区间锁，防止在这个区间插入；
insert into demo1 (id,age) values (5,5);
查看事务状态，发现确实是等待：
select * from INNODB_TRX;
-- ---------------- 1. row ----------------
trx_id: 27162
trx_state:LOCK WAIT
trx_started: 2018-04-06 00:03:39
trx_requested_lock_id: 27162:529:4:3
trx_wait_started: 2018-04-06 00:03:39
trx_weight: 3
trx_mysql_thread_id: 46
trx_query: insert into demo1 (id,age) values (5,5)
trx_operation_state: inserting
trx_tables_in_use: 1
trx_tables_locked: 1
trx_lock_structs: 2
trx_lock_memory_bytes: 360
trx_rows_locked: 1
trx_rows_modified: 1
trx_concurrency_tickets: 0
trx_isolation_level: REPEATABLE READ
trx_unique_checks: 1
trx_foreign_key_checks: 1
trx_last_foreign_key_error: NULL
trx_adaptive_hash_latched: 0
trx_adaptive_hash_timeout: 10000
trx_is_read_only: 0
trx_autocommit_non_locking: 0
-- ---------------- 1. row ----------------
如上说明：(3,6] 和 (6，9] 都加入了gap锁。
这样事务B就无法在这两个区间insert进新数据，但是事务B可以在两个区间外的区间插入数据      
2）当事务A执行如下语句：       
select * from demo1 where age=7 for update;
那么就会给(6,9]这个区间加锁，别的事务无法在此区间插入或更新数据。
3）当事务A执行:
select * from demo1 where age=100 for update;
那么加锁区间就是 (9,positive infinity)，
别的事务无法在此区间插入新数据同时也不允许更新已有的数据到这个区间，
也就是 update demo1 set age=19 where id=1 是不允许的（因为这也类似于新增）。
```

上例说明：

**行锁防止别的事务修改或删除，GAP锁防止别的事务新增（防止新增包括insert和update已有数据到这个范围中）**，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的部分幻读问题，一定注意只是部分幻读问题；

示例2：

```sql
-- 假如emp表中只有101条记录，其empid的值分别是 1,2,...,100,101，下面的SQL：
Select * from emp where empid > 100 for update;
-- 是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，
-- 也会对empid大于101（这些记录并不存在）的“间隙”加锁，
-- 这样其它事务就不能在 empid > 100 范围insert数据了。
```

InnoDB 使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求（对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何 记录，那么本事务如果再次执行上述语句，就会发生幻读）。

示例3：

```sql
-- 假如emp表中只有101条记录，其empid的值分别是 1,5,7,9,10,19，那么下面的sql:
select * from emp where empid >2 and empid <16 for update;
-- 那么InnoDB不仅会对符合条件的empid值为5,7,9,10的记录加锁，也会对(2, 16)这个区间加“间隙”加锁，
-- 这样其他事务就不能在(2, 16)范围insert数据了，并且也不允许更新已有的数据到这个区间；
```

**关于innodb锁机制需要注意的是：**

1. InnoDB行锁是通过给索引上的索引项加锁来实现的

   这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**

   如果没有索引，InnoDB会通过隐藏的聚簇索引来对记录加锁。也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表锁一样。

2. 由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。说白了就是，where id=1 for update 会锁定所有id=1的数据行，如果是where id=1 and name='chensi' for update，这样会把所有 id=1以及所有name='chensi'的行都上排它锁；

3. 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。

4. 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL优化器通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，或者隐式转换，或者like百分号在前等等，这种情况下InnoDB将使用表锁，而不是行锁。

因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。

**查看innodb的相关锁：**

**information_schema** 库中增加了三个关于锁的表：

1. innodb_trx    ## 当前运行的所有事务 ，还有具体的语句

2. innodb_locks   ## 当前出现的锁

3. innodb_lock_waits  ## 锁等待的对应关系

看一下表结构：

```sql
desc innodb_locks;
+————-+———————+——+—–+———+——-+
| Field      | Type                 | Null | Key | Default | Extra |
+————-+———————+——+—–+———+——-+
| lock_id     | varchar(81)         | NO  |      |         | 锁ID
| lock_trx_id | varchar(18)         | NO  |      |         | 拥有锁的事务ID
| lock_mode   | varchar(32)         | NO  |      |         | 锁模式
| lock_type   | varchar(32)         | NO  |      |         | 锁类型
| lock_table  | varchar(1024)       | NO  |      |         | 被锁的表
| lock_index  | varchar(1024)       | YES |      |  NULL   | 被锁的索引
| lock_space  | bigint(21) unsigned | YES |      |  NULL   | 被锁的表空间号
| lock_page   | bigint(21) unsigned | YES |      |  NULL   | 被锁的页号
| lock_rec    | bigint(21) unsigned | YES |      |  NULL   | 被锁的记录号
| lock_data   | varchar(8192)       | YES |      |  NULL   | 被锁的数据
+————-+———————+——+—–+———+——-+

desc innodb_lock_waits;
+——————-+————-+——+—–+———+——-+
| Field            | Type        | Null | Key | Default | Extra |
+——————-+————-+——+—–+———+——-+
| requesting_trx_id | varchar(18) | NO  |    |        | 请求锁的事务ID（也就是等待锁的id）
| requested_lock_id | varchar(81) | NO  |    |        | 请求锁的锁ID
| blocking_trx_id   | varchar(18) | NO  |    |        | 当前拥有锁的事务ID
| blocking_lock_id  | varchar(81) | NO  |    |        | 当前拥有锁的锁ID
+——————-+————-+——+—–+———+——-+

desc innodb_trx;
+—————————-+———————+——+—–+———————+——-+
| Field                      | Type                | Null | Key | Default            | Extra |
+—————————-+———————+——+—–+———————+——-+
| trx_id                     | varchar(18)         | NO  |    |                     | 事务ID
| trx_state                  | varchar(13)         | NO  |    |                     | 事务状态：有锁就显示LOCK WAIT
| trx_started                | datetime            | NO  |    | 0000-00-00 00:00:00 | 事务开始时间；
| trx_requested_lock_id      | varchar(81)         | YES |    | NULL                | innodb_locks.lock_id
| trx_wait_started           | datetime            | YES |    | NULL                | 事务开始等待的时间
| trx_weight                 | bigint(21) unsigned | NO  |    | 0                   | 
| trx_mysql_thread_id        | bigint(21) unsigned | NO  |    | 0                   | 事务线程ID
| trx_query                  | varchar(1024)       | YES |    | NULL                | 具体SQL语句
| trx_operation_state        | varchar(64)         | YES |    | NULL                | 事务当前操作状态
| trx_tables_in_use          | bigint(21) unsigned | NO  |    | 0                   | 事务中有多少个表被使用
| trx_tables_locked          | bigint(21) unsigned | NO  |    | 0                   | 事务拥有多少个锁
| trx_lock_structs           | bigint(21) unsigned | NO  |    | 0                   |
| trx_lock_memory_bytes      | bigint(21) unsigned | NO  |    | 0                   | 事务锁住的内存大小（B）
| trx_rows_locked            | bigint(21) unsigned | NO  |    | 0                   | 事务锁住的行数
| trx_rows_modified          | bigint(21) unsigned | NO  |    | 0                   | 事务更改的行数
| trx_concurrency_tickets    | bigint(21) unsigned | NO  |    | 0                   | 事务并发票数
| trx_isolation_level        | varchar(16)         | NO  |    |                     | 事务隔离级别
| trx_unique_checks          | int(1)              | NO  |    | 0                   | 是否唯一性检查
| trx_foreign_key_checks     | int(1)              | NO  |    | 0                   | 是否外键检查
| trx_last_foreign_key_error | varchar(256)        | YES |    | NULL                | 最后的外键错误
| trx_adaptive_hash_latched  | int(1)              | NO  |    | 0                   |
| trx_adaptive_hash_timeout  | bigint(21) unsigned | NO  |    | 0                   |
+—————————-+———————+——+—–+———————+——-+

show processlist;
show engine innodb status\G;
select ID,STATE from information_schema.processlist 
 where user='system user';
-- 批量kill多个进程
select concat('KILL ',id,';') from information_schema.processlist 
 where user='system user';
+------------------------+
| KILL 3101;            |
| KILL 2946;            |
+------------------------+
-- mysql命令行
select concat('KILL ',id,';') from information_schema.processlist 
 where user='root' into outfile '/tmp/a.txt';
```

**关于死锁：**

**MyISAM表锁是deadlock free的**，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的**事务**外，**锁是逐步获得的（一个包含多条sql的事务）**，这就决定了在InnoDB中发生死锁是可能的。

发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数 **innodb_lock_wait_timeout**来解决。

需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

通常来说，**死锁都是应用设计的问题**，通过调整业务流程、数据库对象设计、**事务大小**，以及访问数据库的SQL语句，绝大部分死锁都可以避免。

下面就通过实例来介绍几种避免死锁的常用方法：

1. 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。

2. 在程序以批量方式处理数据的时候，如果事先**对数据排序**，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。

3. 在事务中，**如果要更新记录，应该直接申请足够级别的锁，即排他锁**，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。

如果出现死锁，可以 `show engine innodb status\G` 命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

其它：

- 插入意向锁（Insert Intention Locks） 
- 主键自增锁 (AUTO-INC Locks) 
- 空间索引断言锁（Predicate Locks for Spatial Indexes）

`lock in share modle` 共享读锁：

> 为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据使用了 `in share mode` 的方式上了`S` 锁。如果不及时的commit 或者rollback 也可能会**造成大量的事务等待**。

`for update`排它写锁：

> 为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候，需要用到`for update`。相当于一个 update 语句。在业务繁忙的情况下，如果事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。

`Gap Lock`间隙锁：

> 1、行锁只能锁住行，如果在记录之间的间隙插入数据就无法解决了，因此MySQL引入了间隙锁(Gap Lock)。间隙锁是`左右开区间`。间隙锁之间`不会冲突`。
>
> 2、间隙锁和行锁合称`NextKeyLock`，每个`NextKeyLock`是`前开后闭区间`。

间隙锁加锁原则（学完忘那种）：

> 1、加锁的基本单位是 NextKeyLock，是前开后闭区间。
>
> 2、查找过程中访问到的对象才会加锁。
>
> 3、索引上的等值查询，给`唯一索引`加锁的时候，NextKeyLock退化为行锁。
>
> 4、索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，NextKeyLock退化为间隙锁。
>
> 5、唯一索引上的范围查询会访问到不满足条件的第一个值为止。

#### MVCC

> 1、全称`Multi-Version Concurrency Control`，即**多版本并发控制**。MVCC是一种并发控制的`理念`，维持一个数据的多个版本，使得读写操作没有冲突。
>
> 2、MVCC在MySQL InnoDB中实现目的主要是为了**提高数据库并发性能**，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

**MySQL InnoDB下的当前读和快照读**

1. 当前读

> 1、像`select lock in share mode`（共享锁）、`select for update` 、`update`、`insert`、`delete`（排他锁）这些操作都是一种`当前读`，就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对`读取的记录进行加锁`。
>
> 2、当前读可以认为是`悲观锁`的具体功能实现

2. 快照读

> 1、不加锁的select就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即`MVCC`，可以认为`MVCC是行锁的一个变种`，但它在很多情况下，`避免了加锁操作`，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。
>
> 2、快照读就是MVCC思想在MySQL的具体非阻塞读功能实现，MVCC的目的就是为了实现读-写冲突不加锁，提高并发读写性能，而这个读指的就是`快照读`。
>
> 3、快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。

因为大佬不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出了MVCC，所以我们可以形成两个组合：

> `MVCC + 悲观锁`：MVCC解决读写冲突，悲观锁解决写写冲突
>
> `MVCC + 乐观锁`：MVCC解决读写冲突，乐观锁解决写写冲突

##### MVCC的实现原理

MVCC实现原理主要是依赖记录中的 `四个隐式字段`、`undo日志` 、`Consistent Read View`来实现的。

**四个隐式字段**：

1. DB_TRX_ID：

> 6byte，最近修改（修改/插入）事务ID：记录创建这条记录/最后一次修改该记录的`事务ID`

2. DB_ROLL_PTR

> 7byte，回滚指针，指向这条记录的`上一个版本`（存储于rollback segment里）

3. DB_ROW_ID

> 6byte，隐含的自增ID（`隐藏主键`），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引

4. FLAG

> 一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了

事务对一条记录的修改，会导致该记录的undo log成为一条记录版本线性表（链表），undo log的链首就是最新的旧记录，链尾就是最早的旧记录。

**undo日志**：此知识点上文已经说过了，对MVCC有帮助的实质是update undo log，undo log实际上就是存在rollback segment中旧记录链。

**一致读视图 Consistent Read View**：Read View是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个`快照`，记录并维护系统当前活跃事务的ID（InnoDB里面每个事务有一个唯一的事务ID，叫作`transaction id`。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的）。拿着这个ID跟记录中ID对比进行选择性展示，这里说下大致的思维。

你可以**简单的理解**为MVCC为每一行增加了两个隐藏字段，两个字段分别保存了这个行的`当前事务ID`跟行的`删除事务ID`。

1. insert时：

> InnoDB为新插入的每一行保存当前系统版本号作为版本号。

2. select时：

> 1、 InnoDB只会查找版本早于当前事务版本的数据行（也就是行的系统版本号<=事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
>
> 2、行的删除版本要么未定义，要么大于当前事务版本号，这可以确保事务读取到的行在事务开始之前未被删除。
>
> 3、**只有1，2 同时满足的记录，才能返回作为查询结果**。

3. delete时：

> InnoDB会为删除的每一行保存当前系统的版本号（事务的ID）作为删除标识.

4. update时：

> InnoDB执行update，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要update的行的删除时间。

上面只是一个浅显的讲解MVCC选择标准流程，源码层面应该是根据`低水位`跟`高水位`来截取的。具体实现可自行百度。

`重点`：

> 1、事务中快照读的结果是`非常依赖`该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力。
>
> 2、在`RC`隔离级别下，是每个快照读都会生成并获取最新的Read View；而在`RR`隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View。



### 3. SQL语句执行流程

MySQL大体上可分为`Server层`和`存储引擎层`两部分。

**Server层：**

- `连接器`：TCP握手后服务器来验证登陆用户身份，A用户创建连接后，管理员对A用户权限修改了也不会影响到已经创建的链接权限，必须重新登陆。
- `查询缓存`：查询后的结果存储位置，MySQL8.0版本以后已经取消，因为查询缓存失效太频繁，得不偿失。
- `分析器`：根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。
- `优化器`：多种执行策略可实现目标，系统自动选择最优进行执行。
- `执行器`：判断是否有权限，将最终任务提交到存储引擎。

**存储引擎层**

负责数据的存储和提取。其架构模式是`插件式`的，支持`InnoDB`、`MyISAM`、`Memory`等多个存储引擎。现在最常用的存储引擎是`InnoDB`，它从MySQL 5.5.5版本开始成为了默认存储引擎（经常用的也是这个）。

![x](D:/WorkingDir/Office/Resources/tbms0022.png)

**SQL执行顺序**

![x](D:/WorkingDir/Office/Resources/tbms0023.png)



#### 4. MySQL索引

索引的常见模型有`哈希表`、`有序数组`和`搜索树`。

> `哈希表`：一种以KV存储数据的结构，只适合等值查询，不适合范围查询。
>
> `有序数组`：只适用于静态存储引擎，涉及到插入的时候比较麻烦。可以参考Java中的**ArrayList**。
>
> `搜索树`：按照数据结构中的二叉树来存储数据，不过此时是N叉树(B+树)。**广泛应用在存储引擎层中**。

![x](D:/WorkingDir/Office/Resources/tbms0026.png)

B+树比B树优势在于：

> 1. B+ 树非叶子节点存储的只是索引，可以存储的更多。B+树比B树更加矮胖，IO次数更少。
> 2. B+ 树叶子节点前后管理，更加方便范围查询。同时结果都在叶子节点，查询效率稳定。
> 3. B+树中更有利于对数据扫描，可以避免B树的回溯扫描。

索引的优点：

> 1、唯一索引可以保证每一行数据的唯一性 
>
> 2、提高查询速度 
>
> 3、加速表与表的连接 
>
> 4、显著的减少查询中分组和排序的时间
>
> 5、通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。

索引的缺点：

> 1、创建跟维护都需要耗时 
>
> 2、创建索引时，需要对表加锁，在锁表的同时，可能会影响到其他的数据操作 
>
> 3、 索引需要磁盘的空间进行存储，磁盘占用也很快。
>
> 4、当对表中的数据进行CRUD的时，也会触发索引的维护，而维护索引需要时间，可能会降低数据操作性能

**索引设计的原则**不应该：

> 1、索引不是越多越好。索引太多，维护索引需要时间跟空间。
>
> 2、 频繁更新的数据，不宜建索引。
>
> 3、数据量小的表没必要建立索引。

应该：

> 1、重复率小的列建议生成索引。因为重复数据少，索引树查询更有效率，等价基数越大越好。
>
> 2、数据具有唯一性，建议生成唯一性索引。在数据库的层面，保证数据正确性 
>
> 3、频繁group by、order by的列建议生成索引。可以大幅提高分组和排序效率 
>
> 4、经常用于查询条件的字段建议生成索引。通过索引查询，速度更快

索引失效的场景

> 1、模糊搜索：左模糊或全模糊都会导致索引失效，比如'%a'和'%a%'。但是右模糊是可以利用索引的，比如'a%' 。
>
> 2、隐式类型转换：比如`select * from t where name = xxx`, name是字符串类型，但是没有加引号，所以是由MySQL隐式转换的，所以会让索引失效 3、当语句中带有or的时候：比如`select * from t where name=‘sw’ or age=14`
>
> 4、不符合联合索引的最左前缀匹配：(A,B,C)的联合索引，你只where了C或B或只有B,C

**关于索引的知识点**：

**主键索引**：主键索引的叶子节点存的是**整行**数据信息。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。主键自增是无法保证完全自增的哦，遇到唯一键冲突、事务回滚等都可能导致不连续。

**唯一索引**：以唯一列生成的索引，该列不允许有重复值，但允许有空值(NULL)

普通索引跟唯一索引查询性能：InnoDB的数据是按数据页为单位来读写的，默认每页16KB，因此这两种索引查询数据性能差别微乎其微。

**change buffer**：普通索引用在更新过程的加速，更新的字段如果在缓存中，如果是普通索引则直接更新即可。如果是唯一索引需要将所有数据读入内存来确保不违背唯一性，所以尽量用普通索引。

**非主键索引**：非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）

**回表**：先通过数据库索引扫描出数据所在的行，再通过行主键id取出索引中未提供的数据，即基于非主键索引的查询需要多扫描一棵索引树。

**覆盖索引**：如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为覆盖索引。

**联合索引**：相对单列索引，组合索引是用多个列组合构建的索引，一次性最多联合16个。

**最左前缀原则**：对多个字段同时建立的组合索引（有顺序，ABC，ACB是完全不同的两种联合索引）以联合索引(a,b,c)为例，建立这样的索引相当于建立了索引a、ab、abc三个索引。另外组合索引实际还是一个索引，并非真的创建了多个索引，只是产生的效果等价于产生多个索引。

**索引下推**：MySQL 5.6引入了索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数。

**索引维护**：B+树为了维护索引有序性涉及到页分裂跟页合并。增删数据时需考虑页空间利用率。

**自增主键**：一般会建立与业务无关的自增主键，不会触发叶子节点分裂。

**延迟关联**：通过使用覆盖索引查询返回需要的主键，再根据主键关联原表获得需要的数据。

**InnoDB存储**：`* .frm`文件是一份定义文件，也就是定义数据库表是一张怎么样的表。`*.ibd`文件则是该表的索引，数据存储文件，既该表的所有索引树，所有行记录数据都存储在该文件中。

**MyISAM存储**：`* .frm`文件是一份定义文件，也就是定义数据库表是一张怎么样的表。`* .MYD`文件是MyISAM存储引擎表的所有行数据的文件。`* .MYI`文件存放的是MyISAM存储引擎表的索引相关数据的文件。MyISAM引擎下，表数据和表索引数据是分开存储的。

**MyISAM查询**：在MyISAM下，主键索引和辅助键索引都属于非聚簇索引。查询不管是走主键索引，还是非主键索引，在叶子结点得到的都是目的数据的地址，还需要通过该地址，才能在数据文件中找到目的数据。

> PS：InnoDB支持聚簇索引，MyISAM不支持聚簇索引



## Redis

1. [Redis 持久化机制](#1. Redis 持久化机制)
2. [Redis过期策略和内存淘汰策略](#2. Redis过期策略和内存淘汰策略)
3. [Redis集群](#3. Redis集群)
   - [redis主从复制](#redis主从复制)
   - [高可用之哨兵模式](#高可用之哨兵模式)
   - [Redis Cluster](#Redis Cluster)
4. [100W并发4G数据，10W并发400G数据，如何设计Redis存储方式？](#4. 100W并发4G数据，10W并发400G数据，如何设计Redis存储方式？)
5. [Redis为什么那么快？](#5. Redis为什么那么快？)

参考：查看[文档](./分布式笔记-缓存-Redis.md)

### 1. Redis 持久化机制

**怎么保证 Redis 挂掉之后再重启数据可以进行恢复？**

Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。

- **快照（snapshotting，RDB）**
- **只追加文件（append-only file, AOF）**。

**快照（snapshotting）持久化（RDB）**

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：

```
save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

同步触发：

- `save` 命令，会阻塞其他所有命令的执行，直到持久化完成；
- 如果存在旧的 RDB 文件，会用新的来替换；
- 复杂度 O(n)，包含所有的数据。

异步触发：

- `bgsave` 命令，创建一个子进程实现数据持久化，完成后通知主进程；
- 不会阻塞其他命令的执行，客户端可以随时访问；
- 文件策略和复杂度都与 save 相同。

自动触发：基于修改数据数量或时间，自动执行持久化。

其他机制：全量复制、debug reload、shutdown。

**AOF（append-only file）持久化**

与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：

```
appendonly yes
```

开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。

在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

**相关 issue** ：[783：Redis 的 AOF 方式](https://github.com/Snailclimb/JavaGuide/issues/783)

**拓展：Redis 4.0 对于持久化机制的优化**

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

**恢复**

启动时会先检查AOF(数据更完整)文件是否存在，如果不存在就尝试加载RDB。

![x](D:/WorkingDir/Office/Resources/tbms0016.png)

**补充内容：AOF 重写**

AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。

在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作

![x](http://121.196.182.26:6100/public/images/redis-aof1.png)

![x](http://121.196.182.26:6100/public/images/redis-aof2.png)

基本配置：

- auto-aof-rewrite-min-size：AOF 文件重写需要的大小；
- auto-aof-rewrite-percentage：AOF 文件增长率

统计指标：

- aofcurrentsize：AOF 当前大小
- aof-base-size：AOF 上次启动和重写的大小

需要同时满足以下条件才会触发：

- aof_current_size > auto-aof-rewrite-min-size
- aof_current_size - aof_base_size/aof_base_size > auto-aof-rewrite-percentage

**补充内容：两种方式对比**

| 命令       | RDB                            | AOF                              |
| ---------- | ------------------------------ | -------------------------------- |
| 启动优先级 | 低，默认关闭                   | 高，建议打开（缓存场景）         |
| 占用空间   | 二进制存储且压缩，占用空间较小 | 以原始日志形式存储，占用空间较大 |
| 写入开销   | 全量存储数据，开销较大         | 日志追加写入，开销较小           |
| 恢复速度   | 快                             | 慢                               |
| 数据安全性 | 有可能丢失数据                 | 根据策略而定                     |

1. RDB更适合做冷备

   **优点：**

   1、压缩后的二进制文，适用于备份、全量复制，用于灾难恢复加载RDB恢复数据远快于AOF方式，适合大规模的数据恢复。

   2、如果业务对数据完整性和一致性要求不高，RDB是很好的选择。数据恢复比AOF快。

   **缺点：**

   1、RDB是**周期间隔性的快照文件**，数据的完整性和一致性不高，因为RDB可能在最后一次备份时宕机了。

   2、备份时占用内存，因为Redis 在备份时会独立fork一个**子进程**，将数据写入到一个临时文件（此时内存中的数据是原来的两倍哦），最后再将临时文件替换之前的备份文件。所以要考虑到大概两倍的数据膨胀性。

   **注意手动触发及COW：**

   1、`SAVE` 直接调用 rdbSave ，`阻塞` Redis 主进程，导致无法提供服务。2、`BGSAVE` 则 fork 出一个子进程，子进程负责调用 rdbSave ，在保存完成后向主进程发送信号告知完成。在BGSAVE 执行期间**仍可以继续处理客户端的请求**。

   3、Copy On Write 机制，备份的是开始那个时刻内存中的数据，只复制被修改内存页数据，不是全部内存数据。

   4、Copy On Write 时如果父子进程大量写操作会导致分页错误。

![x](D:/WorkingDir/Office/Resources/tbms0015.png)

2. AOF更适合做热备。

   优点：AOF是一秒一次去通过一个后台的线程fsync操作，数据丢失不用怕。

   缺点：

   1、对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在**恢复**大数据集时的速度比 AOF 的恢复速度要快。

   2、根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的。

   **AOF整个流程分两步**：第一步是命令的实时写入，不同级别可能有1秒数据损失。命令先追加到`aof_buf`然后再同步到AO磁盘，**如果实时写入磁盘会带来非常高的磁盘IO，影响整体性能**。

   第二步是对aof文件的**重写**，目的是为了减少AOF文件的大小，可以自动触发或者手动触发(**BGREWRITEAOF**)，是Fork出子进程操作，期间Redis服务仍可用。

   1、在重写期间，由于主进程依然在响应命令，为了保证最终备份的完整性；它`依然会写入旧`的AOF中，如果重写失败，能够保证数据不丢失。

   2、为了把重写期间响应的写入信息也写入到新的文件中，因此也会`为子进程保留一个buf`，防止新写的file丢失数据。

   3、重写是直接把`当前内存的数据生成对应命令`，并不需要读取老的AOF文件进行分析、命令合并。

   4、**无论是 RDB 还是 AOF 都是先写入一个临时文件，然后通过`rename`完成文件的替换工作**。

   关于Fork的建议：

   1、降低fork的频率，比如可以手动来触发RDB生成快照、与AOF重写；

   2、控制Redis最大使用内存，防止fork耗时过长；

   3、配置牛逼点，合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。

   4、Redis在执行`BGSAVE`和`BGREWRITEAOF`命令时，哈希表的负载因子>=5，而未执行这两个命令时>=1。目的是**尽量减少写操作**，避免不必要的内存写入操作。

   5、**哈希表的扩展因子**：哈希表已保存节点数量 / 哈希表大小。因子决定了是否扩展哈希表。



### 2. Redis过期策略和内存淘汰策略

rRedis中 过期策略 通常有以下三种：

1、**定时过期**：

> 每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即对key进行清除。该策略可以立即清除过期的数据，对内存很友好；但是**会占用大量的CPU资源去处理过期的数据**，从而影响缓存的响应时间和吞吐量。

2、**惰性过期**：

> 只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却**对内存非常不友好**。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

3、**定期过期**：

> 每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源**达到最优**的平衡效果。
>
> expires字典会保存所有设置了过期时间的key的过期时间数据，其中 key 是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。

Redis采用的过期策略：`惰性删除` + `定期删除`。memcached采用的过期策略：`惰性删除`。

**1、定期删除**

Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。

从过期字典中随机 20 个 key；删除这 20 个 key 中已经过期的 key；如果过期的 key 比率超过 1/4，那就重复步骤 1；同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。

如果某一时刻，有大量key同时过期，Redis 会持续扫描过期字典，造成客户端响应卡顿，因此设置过期时间时，就尽量避免这个问题，在设置过期时间时，可以给过期时间设置一个随机范围，避免同一时刻过期。

**1.1 如何配置定期删除执行时间间隔**

redis的定时任务默认是10s执行一次，如果要修改这个值，可以在redis.conf中修改hz的值。

redis.conf中，hz默认设为10，提高它的值将会占用更多的cpu，当然相应的redis将会更快的处理同时到期的许多key，以及更精确的去处理超时。hz的取值范围是1~500，通常不建议超过100，只有在请求延时非常低的情况下可以将值提升到100。

**1.2 单线程的redis，如何知道要运行定时任务？**

redis是单线程的，线程不但要处理定时任务，还要处理客户端请求，线程不能阻塞在定时任务或处理客户端请求上，那么，redis是如何知道何时该运行定时任务的呢？

Redis 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是接下来处理客户端请求的最大时长，若达到了该时长，则暂时不处理客户端请求而去运行定时任务。

**2、懒惰删除**

定时删除策略中，从删除方法来看，必然会导致有key过期了但未从redis中删除的情况。

面对这种情况，redis在操作一个key时，会先判断这个值是否过期，若已过期，则删除该key；若未过期，则进行后续操作。

**aof、rdb和复制功能对过期键的处理**

1、rdb

生成rdb文件：生成时，程序会对键进行检查，过期键不放入rdb文件。

载入rdb文件：载入时，如果以主服务器模式运行，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会忽略；如果以从服务器模式运行，无论键过期与否，均会载入数据库中，过期键会通过与主服务器同步而删除。

2、aof

当服务器以aof持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被删除，那么aof文件不会因为这个过期键而产生任何影响；当过期键被删除后，程序会向aof文件追加一条del命令来显式记录该键已被删除。

aof重写过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的aof文件中。

3、复制

当服务器运行在复制模式下时，从服务器的过期删除动作由主服务器控制：

主服务器在删除一个过期键后，会显式地向所有从服务器发送一个del命令，告知从服务器删除这个过期键;

从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键;

从服务器只有在接到主服务器发来的del命令后，才会删除过期键。

Redis 的过期清理策略：

- 定期删除：默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除；缺点是如果大量的 key 过期时遍历删除会严重影响性能、随机抽取也会导致一些 key 过期后仍一直留存；
- 惰性删除：获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西；缺点是对于过期又不再需要访问的 key 无法被删除。

对于以上两种情况无法有效清理过期的 key，因此 Redis 可以设置内存最大使用量，超出用量时根据数据淘汰策略清理：

| 策略             | 描述                                                 |
| ---------------- | ---------------------------------------------------- |
| `volatile-lru`   | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| `volatile-ttl`   | 从已设置过期时间的数据集中挑选将要过期的数据淘汰     |
| `latile-random`  | 从已设置过期时间的数据集中任意选择数据淘汰           |
| `llkeys-lru`     | 从所有数据集中挑选最近最少使用的数据淘汰             |
| `allkeys-random` | 从所有数据集中任意选择数据进行淘汰                   |
| `noeviction`     | 禁止驱逐数据，**不删除**的意思。                     |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 `allkeys-lru` 淘汰策略，将最近最少使用的数据淘汰。

Redis 4.0 引入了 `volatile-lfu` 和 `allkeys-lfu` 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。

面试常问常考的也就是**LRU**了，大家熟悉的`LinkedHashMap`中也实现了`LRU`算法的，实现如下：

```java
class SelfLRUCache<K, V> extends LinkedHashMap<K, V> {
    private final int CACHE_SIZE;
    /**
     * 传递进来最多能缓存多少数据
     * @param cacheSize 缓存大小
     */
    public SelfLRUCache(int cacheSize) {
  // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
        return size() > CACHE_SIZE;
    }
}
```

总结：

Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据，过期策略用于处理过期的缓存数据。



### 3. Redis集群

单机问题有机器故障、容量瓶颈、QPS瓶颈。在实际应用中，Redis的多机部署时候会涉及到`redis主从复制`、`Sentinel哨兵模式`、`Redis Cluster`。

| 模式          | 优点                             | 缺点                                              |
| :------------ | :------------------------------- | :------------------------------------------------ |
| 单机版        | 架构简单，部署方便               | 机器故障、容量瓶颈、QPS瓶颈                       |
| 主从复制      | 高可靠性，读写分离               | 故障恢复复杂，主库的写跟存受单机限制              |
| Sentinel 哨兵 | 集群部署简单，HA                 | 原理繁琐，slave存在资源浪费，不能解决读写分离问题 |
| Redis Cluster | 数据动态存储solt，可扩展，高可用 | 客户端动态感知后端变更，批量操作支持查            |

集群简介：

- redis 是一个开源的 key-value 存储系统，受到了广大互联网公司的青睐。redis3.0版本之前只支持单例模式，在3.0版本及以后才支持集群；

- redis 集群采用 P2P 模式，是完全去中心化的，不存在中心节点或者代理节点；

- redis 集群是没有统一的入口的，客户端（client）连接集群的时候连接集群中的任意节点（node）即可，集群内部的节点是相互通信的（PING-PONG机制），每个节点都是一个 redis 实例；

- 为了实现集群的高可用，即判断节点是否健康（能否正常使用），redis-cluster有这么一个投票容错机制：如果集群中超过半数的节点投票认为某个节点挂了，那么这个节点就挂了（fail）。这是判断节点是否挂了的方法；

- 那么如何判断集群是否挂了呢？如果集群中任意一个节点挂了，而且该节点没有从节点（备份节点），那么这个集群就挂了。这是判断集群是否挂了的方法；

- 那么为什么任意一个节点挂了（没有从节点）这个集群就挂了呢？

  > 因为集群内置了16384个slot（哈希槽），并且把所有的物理节点映射到了这16384[0-16383]个slot上，或者说把这些slot均等的分配给了各个节点。
  >
  > 当需要在Redis集群存放一个数据（key-value）时，redis会先对这个key进行crc16算法，然后得到一个结果。再把这个结果对16384进行求余，这个余数会对应[0-16383]其中一个槽，进而决定key-value存储到哪个节点中。
  >
  > 所以一旦某个节点挂了，该节点对应的slot就无法使用，那么就会导致集群无法正常工作。

- 综上所述，每个Redis集群理论上最多可以有16384个节点。

#### redis主从复制

主从复制简介：

- 几种流行的Redis集群解决方案都没有将一个key写到多个节点中，若某个节点故障则无法访问访问其上的key这显然是不满足集群的分区容错性的。

- 使用 **主从复制**，解决 **单点故障**、**容量瓶颈** 和 **QPS瓶颈** 的问题。
- 该模式下具有高可用性且读写分离，会采用 `增量同步` 跟 `全量同步` 两种机制。数据从线上 Redis 实例（主）复制到新启动 Redis 实例（从），提供备份和读写分离；

- Redis集群使用主从模型（master-slave）来提高可靠性，每个 master 节点上绑定若干个 slave 节点（哨兵模式下，当 master 节点故障时集群会推举它的某个 slave 节点代替 master 节点）。

- 使用 slaveof host port 异步命令 或 配置文件 可以让一个节点成为另一个节点的从节点，并复制数据；从节点在从主节点上同步数据时会把旧数据都清空，同步后只允许读，不能写入数据；

- 一个主节点可以有多个从节点，但一个从节点只能有一个主节点，并且不支持主主复制。

Redis主从复制常用的几种方式：

- 一主二仆 A（B、C） 一个Master两个Slave
- 薪火相传（去中心化） A-B-C，B既是主节点（C的主节点），又是从节点（A的从节点）
- 反客为主（主节点down掉后，手动操作升级从节点为主节点）
- 哨兵模式（反客为主的自动版，即主节点down掉后，从节点会自动升级为主节点）

参考：[https://blog.csdn.net/weixin_41846320/article/details/83753667](https://blog.csdn.net/weixin_41846320/article/details/83753667)

**全量同步**

主节点所有数据同步到从节点，包括同步过程中产生的数据。

![x](D:/WorkingDir/Office/Resources/tbms0017.png)

![x](http://121.196.182.26:6100/public/images/redis-copy1.png)

Redis全量复制一般发生在**Slave初始化阶段**，这时Slave需要将Master上的**所有数据**都复制一份：

1. slave连接master，发送`psync`命令。
2. master接收到`psync`命名后，开始执行`bgsave`命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令。
3. master发送快照文件到slave，并在发送期间继续记录被执行的写命令。
4. slave收到快照文件后丢弃所有旧数据，载入收到的快照。
5. master快照发送完毕后开始向slave发送缓冲区中的写命令。
6. slave完成对快照的载入，开始接收命令请求，并执行来自master缓冲区的写命令。

> 总结：同步(sync) + 命令传播(command propagate)

**增量同步**

也叫**指令同步**，就是从库重放在主库中进行的指令。Redis会把指令存放在一个**环形队列**当中，因为内存容量有限，如果备机一直起不来，不可能把所有的内存都去存指令，也就是说，如果备机一直未同步，指令可能会被覆盖掉。

![x](D:/WorkingDir/Office/Resources/tbms0018.png)

Redis增量复制是指Slave初始化后开始正常工作时master发生的写操作同步到slave的过程。增量复制的过程主要是master每执行一个写命令就会向slave发送相同的写命令。

如果主从间网络状况不好，从节点上可能会发生部分数据丢失，这时候再进行一次全量复制开销会很大。可以采用部分复制策略

![x](http://121.196.182.26:6100/public/images/redis-copy2.png)

规避全量复制：

- 全量复制开销较大，除了第一次以外，应该尽量规避。
- 可以选择小主节点（分片）、低峰期间操作。
- 如果节点运行 id 不匹配（如主节点重启、运行 id 发生变化），此时要执行全量复制，应该配合哨兵和集群解决。

- 主从复制挤压缓冲区不足产生的问题（网络中断，部分复制无法满足），可增大复制缓冲区（rel_backlog_size 参数）。

主从链：

随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。

![x](http://121.196.182.26:6100/public/images/redis-copy3.png)

**常见问题**

- 同步故障
- 读写分离：将主节点读流量分摊到从节点。但可能存在以下问题：
  - 复制数据延迟（不一致）；
  - 读取过期数据（Slave不能删除数据）；
  - 从节点故障；
  - 主节点故障。
- 配置不一致
- maxmemory不一致：丢失数据；
- 优化参数不一致：内存不一致。

- 复制风暴
  - 单主节点复制风暴：主节点宕机恢复之后，所有的从节点会重新执行复制，开销非常大。解决方法是更换复制拓扑，把 “一主 - 多从” 替换成 “一主 - 一从 - 多从从” 或更好的拓扑，有效减少多节点复制的压力；
  - 单机器复制风暴：一台机器上运行多个主实例，机器宕机后所有实例都要进行复制。解决方法是把主节点分散到多台机器，或改成高可用架构（从节点接替主节点）。

##### Redis主从同步策略：

1. `主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步`。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。
2. slave在同步master数据时候如果slave丢失连接不用怕，slave在重新连接之后`丢失重补`。
3. 一般通过主从来实现读写分离，但是如果master挂掉后如何保证Redis的HA呢？引入`Sentinel`进行master的选择。

#### 高可用之哨兵模式

![x](D:/WorkingDir/Office/Resources/tbms0019.png)

Redis-sentinel  本身是一个**独立**运行的进程，一般sentinel集群 节点数至少三个且奇数个，它能监控多个master-slave集群，sentinel节点发现master宕机后能进行自动切换。Sentinel可以监视任意多个主服务器以及主服务器属下的从服务器，并在被监视的主服务器下线时，**自动执行故障转移操作**。这里需注意`sentinel`也有`single-point-of-failure`问题。大致罗列下哨兵用途：

- 集群监控：循环监控master跟slave节点。
- 消息通知：当它发现有redis实例有故障的话，就会发送消息给管理员 
- 故障转移：这里分为主观下线（单独一个哨兵发现master故障了）。客观下线（多个哨兵进行抉择发现达到quorum数时候开始进行切换）。
- 配置中心：如果发生了故障转移，它会通知将master的新地址写在配置中心告诉客户端。

**领导者选举**

选举出一个 Sentinel 作为 Leader：集群中至少有三个 Setinel 节点，但只有其中一个节点可完成故障转移。通过以下命令可以进行失败判定或领导者选举：

```sh
sentinel is-mastr-down-by-addr
```

具体流程：

- 每个主观下线的 Sentinel 节点向其他 Sentinel 节点发送命令，要求设置它为领导者；
- 收到命令的 Sentinel 节点如果没有同意通过其他 Sentinel 节点发送的命令，则同意该请求，否则拒绝；
- 如果该 Sentinel 节点发现自己的票数已经超过 Sentinel 集合半数且超过 quorum，则它成为领导者；
- 如果此过程有多个 Sentinel 节点成为领导者，则等待一段时间再重新进行选举。

故障转移的流程：

- Sentinel 选出一个合适的 Slave 作为新的 Master（slaveof no one 命令）；
- 向其余 Slave 发出通知，让它们成为新 Master 的 Slave（parallel-syncs 参数）；
- 等待旧 Master 复活，并使之称为新 Master 的 Slave；
- 向客户端通知 Master 变化。

从 Slave 中选择新 Master 节点的规则：

- 选择 slave-priority 最高的节点；
- 选择复制偏移量最大的节点（同步数据最多）；
- 选择 runId 最小的节点。

#### Redis Cluster

RedisCluster是Redis的分布式解决方案，在3.0版本后推出的方案，有效地解决了Redis分布式的需求。

![x](D:/WorkingDir/Office/Resources/tbms0020.png)

在分布式架构下：

- 每个节点都负责读写（分配指派槽）；
- 节点之间相互通信(meet)，所有节点共享指派槽信息，因此客户端不需要知道数据具体在哪个节点；

![x](http://121.196.182.26:6100/public/images/redis-cluster1.png)

**分区规则**

![x](D:/WorkingDir/Office/Resources/tbms0021.png)

**❓问题：**Redis-Cluster数据是如何进行数据分片的？

常见的分区规则：

1. `节点取余`：hash(key) % N
2. `一致性哈希`：一致性哈希环
3. `虚拟槽哈希`：CRC16[key] & 16383

RedisCluster采用了**虚拟槽分区**方式，具体的实现细节如下：

1. 采用去**中心化**的思想，它使用**虚拟槽solt分区**覆盖到所有节点上。取数据一样的流程，节点之间使用轻量协议通信**Gossip**来减少带宽占用，所以性能很高。
2. 自动实现**负载均衡与高可用**，自动实现**failover**并且支持**动态扩展**，官方已经玩到可以1000个节点，实现的复杂度低。
3. 每个Master也需要配置主从，并且内部也是采用**哨兵模式**，如果有半数节点发现某个异常节点会共同决定更改异常节点的状态。
4. 如果集群中的master没有slave节点，则master挂掉后整个集群就会进入**fail**状态，因为集群的slot映射不完整。**如果集群超过半数以上的master挂掉，集群都会进入fail状态**。
5. 官方推荐 **集群部署至少要3台以上的master节点**。



**❓问题：**介绍3种Redis高可用解决方案。

**方案1：Redis Cluster**

从3.0版本开始，Redis 支持集群模式——Redis Cluster，可线性扩展到1000个节点。

Redis-Cluster 采用无中心架构，每个节点都保存数据和整个集群状态，每个节点都和其它所有节点连接，客户端直连 Redis 服务，免去了 Proxy 代理的损耗。

Redis Cluster 最小集群需要三个主节点，为了保障可用性，每个主节点至少挂一个从节点（当主节点故障后，对应的从节点可以代替它继续工作），三主三从的 Redis Cluster 架构如下图所示：

**方案2：Twemproxy**

Twemproxy 是一个使用 C 语言编写、以代理的方式实现的、轻量级的 Redis 代理服务器。

它通过引入一个代理层，将应用程序后端的多台 Redis 实例进行统一管理，使应用程序只需要在 Twemproxy 上进行操作，而不用关心后面具体有多少个真实的 Redis 实例，从而实现了基于 Redis 的集群服务。

当某个节点宕掉时，Twemproxy 可以自动将它从集群中剔除，而当它恢复服务时，Twemproxy 也会自动连接。由于是代理，Twemproxy 会有微小的性能损失。

Twemproxy 架构如下图所示：

**方案3：Codis**

Codis 是一个分布式 Redis 解决方案。对于上层的应用来说，连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别（部分命令不支持）。上层应用可以像使用单机的 Redis 一样使用，Codis 底层会处理请求的转发，不停机的数据迁移等工作。

**集群方案对比**

| 命令      | Redis Cluster  | ShardedJedis | Codis                           |
| --------- | -------------- | ------------ | ------------------------------- |
| mget/mset | 仅限同一个slot | 不支持       | 失去原子性                      |
| keys      | 仅限同一个slot | 不支持       | 不支持                          |
| scan      | 仅限同一个slot | 不支持       | 仅限同一个slot（SLOTSSCAN命令） |
| rename    | 仅限同一个slot | 不支持       | 不支持                          |
| pipeline  | 不支持         | 不支持       | 支持                            |
| 事务      | 支持相同slot   | 不支持       | 不支持                          |
| 发布/订阅 | 支持           | 不支持       | 不支持                          |
| eval      | 仅限同一slot   | 不支持       | 支持                            |

参考：[https://www.cnblogs.com/Finley/p/8595506.html](https://www.cnblogs.com/Finley/p/8595506.html)



**高可用读写分离**

从节点是主节点的副本，是高可用的基础，同时扩展了读数据的能力。

当主节点宕机，Sentinel 可以选出新的 Master 解决问题，但同时也需要向客户端发出通知消息，使之基于三个消息做出调整：

1. +switch-master：切换主节点（从 -> 主）；
2. +convert-to-slave：切换从节点（旧主 -> 从）；
3. +sdown：主观下线。

![x](http://121.196.182.26:6100/public/images/redis-copy4.png)

**定时任务**

- 每 10s 每个 Sentinel 对 Master 和 Slave 执行 info，目的是发现 Slave 节点、确定主从关系；
- 每 2s 每个 Sentinel 通过 Master 的 Channel 交换信息(pub-sub)：
- 通过 `__sentinel__:hello` 频道交互；
- 交互对节点的分析和自身信息；
- 每 1s 每个 Sentinel 对其他 Sentinel 和 Redis 执行 ping，进行心跳检测。



**基本概念：**

**HashTag**

HashTag机制可以影响key被分配到的slot，从而可以使用那些被限制在slot中操作。

HashTag即是用 `{}` 包裹key的一个子串，如`{user:}1`, `{user:}2`。

在设置了HashTag的情况下，集群会根据HashTag决定key分配到的slot，两个key拥有相同的HashTag:`{user:}`, 它们会被分配到同一个slot，允许我们使用MGET命令。

通常情况下，HashTag不支持嵌套，即将第一个 `{` 和第一个 `}` 中间的内容作为HashTag。若花括号中不包含任何内容则会对整个key进行散列，如`{}user:`。

HashTag可能会使过多的key分配到同一个slot中，造成数据倾斜影响系统的吞吐量，务必谨慎使用。

**通信机制**

集群元数据的维护有两种方式：集中式、Gossip 协议。

redis cluster 节点间采用 Gossip 协议进行通信。

**集中式：**

将集群元数据（节点信息、故障等等）集中存储在某个节点上。集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。

![x](http://121.196.182.26:6100/public/images/redis-cluster2.png)

集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。

**Gossip协议**

redis 维护集群元数据采用 Gossip 协议：所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。

其好处在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上执行，降低了压力；缺点在于元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000。每个节点每隔一段时间都会往其他节点发送 ping 消息，接收到 ping 之后节点会返回 pong。

交换信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。

**Gossip消息**

Gossip 协议包含多种消息：

- meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信：redis-trib.rb add-node，其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。
- ping：每个节点都会频繁给其它节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。
- pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。
- fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。

其中 ping 消息会携带一些元数据，如果很频繁，可能会加重网络负担：

- 每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。

  当然如果发现某个节点通信延时达到了 cluster_node_timeout / 2，那么立即发送 ping，避免数据交换延时过长（比如两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题）。

  cluster_node_timeout 如果调得比较大会降低 ping 的频率。

- 每次 ping 会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。

  至少包含 3 个其它节点的信息，最多包含 **总节点数减 2** 个其它节点的信息。

**数据分片（寻址）：**

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

| 分布方式 | 描述                                                         | 特点                                                       | 典型产品                  |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------------- | ------------------------- |
| 顺序分布 | 把 id 按顺序平均地划分到不同区间，对应的数据分配到不同的实例中 | 数据分散度易倾斜，键值业务相关，可顺序访问，支持批量操作   | BigTable<br>HBase         |
| 哈希分布 | 使用 CRC32 哈希函数将键转换为 hash 值，所得 hash 值取模分配到不同实例中 | 业务分散度高，键值分布业务无关，无法顺序访问，支持批量操作 | MemCache<br>Redis Cluster |

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点；典型代表为ShardedJedis
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上；典型代表为Codis
- 服务器分片：客户端与集群中任意的节点通信，服务端计算 key 在哪一个节点上，若不在当前节点上则通知客户端应访问的节点。典型代表为官方推出的Redis Cluster。

单机版的Redis中单条指令的执行总是原子性的，在集群中则难以保证这一性质，某些指令可能无法在集群中使用或者受到限制。

若需要使用这些指令或需要它们保持原子性，可以采用单机版Redis和集群搭配使用的方法。将主要业务部署在集群上，将需要较多支持的服务部署在单机版Redis上。

**哈希取模**

对于客户端请求的 key，会首先计算 hash 值，然后对节点数取模，分配到不同的 master 节点上。这种做法最简单，但存在以下问题：

- 节点伸缩：数据节点关系变化会导致数据迁移（迁移数量和添加节点数量有关，建议翻倍扩容）；
- 缓存失效：加入某一 master 节点宕机，所有请求过来都会基于最新的剩余可用节点数取模、尝试去取数据。这会导致大部分无法命中缓存的请求流量涌入数据库。

**一致性哈希**

一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。

对于客户端请求的 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针移动，遇到的第一个 master 节点就是 key 所在位置。

在一致性哈希算法中增删一个节点受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响（保证节点伸缩、数据迁移受影响范围最小）。

但同样会有问题：一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。可以通过引入虚拟节点机制解决：即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。

- 客户端分片：hash + 优化取余
- 节点伸缩：只影响邻近节点，不需要整体上做数据迁移
- 翻倍伸缩：保证最小迁移数据和负载均衡

**虚拟槽**

哈希槽(hash slot)是来自Redis Cluster的概念, 但在各种集群方案都有使用。

redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。

每个 master 都会持有部分 slot（比如有 3 个 master，可能每个 master 持有 5000 多个 hash slot）。因此节点的增加和移除很简单：只需要在 master 之间移动 hash slot 即可，移动成本是非常低的。

客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。如果任何一台机器宕机，另外两个节点不受影响。因为 key 找的是 hash slot 不是机器。

![x](http://121.196.182.26:6100/public/images/redis-cluster3.png)

以有三个节点的集群为例:

- 节点A包含0到5500号哈希槽
- 节点B包含5501到11000号哈希槽
- 节点C包含11001到16384号哈希槽

这样的设计有利于对集群进行横向伸缩，若要添加或移除节点只需要将该节点上的槽转移到其它节点即可。

在某些集群方案中，涉及多个key的操作会被限制在一个 slot 中，如 Redis Cluster 中的 mget/mset 操作。

**高可用原理**

redis cluster 的高可用的原理，几乎跟哨兵是类似的，直接集成了 replication 和 sentinel 的功能。

**判断节点宕机**

分为主观宕机和客观宕机：

- 主观宕机（pfail）：即一个节点认为另外一个节点宕机。在 cluster-node-timeout 内，某个节点一直没有返回 pong，那么就被认为 pfail。
- 客观宕机（fail）：即多个节点都认为另外一个节点宕机。如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中提示给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。

**从节点过滤**

- 对宕机的 master node，从其所有的 slave node 中选择一个切换成 master node；
- 判断标准：检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout * cluster-slave-validity-factor，就没有资格切换成 master。

**从节点选举**

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。

#### 

### 5. Redis为什么那么快？

1. **基于内存实现**：数据都存储在内存里，相比磁盘IO操作快百倍，操作速率很快。

2. **高效的数据结构**：Redis底层多种数据结构支持不同的数据类型，比如HyperLogLog它连2个字节都不想浪费。

3. **丰富而合理的编码**：Redis底层提供了 [丰富而合理的编码](https://mp.weixin.qq.com/s?__biz=MzIzNzk1NTU2Mg==&mid=2247486037&idx=1&sn=0f5507a683ffab4f8dcd8f947e473cf6&scene=21#wechat_redirect) ，五种数据类型根据长度及元素的个数适配不同的编码格式。

   - String：自动存储int类型，非int类型用raw编码。
   - List：字符串长度且元素个数小于一定范围使用 **ziplist** 编码，否则转化为 **linkedlist** 编码。
   - Hash：hash 对象保存的键值对内的键和值字符串长度小于一定值及键值对。
   - Set：保存元素为整数及元素个数小于一定范围使用 intset 编码，任意条件不满足，则使用 **hashtable** 编码。
   - Zset：保存的元素个数小于定值且成员长度小于定值使用 **ziplist** 编码，任意条件不满足，则使用 **skiplist** 编码。

4. **合适的线程模型**：`I/O 多路复用`模型同时监听客户端连接，多线程是需要上下文切换的，对于内存数据库来说这点很致命。

   ![x](D:/WorkingDir/Office/Resources/st040.png)

5. Redis6.0后引入多线程提速：

   要知道 读写网络的read/write系统耗时 `>>` Redis运行执行耗时，Redis的瓶颈主要在于**网络的 IO 消耗**, 优化主要有两个方向：

   1、提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式 

   2、使用多线程充分利用多核，典型的实现比如 Memcached。

   协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以Redis支持多线程主要就是两个原因：

   1、可以充分利用服务器 CPU 资源，目前主线程只能利用一个核

   2、多线程任务可以分摊 Redis 同步 IO 读写负荷

   关于多线程须知：

   1. Redis 6.0 版本 默认多线程是关闭的 io-threads-do-reads no
   2. Redis 6.0 版本 开启多线程后 线程数也要 谨慎设置。
   3. 多线程可以使得性能翻倍，但是多线程只是用来处理网络数据的读写和协议解析，**执行命令仍然是单线程顺序执行**。



### API网关

#### 1. 为什么需要API网关？

微服务下一个系统被拆分为多个服务，但是像安全认证，流量控制，日志，监控等功能是每个服务都需要的，没有网关的话，我们就需要在每个服务中单独实现，这使得我们做了很多重复的事情并且没有一个全局的视图来统一管理这些功能。

综上：**一般情况下，网关一般都会提供请求转发、安全认证（身份/权限认证）、流量控制、负载均衡、容灾、日志、监控这些功能。**

上面介绍了这么多功能实际上网关主要做了一件事情：**请求过滤** 。权限校验、流量控制这些都可以通过过滤器实现，请求转发是通过过滤器实现的。



### 代理模式

参考：https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/basis/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3.md

**定义**

为其他对象提供一种代理以控制对这个对象的访问。

代理模式也叫做委托模式，它是一项基本设计技巧。许多其他的模式，如状态模式、策略模式、访问者模式本质上是在更特殊的场合采用了委托模式，而且在日常的应用中，代理模式可以提供非常好的访问控制。在一些著名开源软件中也经常见到它的身影，如 Struts2 的 Form 元素映射就采用了代理模式（准确地说是动态代理模式）。

代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。

**类图**

![x](E:/WorkingDir/Office/Resources/design_pattern_39.png)

我们先看一下类图中的三个角色的定义：

- Subject抽象主题角色：抽象主题类可以是抽象类也可以是接口，是一个最普通的业务类型定义，无特殊要求。

- RealSubject具体主题角色：也叫做被委托角色、被代理角色。它才是冤大头，是业务逻辑的具体执行者。

- Proxy代理主题角色：也叫做委托类、代理类。它负责对真实角色的应用，把所有抽象主题类定义的方放限制委托给真实主题角色实现，并且在真实主题角色处理完毕前后做预处理和善后处理工作。

一个代理类可以代理多个被委托者或被代理者，因此一个代理类具体代理哪个真实主题角色，是由场景类决定的。当然，最简单的情况就是一个主题类和一个代理类，这是最简洁的代理模式。在通常情况下，一个接口只需要一个代理类就可以了，具体代理哪个实现类由高层模块来决定，也就是在代理类的构造函数中传递被代理者。

**特点**

- 职责清晰：真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后期的代理完成其它事务，附带的结果就是编程简洁清晰。

- 高扩展性：具体主题角色是随时都会发生变化的，只要它实现了接口，甭管它如何变化，都逃不脱如来佛的手掌（接口），那我们的代理类完全就可以在不做任何修改的情况下使用。

- 智能化：Struts是如何把表单元素映射到对象上的示例

**使用场景**

为什么要用代理？想想现实世界，打官司为什么要找个律师？因为你不想参与中间过程的是是非非，只要完成自己的答辩就成，其他的比如事前调查、事后追查都由律师来搞定，这就是为了减轻你的负担。代理模式的使用场景非常多，大家可以看看Spring AOP，这是一个非常典型的动态代理。

**扩展**

在网络上代理服务器设置分为透明代理和普通代理，是什么意思呢？透明代理就是用户不用设置代理服务器地址，就可以直接访问，也就是说代理服务器对用户来说是透明的，不用知道它存在的，普通代理则是需要用户自己设置代理服务器的IP地址，用户必须知道代理的存在。

我们设计模式中的普通代理和强制代理也是类似的一种结构，普通代理就是我们要知道代理的存在，也就是类似的GamePlayerProxy这个类的存在，然后才能访问，强制代理则是调用者直接调用真实角色，而不用关心代理是否存在，其代理的产生是由真实角色决定的。

**普通代理**

它的要求就是客户端只能访问代理角色，而不能访问真实角色，这是比较简单的。

![x](E:/WorkingDir/Office/Resources/design_pattern_40.png)

在该模式下，调用者只知代理而不用知道真实的角色是谁，屏蔽了真实角色的变更对高层模块的影响，真实的主题角色想怎么修改就怎么修改，对高层次的模块没有任何的影响，只要你实现了接口所对应的方法，该模式非常适合对扩展性要求较高的场合。当然，在实际的项目中，一般都是通过约定来禁止new一个真实的角色，这也是一个非常好的方案。

> **注意**：普通代理模式的约束问题，尽量通过团队内的编程规范类约束，因为每一个主题类是可被重用的和可维护的，使用技术约束的方式对系统维护是一种非常不利的因素。

**强制代理（静态代理）**

只有通过真实角色指定的代理类才可以访问，也就是说由真实角色管理代理角色。这么说吧，高层模块new了一个真实角色的对象，返回的却是代理角色。

![x](E:/WorkingDir/Office/Resources/design_pattern_41.png)

强制代理的概念就是要从真实角色查找到代理角色，不允许直接访问真实角色。高层模块只要调用getProxy就可以访问真实角色的所有方法，它根本就不需要产生一个代理出来，代理的管理已经由真实角色自己完成。

静态代理实现步骤:

1. 定义一个接口及其实现类；
2. 创建一个代理类同样实现这个接口
3. 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。

> **点评：**实际应用场景非常非常少，日常开发几乎看不到使用静态代理的场景。

代码展示：

```java
// 1. 定义发送短信的接口
public interface SmsService {
    String send(String message);
}

// 2. 实现发送短信的接口
public class SmsServiceImpl implements SmsService {
    public String send(String message) {
        System.out.println("send message:" + message);
        return message;
    }
}

// 3. 创建代理类并同样实现发送短信的接口
public class SmsProxy implements SmsService {

    private final SmsService smsService;

    public SmsProxy(SmsService smsService) {
        this.smsService = smsService;
    }

    @Override
    public String send(String message) {
        // 调用方法之前，我们可以添加自己的操作
        System.out.println("before method send()");
        smsService.send(message);
        // 调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method send()");
        return null;
    }
}

// 4. 场景使用
public class Main {
    public static void main(String[] args) {
        SmsService smsService = new SmsServiceImpl();
        SmsProxy smsProxy = new SmsProxy(smsService);
        smsProxy.send("java");
    }
}
```

**个性代理**

一个类可以实现多个接口，完成不同任务的整合。也就是说代理类不仅仅可以实现主题接口，也可以实现其他接口完成不同的任务，而且代理的目的是在目标对象方法的基础上作增强，这种增强的本质通常就是对目标对象的方法进行拦截和过滤。

![x](E:/WorkingDir/Office/Resources/design_pattern_42.png)

代理类不仅仅是可以有自己的运算方法，通常的情况下代理的职责并不一定单一，它可以组合其他的真实角色，也可以实现自己的职责，比如计算费用。代理类可以为真实角色预处理消息、过滤消息、消息转发、事后处理消息等功能。当然一个代理类，可以代理多个真实角色，并且真实角色之间可以有耦合关系。

**虚拟代理**

在需要使用的时候才初始化主题对象（不在代理类的构造函数中初始化），可以避免被代理对象较多而引起的初始化缓慢的问题。其缺点是需要在每个方法中判断主题对象是否被创建，这就是虚拟代理，非常简单。

以下是一个虚拟代理的实现，模拟了图片延迟加载的情况下使用与图片大小相等的临时内容去替换原始图片，直到图片加载完成才将图片显示出来。

```java
public interface Image {
    void showImage();
}

public class HighResolutionImage implements Image {
    private URL imageURL;
    private long startTime;
    private int height;
    private int width;

    public int getHeight() {
        return height;
    }
    
    public int getWidth() {
        return width;
    }
    
    public HighResolutionImage(URL imageURL) {
        this.imageURL = imageURL;
        this.startTime = System.currentTimeMillis();
        this.width = 600;
        this.height = 600;
    }
    
    public boolean isLoad() {
        // 模拟图片加载，延迟 3s 加载完成
        long endTime = System.currentTimeMillis();
        return endTime - startTime > 3000;
    }
    
    @Override
    public void showImage() {
        System.out.println("Real Image: " + imageURL);
    }

}

public class ImageProxy implements Image {
    private HighResolutionImage highResolutionImage;

    public ImageProxy(HighResolutionImage highResolutionImage) {
        this.highResolutionImage = highResolutionImage;
    }
    
    @Override
    public void showImage() {
        while (!highResolutionImage.isLoad()) {
            try {
                System.out.println("Temp Image: " + highResolutionImage.getWidth() + " " + highResolutionImage.getHeight());
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        highResolutionImage.showImage();
    }

}

public class ImageViewer {
    public static void main(String[] args) throws Exception {
        String image = "http://image.jpg";
        URL url = new URL(image);
        HighResolutionImage highResolutionImage = new HighResolutionImage(url);
        ImageProxy imageProxy = new ImageProxy(highResolutionImage);
        imageProxy.showImage();
    }
}
```

**动态代理**

![x](E:/WorkingDir/Office/Resources/design_pattern_43.png)

动态代理是在实现阶段不用关心代理谁，而在运行阶段才指定代理哪一个对象。现在有一个非常流行的名称叫做面向横切面编程，也就是AOP(Aspect Oriented Programming)，其核心就是采用了动态代理机制。

在类图中增加了一个InvocationHanlder接口和GamePlayIH类，作用就是产生一个对象的代理对象，其中InvocationHandler是JDK提供的动态代理接口，对被代理类的方法进行代理。

通用动态代理模型，很简单，两条独立发展的线路。动态代理实现代理的职责，业务逻辑Subject实现相关的逻辑功能，两者之间没有必然的相互耦合的关系。通知Advice从另一个切面切人，最终在高层模块也就是Client进行耦合，完成逻辑的封装任务。

![x](E:/WorkingDir/Office/Resources/design_pattern_44.png)

动态代理调用过程示意图

![x](E:/WorkingDir/Office/Resources/design_pattern_45.png)

动态代理的主要意图就是解决我们常说的“审计”问题，也就是横切面编程，在不改变我们已有代码结构的情况下增强或控制对象的行为。

要实现动态代理的首要条件是：被代理类必须实现一个接口，回想一下前面的分析吧。当然了，现在也有很多技术如CGLIB可以实现，不需要接口也可以实现，动态代理的方式。

**从 JVM 角度来说，动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。**

**动态代理在我们日常开发中使用的相对较少，但是在框架中的几乎是必用的一门技术。学会了动态代理之后，对于我们理解和学习各种框架的原理也非常有帮助。**

就 Java 来说，动态代理的实现方式有很多种，比如 **JDK 动态代理**、**CGLIB 动态代理**等等。

[guide-rpc-framework](https://github.com/Snailclimb/guide-rpc-framework) 使用的是 JDK 动态代理，我们先来看看 JDK 动态代理的使用。

另外，虽然 [guide-rpc-framework](https://github.com/Snailclimb/guide-rpc-framework) 没有用到 **CGLIB 动态代理 **，我们这里还是简单介绍一下其使用以及和JDK 动态代理的对比。

**在 Java 动态代理机制中 `InvocationHandler` 接口和 `Proxy` 类是核心。**

`Proxy` 类中使用频率最高的方法是：`newProxyInstance()` ，这个方法主要用来生成一个代理对象。

```java
public static Object newProxyInstance(ClassLoader loader,
                                          Class<?>[] interfaces,
                                          InvocationHandler h)
        throws IllegalArgumentException
    {
        ......
    }
```

这个方法一共有 3 个参数：

1. **loader**: 类加载器，用于加载代理对象。
2. **interfaces**: 被代理类实现的一些接口；
3. **h**: 实现了 `InvocationHandler` 接口的对象；

要实现动态代理的话，还必须实现`InvocationHandler` 来自定义处理逻辑。当我们的动态代理对象调用一个方法时候，这个方法的调用就会被转发到实现`InvocationHandler` 接口类的 `invoke` 方法来调用。



`invoke()` 方法有下面三个参数：

1. **proxy** :动态生成的代理类
2. **method** : 与代理类对象调用的方法相对应
3. **args** : 当前 method 方法的参数

也就是说：**你通过`Proxy` 类的 `newProxyInstance()` 创建的代理对象在调用方法的时候，实际会调用到实现`InvocationHandler` 接口的类的 `invoke()`方法。** 你可以在 `invoke()` 方法中自定义处理逻辑，比如在方法执行前后做什么事情。

```java
public interface InvocationHandler {

    /**
     * 当你使用代理对象调用方法的时候实际会调用到这个方法
     */
    public Object invoke(Object proxy, Method method, Object[] args)
        throws Throwable;
}
```

**JDK 动态代理类使用步骤：**

1. 定义一个接口及其实现类；
2. 自定义 `InvocationHandler` 并重写`invoke`方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；
3. 通过 `Proxy.newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)` 方法创建代理对象；

代码示例

```java
// 1.定义发送短信的接口
public interface SmsService {
    String send(String message);
}

// 2.实现发送短信的接口
public class SmsServiceImpl implements SmsService {
    public String send(String message) {
        System.out.println("send message:" + message);
        return message;
    }
}

// 3.定义一个 JDK 动态代理类
public class DebugInvocationHandler implements InvocationHandler {
    /**
     * 代理类中的真实对象
     */
    private final Object target;

    public DebugInvocationHandler(Object target) {
        this.target = target;
    }

    /**
     * invoke() 方法: 当我们的动态代理对象调用原生方法的时候，最终实际上调用到的是 invoke() 方法，
     * 然后 invoke() 方法代替我们去调用了被代理对象的原生方法。
     */
    public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException {
        // 调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object result = method.invoke(target, args);
        // 调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return result;
    }
}

// 4.获取代理对象的工厂类
public class JdkProxyFactory {
    /**
     * getProxy() ：主要通过Proxy.newProxyInstance（）方法获取某个类的代理对象
     */
    public static Object getProxy(Object target) {
        return Proxy.newProxyInstance(
                target.getClass().getClassLoader(), // 目标类的类加载
                target.getClass().getInterfaces(),  // 代理需要实现的接口，可指定多个
                new DebugInvocationHandler(target)   // 代理对象对应的自定义 InvocationHandler
        );
    }
}

// 5.实际使用
SmsService smsService = (SmsService) JdkProxyFactory.getProxy(new SmsServiceImpl());
smsService.send("java");
```

JDK 动态代理有一个最致命的问题是其**只能代理实现了接口的类**。为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。

[CGLIB](https://github.com/cglib/cglib)(*Code Generation Library*)是一个基于[ASM](http://www.baeldung.com/java-asm)的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了[CGLIB](https://github.com/cglib/cglib)， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。

在 CGLIB 动态代理机制中 `MethodInterceptor` 接口和 `Enhancer` 类是核心。

你需要自定义 `MethodInterceptor` 并重写 `intercept` 方法，`intercept` 用于拦截增强被代理类的方法。

```java
public interface MethodInterceptor
extends Callback{
    // 拦截被代理类中的方法
    public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args,
                               MethodProxy proxy) throws Throwable;
}
```

1. **obj**: 被代理的对象（需要增强的对象）
2. **method**: 被拦截的方法（需要增强的方法）
3. **args**: 方法入参
4. **methodProxy**: 用于调用原始方法

你可以通过 `Enhancer`类来动态获取被代理类，当代理类调用方法的时候，实际调用的是 `MethodInterceptor` 中的 `intercept` 方法。

**CGLIB 动态代理类使用步骤：**

1. 定义一个类；
2. 自定义 `MethodInterceptor` 并重写 `intercept` 方法，`intercept` 用于拦截增强被代理类的方法，和 JDK 动态代理中的 `invoke` 方法类似；
3. 通过 `Enhancer` 类的 `create()`创建代理类；

代码示例：

首先添加依赖：

```xml
<dependency>
  <groupId>cglib</groupId>
  <artifactId>cglib</artifactId>
  <version>3.3.0</version>
</dependency>
```

java代码：

```java
// 1.实现一个使用阿里云发送短信的类
public class AliSmsService {
    public String send(String message) {
        System.out.println("send message:" + message);
        return message;
    }
}

// 2.自定义 MethodInterceptor（方法拦截器）
public class DebugMethodInterceptor implements MethodInterceptor {
    /**
     * @param o           被代理的对象（需要增强的对象）
     * @param method      被拦截的方法（需要增强的方法）
     * @param args        方法入参
     * @param methodProxy 用于调用原始方法
     */
    @Override
    public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
        // 调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object object = methodProxy.invokeSuper(o, args);
        // 调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return object;
    }
}

// 3.获取代理类
public class CglibProxyFactory {
    public static Object getProxy(Class<?> clazz) {
        // 创建动态代理增强类
        Enhancer enhancer = new Enhancer();
        // 设置类加载器
        enhancer.setClassLoader(clazz.getClassLoader());
        // 设置被代理类
        enhancer.setSuperclass(clazz);
        // 设置方法拦截器
        enhancer.setCallback(new DebugMethodInterceptor());
        // 创建代理类
        return enhancer.create();
    }
}

// 4.实际使用
AliSmsService aliSmsService = (AliSmsService) CglibProxyFactory.getProxy(AliSmsService.class);
aliSmsService.send("java");
```

**JDK 动态代理和 CGLIB 动态代理对比**

1. **JDK 动态代理只能只能代理实现了接口的类，而 CGLIB 可以代理未实现任何接口的类。**另外，CGLIB动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
2. 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。

**静态代理和动态代理的对比**

1. **灵活性** ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
2. **JVM 层面** ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

**最佳实践**

有了AOP大家写代理就更加简单了，有类似Spring AOP和AspectJ这样非常优秀的工具，拿来主义即可！在学习AOP框架时，弄清楚几个名词：切面(Aspect)、切入点(JoinPoint)、通知(Advice)、织入(Weave)。

**总结：**

1. 代理模式实现类图
2. 静态代理和动态代理的对比
3. JDK 动态代理和 cglib 动态代理的对比



### 消费者模式





### JS闭包

#### 1. 什么是闭包

函数执行后返回结果是一个内部函数，并被外部变量所引用，如果内部函数持有被执行函数作用域的变量，即形成了闭包。

可以在内部函数访问到外部函数作用域。使用闭包，一可以读取函数中的变量，二可以将函数中的变量存储在内存中，保护变量不被污染。而正因闭包会把函数中的变量值存储在内存中，会对内存有消耗，所以不能滥用闭包，否则会影响网页性能，造成内存泄漏。当不需要使用闭包时，要及时释放内存，可将内层函数对象的变量赋值为null。

#### 2. 闭包原理

函数执行分成两个阶段(预编译阶段和执行阶段)。

- 在预编译阶段，如果发现内部函数使用了外部函数的变量，则会在内存中创建一个“闭包”对象并保存对应变量值，如果已存在“闭包”，则只需要增加对应属性值即可。
- 执行完后，函数执行上下文会被销毁，函数对“闭包”对象的引用也会被销毁，但其内部函数还持用该“闭包”的引用，所以内部函数可以继续使用“外部函数”中的变量

利用了函数作用域链的特性，一个函数内部定义的函数会将包含外部函数的活动对象添加到它的作用域链中，函数执行完毕，其执行作用域链销毁，但因内部函数的作用域链仍然在引用这个活动对象，所以其活动对象不会被销毁，直到内部函数被烧毁后才被销毁。

#### 3. 优点

1. 可以从内部函数访问外部函数的作用域中的变量，且访问到的变量长期驻扎在内存中，可供之后使用
2. 避免变量污染全局
3. 把变量存到独立的作用域，作为私有成员存在

#### 4. 缺点

1. 对内存消耗有负面影响。因内部函数保存了对外部变量的引用，导致无法被垃圾回收，增大内存使用量，所以使用不当会导致内存泄漏
2. 对处理速度具有负面影响。闭包的层级决定了引用的外部变量在查找时经过的作用域链长度
3. 可能获取到意外的值(captured value)

#### 5. 应用场景

**应用场景一：** 典型应用是模块封装，在各模块规范出现之前，都是用这样的方式防止变量污染全局。

```js
var Yideng = (function () {
    // 这样声明为模块私有变量，外界无法直接访问
    var foo = 0;

    function Yideng() {}
    Yideng.prototype.bar = function bar() {
        return foo;
    };
    return Yideng;
}());
```

**应用场景二：** 在循环中创建闭包，防止取到意外的值。如下代码，无论哪个元素触发事件，都会弹出 3。因为函数执行后引用的 i 是同一个，而 i 在循环结束后就是 3

```js
for (var i = 0; i < 3; i++) {
    document.getElementById('id' + i).onfocus = function() {
      alert(i);
    };
}
// 可用闭包解决
function makeCallback(num) {
  return function() {
    alert(num);
  };
}
for (var i = 0; i < 3; i++) {
    document.getElementById('id' + i).onfocus = makeCallback(i);
}
```



### .NET多线程

#### 实现异步3种方式

**1. 异步模式**

```c#
/// 异步模式
/// </summary>
/// <param name="start"></param>
/// <param name="num"></param>
/// <returns></returns>
public void SumAsyncPattern(int start, int num)
{
    Func<int> BeginGetNum = () =>
    {
        int result = start;
        // 耗时操作
        for (int i = 0; i < 9; i++)
        {
            Thread.Sleep(1000);
            result += num;
        }
        return result;
    };

    Action<int> EndGetNum = result => Console.WriteLine(result);

    /**
     * <summary>
     * BeginInvoke的参数说明：
     * </summary>
     * <param name="">AsyncCallback类型的委托，需要IAsyncResult作为参数，当异步方法执行完成后，将调用这个委托引用的方法</param>
     * <see cref="AsyncCallback"/>
     * <see cref="IAsyncResult"/>
     */
    BeginGetNum.BeginInvoke(_ =>
    {
        int result = BeginGetNum.EndInvoke(_);
        EndGetNum.Invoke(result);
    }, null);
}
```

**2. 基于事件的异步模式**

```C#
public void SumAsyncEventPattern(int start, int num)
{
    BackgroundWorker bgWorker = new BackgroundWorker();

    bgWorker.RunWorkerCompleted += (sender, e) =>
    {
         Console.WriteLine(e.Result);
    };

    bgWorker.DoWork += (sender, e) =>
    {
        int result = start;
        // 耗时操作
        for (int i = 0; i < 9; i++)
        {
            Thread.Sleep(1000);
            result += num;
        }
        e.Result = result;
    };

    bgWorker.RunWorkerAsync();
}
```

**3. 基于任务的异步模式**

```C#
public async void SumTaskBasedAsyncPattern(int start, int num)
{
    int result = start;
    await Task.Run(() =>
    {
        for (int i = 0; i < 9; i++)
        {
            Thread.Sleep(1000);
            result += num;
        }
    });
    Console.WriteLine(result);
}
```

#### 线程

在 .NET4 之前，必须直接使用 **Thread** 类和 **ThreadPool** 类编写线程。现在 .NET 对这两个类做了抽象，允许使用 **Parallel** 类和 **Task** 类。

数据并行：Parallel.For和Parallel.ForEach

任务并行：Parallel.Invoke

#### 问题

**1. 争用条件**

如果两个或多个线程访问相同的对象，并且对共享**状态**的访问没有同步，就会出现争用条件。

**解决方法：**

1、要避免争用条件，可以**锁定**共享的对象。这可以在线程中完成。

2、将共享对象设置为线程安全的对象。

**2. 死锁**

至少有两个线程被挂起，并等待对方解除锁定。由于两个线程都在等待对方，就出现了死锁，线程将无限等待下去。

死锁问题并不总是这么明显。

一个线程锁定了s1，接着锁定s2；另一个线程锁定了s2，接着锁定s1。

在上例中只需要改变锁定顺序，这两个线程就会以相同的顺序进行锁定。但是，锁定可能隐藏在方法的深处。

为了避免这个问题，可以在应用程序的体系架构中，从一开始就设计好**锁定顺序**，也可以为锁定定义**超时时间**。

#### 同步

lock、Interlocked、Monitor可用于进程内部的同步；Mutex、Event、Semaphore、ReadWriterLockSlim提供了多个进程之间的线程同步。

- Interlocked只能用于简单的同步问题，用于使变量的简单语句原子化，修改后再将它存储回内存。
- Monitor与使用 lock 关键字基本上是一样的，lock 语句由 C# 编译器解析为使用 Monitor 类。
- SpinLock：.NET 4 引入。如果有大量的锁定（例如，列表中的每个节点都有一个锁定），且锁定的时间总是非常短，SpinLock结构就很有用
- WaitHandle：一个抽象基类，用于等待一个信号的设置，可以等待不同的信号。Mutex、EventWaitHandle 和 Semapbore 类派生自 WaitHandle 基类
- Mutex（mutual exclusion，互斥）似于Monitor类，都只有一个线程能拥有锁定。
- Semapbore信号量同步限制了访问同一共享资源的**线程数量**。类似于互斥，其区别是，信号量可以同时由多个线程使用。信号量是一种**计数**的互斥锁定。
- Event事件同步能够通知其他线程执行指定操作（AutoResetEvent、ManualResetEvent、WaitHandle），和基于委托的event关键字没有关系

 

### 如何设计一个高并发系统？

参考：https://mp.weixin.qq.com/s?__biz=MzAwNTMxMzg1MA==&mid=2654082209&idx=1&sn=2fbf4808eca543af1b711a264027ada2&chksm=80d830f4b7afb9e2e4ccd6988b013db3de03199ef83cb2a7e6b9186f4dafdeb2ce708cb8b896&mpshare=1&scene=23&srcid=0105O42X9TtQqomxwbLQSbaA&sharer_sharetime=1609806821943&sharer_shareid=83c85f3c4ddf8afec618435580a94a3e#rd
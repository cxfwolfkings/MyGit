# 消息队列

- [1. 为什么要使用消息队列？](#1. 为什么要使用消息队列？)

- [2. 各种消息队列产品的比较？](#2. 各种消息队列产品的比较？)

- [3. 消息队列的优点和缺点？](#3. 消息队列的优点和缺点？)

- [4. 如何保证消息队列的高可用性？](#4. 如何保证消息队列的高可用性？)

- [5. 如何保证消息不丢失？](#5. 如何保证消息不丢失？)

- [6. 如何保证消息不被重复消费？](#6. 如何保证消息不被重复消费？)

- [7. 如何保证消息的顺序性？](#7. 如何保证消息的顺序性？)

- [8. 大量消息堆积怎么办？](#8. 大量消息堆积怎么办？)

- [9. 消息过期怎么处理？](#9. 消息过期怎么处理？)

参考：

1. https://blog.csdn.net/weixin_39265427/article/details/107418735
2. https://www.cnblogs.com/zz-ksw/p/12302431.html
3. https://gitbook.cn/gitchat/activity/5e83fbf2f784144a11628723

特性：先进先出

#### 1. 为什么要使用消息队列？

消息队列的应用场景，核心3项：**解耦**、**异步**、**削峰**。

**解耦：**

![x](D:/WorkingDir/Office/Resources/tbms0042.png)

![x](D:/WorkingDir/Office/Resources/tbms0043.png)

**异步：**

![x](D:/WorkingDir/Office/Resources/tbms0044.png)

![x](D:/WorkingDir/Office/Resources/tbms0045.png)

**削峰：**

![x](D:/WorkingDir/Office/Resources/tbms0046.png)

#### 2. 各种消息队列产品的比较？

| 特性                    | activeMQ                                                   | rabbitMQ                       | rocketMQ                                                     | kafka                                             |
| ----------------------- | ---------------------------------------------------------- | ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |
| 并发语言                | java                                                       | erlang                         | java                                                         | scale                                             |
| 单机吞吐量              | 万级                                                       | 万级                           | 十万级                                                       | 十万级                                            |
| 时效性                  | ms                                                         | us（延迟最低）                 | ms                                                           | ms以内                                            |
| 可用性                  | 高（主从模式）                                             | 高（主从模式）                 | 非常高（集群模式）                                           | 非常高（集群模式）                                |
| 功能特性                | 成熟的产品，在很多公司得到应用，有较多的文档，各种协议支持 | 并发性很强，性能极好，延时很低 | 功能比较完备，扩展性佳                                       | 只支持一些主要的mq功能，在大数据领域使用非常广    |
| topic数量对吞吐量的影响 |                                                            |                                | topic可以达到几百/几千级别，吞吐量会有小幅度下降（一大优势，同等机器下支持大量topic） | topic从几十到几百个的时候，吞吐量大幅度下降。同等 |

**MQ选型总结**

1. activeMQ：早期使用较多，没经过大规模吞吐量场景验证，社区不是很活跃，现在使用的不多，不推荐
2. RabbitMQ：开发语言使用erlang，对于java开发工程师二次开发门槛较高，但rabbitMQ是开源的，社区活跃度较高，追求性能和稳定性的话，推荐使用。
3. 开发语言是java，在阿里内部经受过高并发的考验，稳定性和性能均不错，若考虑二次开发，推荐使用。
4. kafka：大数据领域的实时计算、日志采集等场景，用kafka是业内标准，社区活跃，推荐使用。

#### 3. 消息队列的优点和缺点？

优点：解耦、异步、流量削峰

缺点：系统可用性降低、系统复杂性提高、一致性问题

![x](D:/WorkingDir/Office/Resources/tbms0047.png)

#### 4. 如何保证消息队列的高可用性？

**rabbitMQ**

- 普通集群模式：在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

  点评：没有做到真正的高可用；数据拉取开销和单实例的瓶颈问题。

![x](D:/WorkingDir/Office/Resources/tbms0031.png)

- 镜像集群模式

![x](D:/WorkingDir/Office/Resources/tbms0032.png)

RabbitMQ 有很好的管理控制台，在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去。

优点：任何一个机器宕机，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。

缺点：

1. 性能开销太大。消息需要同步到所有机器上，导致网络带宽压力和消耗很重！
2. 不是分布式，没有扩展性可言。如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？

**rocketMQ**

- 双主双从

![x](D:/WorkingDir/Office/Resources/tbms0033.png)

**Kafka**

Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。

这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。

Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。

Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

![x](D:/WorkingDir/Office/Resources/tbms0048.png)

![x](D:/WorkingDir/Office/Resources/tbms0049.png)

这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。

写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

#### 5. 如何保证消息不丢失？

**消息丢失的原因**

- 消息生产者没有成功发送到MQ broker
- 消息发送到mq broker后，broker宕机导致内存中的消息数据丢失
- 消费者消费了消息，但是没有处理完毕就发生异常导致消息丢失。

![x](D:/WorkingDir/Office/Resources/tbms0034.png)

**确保消息不丢失方案**

- 发送方可靠发送
- mq进行消息持久化
- 消费放完成消费后进行ack确认，mq收到ack确认再删除本地消息

![x](D:/WorkingDir/Office/Resources/tbms0035.png)

#### 6. 如何保证消息不被重复消费？

> 即保证消息的幂等性。重复消息产生的根本原因：**网络不可达**

发送时消息重复

![x](D:/WorkingDir/Office/Resources/tbms0036.png)

消费时消息重复

![x](D:/WorkingDir/Office/Resources/tbms0037.png)

**解决消息重复发送问题——消息幂等性**

- 消息发送者发送消息时携带一个全局唯一的消息id
- 消费者获取消费后先根据id在db/redis查询消息是否成功消费
- 如果没有消费过直接消费，消费完成后写入db/redis
- 如果消费过则不予处理

#### 7. 如何保证消息的顺序性？

**全局顺序消费**：生产者：MQ：消费者 = 1：1：1

**局部顺序消费**

- 生产者根据消息id将同一组消息发送到一个queue中
- 多个消费者同时获取queue中的消息进行消费
- mq使用分段锁保证单个queue中的有序消费

![x](D:/WorkingDir/Office/Resources/tbms0038.png)

#### 8. 大量消息堆积怎么办？

**消息堆积的原因：**

- 网络故障
- 消费方处理消息后没有给mq broker正常应答

**消息堆积的处理方案**

- 检查并修复消费方的正常消费速度
- 将堆积的消息转存到容量更大的mq集群
- 增加多个消费者节点并行消费堆积消息
- 消费完毕后，回复原始架构

![x](D:/WorkingDir/Office/Resources/tbms0039.png)

#### 9. 消息过期怎么处理？

**消息过期的原因**

给消息设置了过期时间，如果超时还未被消费，则视为消息过期。过期消息可以转存到死信队列。

![x](D:/WorkingDir/Office/Resources/tbms0040.png)

**消息过期的处理方案**

- 过期消息进入到死信队列
- 启动专门的消费者消费死信队列消息，并写入数据库记录日志
- 查询数据库消息日志，重新发送消息到mq

![x](D:/WorkingDir/Office/Resources/tbms0041.png)





（1）点对点&多订阅（因为不删消息，所以这两种就不区分了）。发布者生产一条消息到topic中，不同订阅组消费此消息。

![x](D:/WorkingDir/Office/Resources/tbms0014.png)

 

对于消费者而言有两种方式从消息中间件获取消息：

① Push方式：由消息中间件主动地将消息推送给消费者；

② Pull方式：由消费者主动向消息中间件拉取消息。

比较：

- 采用Push方式，可以尽可能快地将消息发送给消费者(stream messages to consumers as fast as possible)

- 而采用Pull方式，会增加消息的延迟，即消息到达消费者的时间有点长(adds significant latency per message)。

但是，Push方式会有一个坏处：

如果消费者的处理消息的能力很弱（一条消息需要很长的时间处理），而消息中间件不断地向消费者Push消息，消费者的缓冲区可能会溢出。

ActiveMQ是怎么解决这个问题的呢？那就是[**prefetch limit**](http://activemq.apache.org/what-is-the-prefetch-limit-for.html)

prefetch limit 规定了一次可以向消费者Push（推送）多少条消息。

当推送消息的数量到达了perfetch limit规定的数值时，消费者还没有向消息中间件返回ACK，消息中间件将不再继续向消费者推送消息。

prefetch limit设置的大小根据场景而定：

如果消息的数量很少（生产者生产消息的速率不快），但是每条消息 消费者需要很长的时间处理，那么prefetch limit设置为1比较合适。

这样，消费者每次只会收到一条消息，当它处理完这条消息之后，向消息中间件发送ACK，此时消息中间件再向消费者推送下一条消息。

prefetch limit 设置成0意味着什么？意味着变成 拉pull模式。

push都要设置prefetch。

另外，对于prefetch模式，那么消费需要进行响应ACK。因为服务器需要知道consumer消费的情况。

perfetch limit是“消息预取”的值，这是针对消息中间件如何向消费者发消息 而设置的。

与之相关的还有针对 消费者以何种方式向消息中间件返回确认ACK（响应）：

比如消费者是每次消费一条消息之后就向消息中间件确认呢？还是采用“延迟确认”---即采用批量确认的方式（消费了若干条消息之后，统一再发ACK）。

如果prefetchACK为true，那么prefetch必须大于0；当prefetchACK为false时，你可以指定prefetch为0以及任意大小的正数。

不过，当prefetch=0是，表示consumer将使用PULL（拉取）的方式从broker端获取消息，broker端将不会主动push消息给client端，直到client端发送PullCommand时；

当prefetch>0时，就开启了broker push模式，此后只要当client端消费且ACK了一定的消息之后，会立即push给client端多条消息。

#### 可靠性

**发送端的可靠性**

发送端完成操作后一定能将消息成功发送到消息队列中。

实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。

**接收端的可靠性**

接收端能够从消息队列成功消费一次消息。

两种实现方法：

- 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。

- 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。


好，现在开始。

今天我讲的主题，是消息队列，Message Queue。

我打算分8个小主题由浅入深，逐步介绍：

第1节：MQ简介，主要概述一下我们的系统中为什么需要引入MQ系统，以及MQ相关的基本概念。

第2节：简易MQ实现，为了更好的理解MQ概念，自己实现一款简易阉割版的消息队列。

第3节：常用MQ架构，讲解现在比较流行的两种消息队列Kafka和RabbitMQ的基本架构，以及对应的高可用实现。

第4节：MQ图形化管理，图形化管理大大方便了我们在开发运维过程中的查询和调试，所以简要介绍下Kafka和RabbitMQ的比较好用的图形化工具。

第5节：C# 常用MQ API，介绍在 .NET 环境下流行的MQ客户端包，以及简单使用。

第6节：MQ对比选型，对比几个常用的MQ系统，并介绍它们更适合的使用场景

第7节：介绍一下MQ中的常见问题，包含消息可靠性、重复消费问题等等

第8节：稍微讲一下EDA，以及基于RabbitMQ的实现

下面开始第一节：首先我们的系统中为什么需要MQ？

想象一个较为通用的注册流程，我们将注册信息提交到后端接口时，后端接口一般会做这么几歩处理：首先，将注册信息写入数据库，然后发送注册邮件，接着再发送注册信息，最后返回处理的结果。这是典型的同步处理接口，一个串行链，接口总的处理时间就是链条上所有处理节点的耗时之和。

如果我们在后台系统中引入MQ，情况就变成了这样：首先我们还是将注册信息写入数据库，原始业务数据的持久化，我们一般还是同步为好；保存成功后我们给MQ推送一条注册消息，然后后端接口就可以直接返回了。至于邮件通知、消息通知这些额外的操作，可以通过订阅MQ中的注册消息来实现。这其实就是异步处理，MQ可以方便我们进行异步处理。可以看到，此时后端接口能够更快地进行响应，性能得到了提升。

但是，如果只是异步处理，我们直接通过代码就可以实现，引入了MQ反而增加了系统复杂度，所以异步是MQ的一个特性，但是并不是我们引入它的必要条件！

接着看：假设有一个订单管理的功能，我们可以在订单中选择各种需要的商品，订单创建完，调用后台接口，首先要在订单系统中创建一个订单，然后要调用库存系统的接口，将订单选择的商品标识为已使用。这两个系统之间就发生了耦合，彼此之间有了强关联，增加了接口调用的风险。如果在两个系统之间引入MQ，它们之间就无需知道对方的存在，也杜绝了彼此之间的直接调用，隔离即安全！因此应用解耦是MQ的第二个功能。为了解耦，已经有足够的理由引入MQ，但是，这是开发层面的一个要求，关乎于代码质量，对于使用层面的性能、稳定性来讲，似乎没什么影响，那么引入MQ的因由何在呢？

个人认为MQ最重要的一个使用场景：流量削峰。最典型的应用场景：春节抢票、双11秒杀。后端系统的性能瓶颈大多在数据库，比如说MySQL，支持的并发连接数在千这个数量级。同一时间内过多的请求，会给数据库造成很大压力，达到瓶颈后响应速度大大减慢甚至会宕机。MQ正是为这种场景而生的，一般MQ的单机吞吐量至少都能达到万级，其次还可以通过集群的方式扩展以应对更高的并发量；通过MQ的限流，到达DB端的请求就可以控制在一个平稳的范围内，保证整个系统的稳定运行。

总结一下，MQ，最主要的使用场景就是：异步处理、应用解耦和流量削峰。这也是系统中为什么需要引入MQ的原因。

一般的MQ都实现了发布订阅模式，一个消息可以有多个订阅者，看上去就像是一个人把消息发给了多个人，因此消息分发是对MQ功能的一个直观阐述，当然也是一个使用的场景。

使用MQ前，首先要了解一些基本的概念：

生产者： “生产” 消息

消费者： “消费” 消息。

连接（Connection）：主要表示生产者/消费者与消息代理建立的 TCP 连接。

MQ 通过 “信道”（Channel）构建 “连接” 的多路复用：信道是逻辑层面的连接管道，共享 “连接”，又相互独立，MQ的任何通信，都属于 “信道” 层面的通信。

MQ的服务端称为Broker，一般称为服务代理，其实Broker就是接收和分发消息的应用。在Broker中包含交换器和队列。

交换器exchange：负责接收来自生产者的消息，将消息路由到队列中。交换器最关键的属性是路由规则，也就是绑定哪些队列。

队列Queue，绑定到交换器，接收来自交换器分发的消息，供消费者读取。

其中贯穿始终的就是消息Message：它的基本结构有两部分：Header和Body。Header是一堆属性，包括：路由键（交换器路由消息的 “依据”，也就是将消息投递到哪个队列）；投递模式（是否 “持久化”）。当然，为了达成消息的 “持久化”，消息、交换器、队列，必须全部 “持久化”。

整个核心流程，如图所示：消息由 “生产者”（producer / publisher）通过 “消息代理”（broker）传递到 “消费者”（consumer），具体而言：

- 消息由 “生产者” 发布到 “交换器”（exchange）；
- “交换器” 根据 “绑定”（binding），将消息路由（分发）到队列（queue）；
- “消费者” 获取 “队列” 中的消息进行处理。

为了理解这些概念，我们通过一个极简的MQ系统的工作流程来讲解。

首先，看一下类图：上面的两个类模拟的是消息代理Broker的功能，也就是服务端进程。其中，BrokerServer中的Run方法，代表服务进程启动，正在运行中，可以让客户端连接。Broker中的messageQueue代表了队列的概念，就是消息在服务端的存储位置。这里面省略了交换器。

下面的两个类代表，生产者和消费者的客户端，分别实现了发布消息和处理消息的方法。

整个工作过程如图所示：首先，消息代理服务端启动，然后消费者客户端连接到Broker进行监听，此处的连接就是Connection，忽略信道。接着如果生产者想要发送消息，就打开与broker的连接，将消息发送过去，Broker按顺序将消息存进Queue中（当然，这里的简易MQ忽略了交换器，真实情况是Producer将消息发送给Broker上的交换器exchange，exchange根据message上的路由规则将消息分发到对应的绑定的队列中）。如果消费者订阅的正是当前队列，MQ就将消息取出来，发送给消费者进行处理。

好，演示一下代码：服务端本质上就是开启了一个TCP接口，接听各种请求；接下来启动消费者客户端，模拟消息订阅的功能；启动生产者客户端，发送几个消息做测试。

我们看一下消费者，它订阅了消息，所以现在可以用指令进行消费。

现在我们大致了解了MQ的各个概念，下面看一下常用的两种MQ（Kafka和RabbitMQ）的基础架构。

这是RabbitMQ的基础架构图形，了解了刚才的基本概念后，这个架构图就变得一目了然了。

Publisher生产者，Consumer消费者，Connection物理连接，Channel逻辑信道，Broker消息代理，内部有交换机Exchange和队列Queue。刚才唯一没有介绍到的就是这个：虚拟主机Virtual Host。这是RabbitMQ中独有的一个逻辑分区，一个 Broker 可以有多个虚拟主机，用作不同用户的权限分离，一个虚拟主机持有一组 Exchange、Queue。

刚才说到了权限分离，RabbitMQ是怎么实现的呢？通过不同的用户绑定不同的虚拟主机权限，如图所示：3个用户分别绑定了3个不同的虚拟主机，因此它们就只能操作各自虚拟主机内的交换机和队列，算是在逻辑上实现了隔离。

我们关注物理架构，一般有几个基本的质量属性，比如性能、伸缩性、灵活性、复用性等，其中最基本的是可用性，高可用是实现其它质量要求的基础，如果用都不能用，其它就无从谈起。而要实现高可用，归根结底，其实就是靠集群，人多力量大，多个节点组成逻辑上的组，以整体的形式对外提供服务，组内某个节点挂了，整体对外的服务不受影响。

那么，我们看一下RabbitMQ中的高可用架构：RabbitMQ提供了两种集群部署方式：普通集群模式和镜像集群模式。

普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。我们创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。消费的时候，如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

这种方式麻烦，也不怎么好，就是个普通集群。因为这导致消费者每次连接一个实例后经常要从其它实例拉取数据，有数据拉取的开销。而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法拉取。当然如果你开启了消息持久化，让消息存储到物理介质上的话，消息不一定会丢，但是得等这个实例恢复了，才可以继续从这个 queue 拉取数据。

所以这就没有什么高可用性了，这个方案主要是用来提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。

镜像集群模式，才是 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 中。

那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

这样的好处在于，你任何一个机器宕机了，没事儿，其它节点还包含了这个 queue 的完整数据，consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销太大，消息需要同步到指定机器上，导致网络带宽消耗很重！第二，这其实不是分布式，没有扩展性可言，因为，如果某个 queue 负载很重，加机器，新增的机器也是包含这个 queue 的所有数据，所以没有办法线性扩展。如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳，此时RabbitMQ就没办法了？

相对的，Kafka就是一个天然的分布式消息队列，因此它有一些独有的概念：

Topic：主题的意思，Kafka 规定每个消息都应该有个主题，Topic 可以理解为对消息的一个分类，比如用户注册使用一个 Topic，用户删除应该使用另外一个 Topic。Broker 和 Topic 没有包含的含义，一个 Broker 下面可以存在多个 Topic 的消息，而一个 Topic 的消息可以保存在一个或者多个 Broker 中。

Partition：分区，每个Partition都是一个有序的队列，Partition中每条消息都会被分配一个有序的Id（offset）。创建 Topic 时，可以指定 Partition 数，一个 Topic 至少有一个 Partition，kafka 在接收到生产者发送的消息之后，会根据 Partition机制将消息并行的存储到不同Partition中，这样就提高了吞吐量。

Group：消费者组。每个 Consumer 可以指定一个 Group Name，相同 Group Name 的 Consumer 视为一个 Group。在开发过程中，同一 Group Name 的 Consumer 应该实现相同功能！如果 不指定，那么它属于默认Group。Consumer 以 Group 的形式从 Topic 中获取消息进行消费，准确说是从某个 Partition 中获取消息进行消费。一个 Group 下会有一个或者多个 Consumer，而 Partition 中的每个消息只会被同一 Group（中的某一个 Consumer）消费一次，因此如果想要多个 Consumer 都可以对同一个消息进行消费，需要设置将它们设置在不同的组中。

Offset：偏移，偏移是 Partition 对 Consumer Group 而言的，当某个 Consumer 成功消费消息之后，Kafka 会标记该 Consumer 对应的 Group 对于此 Partition 的 Offset 加1，也就是偏移一个单位，因此这个 Group 下的其他 Consumer 就不会重复消费这个消息了。

Replication：Topic 的副本，一个 Topic 可以有多个副本，一个 Topic 下有多个 Partition，每个 Partition 在每个副本中有对应的副本，因为 Topic 的副本之间需要保持数据的一致性，所以这些 Partition 之间也就形成Leader-Follower结构，Kafka中，对于数据的读写操作都在 Leader 上，Follower只是当 Leader 挂了后用来重新选取 Leader，Follower 并不向外提供服务。

kafka基本架构如图所示，从这个相对宏观的视角来看，它和RabbitMQ区别不大，都是生产者，消费者和消息代理，只是引入了Zookeeper用来管理集群。下面从broker的视角进入，

我们可以看到其中的Partition，也可以认为是queue。主题topic1的消息被分散在两个Partition上，这两个Partition又都有自己的Replication，形成主从结构。其中broker1上的Partition1被选举为leader，其它两个broker中对应Topic的Partition1就是Follower。我们的读写都是通过leader进行，如果leader挂了，Zookeeper会根据一定的策略在副本中选举一个作为新的leader。

因此，Kafka 提供的高可用机制，就是副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。

为什么只能读写 leader？因为，如果可以随意读写每个 follower，那么就要解决数据一致性的问题，副本越多，系统的复杂度也越高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的broker上，提高容错性。这就是它的高可用性架构。

下面分别看一下Kafka和RabbitMQ的图形化管理工具。

Kafka的工具是这款：Offset Explorer，偏移资源管理器，名字起得很随意，不过功能还行。既可以看到kafka的基本结构，也能watch到Partition中的消息，最重要的是可以造数据。

RabbitMQ的图形化管理工具是官方提供的，功能齐全，开发、运维、监控都能hold住，基本上是不做其它选择。

接下来就是代码环节了，这边主要介绍下Kafka和RabbitMQ的两个较为常用的客户端以及使用。

首先Kafka，使用的nuget包是confluent-kafka-dotnet，它主要包含5部分，安装命令看文档。我们使用这个客户端时，基本的类图结构如图所示：它使用了建造者模式，通过建造者类来生成客户端实例。生产者类主要提供了Produce方法来发布消息，消费者类则通过Subscribe方法来订阅主题，使用Consume方法来消费其中的一条消息。

RabbitMQ使用的nuget包是RabbitMQ.Client，从类图可以看出来，它使用工厂模式来生成客户端实例，这个实例代表的就是Channel的意思，它没有区分生产者和消费者，而是通过Channel开放了绑定、发布、消费一篮子方法，让用户自己调用。

我们演示代码：

RabbitMQ 支持的交换器类型，主要包括：direct、fanout、topic、header。

direct 交换器的工作机制：

- 队列以绑定键 B 绑定到 direct 交换器；
- 消息（路由键 R）发送到 direct 交换器，若 `B == R`，消息即进入队列。

fanout 交换器将消息路由到所有绑定的队列。类似于 “广播”。

topic 交换器与 direct 交换器类似，基于消息路由键与队列绑定键进行匹配。区别在于，topic 交换器支持 “通配符” 形式的 “绑定键”：

- “键” 以 `.` 划分成多个词
- `*` 匹配任意 1 个词
- `#` 匹配 0 到多个词

例如：`gitchat.rmq.example_1` 与 `*.rmq.example_1` 和 `gitchat.#` 匹配。

header交换器与 direct 交换器类似，区别在于，header不依赖于消息路由键与队列绑定键的匹配，而是依赖于消息和绑定的 “headers” 匹配。

具体的匹配规则，依赖绑定的 “headers” 支持 `x-match` 属性：

- `all`：默认值，当且仅当，消息 “headers” 与绑定 “headers”，全部 K-V 匹配
- `any`：消息 “headers” 中任意 K-V，都能够与绑定 “headers” 匹配

需要说明，“headers” 中，若以 `x-` 作为前缀，则不参与匹配计算。

路由模式：队列名direct1，direct2，路由同名

发布订阅模式：队列名fanout1，fanout2；

主题模式：队列名topic1，topic2，路由topic1.#，topic2.#



下面我们对比一下常见的消息队列并看一下该如何选型：从这张表格我们可以看出来，RabbitMQ的优势在于性能，协议支持的也多；RocketMQ的单机吞吐量最大，毕竟是阿里开发，接受过大规模吞吐量的验证；Kafka的单机吞吐量也很优秀，能达到10万级别。

在.NET环境下，首先排除ActiveMQ和RocketMQ。ActiveMQ现在几乎已经是被抛弃的状态，RocketMQ没有官方支持的.NET客户端。在吞吐量要求不太高，没有大规模的消息请求需要处理的时候，RabbitMQ是个好选择，消息延迟最短，web管理界面功能齐全，因为不是真正意义上的分布式，所以理解起来也相对容易些。当然，就和文档上介绍的一样，在大数据领域的实时计算、日志采集等场景下，kafka就是业内标准，RabbitMQ的伪分布式是hold不住这样的场景的。

在使用MQ时，会遇到一些常见的问题，我这里总结了一下，主要是这5个：

1. 高可用架构
2. 可靠性保障
3. 不重复消费
4. 顺序处理
5. 堆积处理

如何保证消息不丢，可靠传输？

数据的丢失问题，可能出现在生产者、MQ、消费者中。

先从 RabbitMQ 来分析：

生产者丢数据

生产者将数据发送到 RabbitMQ 的时候，可能因为网络问题，数据在半路就丢了。此时可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 broker 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。

但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量就会下降，因为太耗性能。

所以一般来说，如果要确保写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉生产者这个消息接收失败，可以重试。而且生产者可以结合这个机制在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，就可以重发。

事务机制和 confirm 机制最大的不同在于，事务机制是同步的，提交一个事务之后会阻塞，但是 confirm 机制是异步的，发送消息之后就可以发送下一个消息。

所以一般在生产者这块避免数据丢失，都是用 confirm 机制的。

RabbitMQ丢数据

就是 RabbitMQ 自己弄丢了数据，这个必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。

设置持久化有两个步骤：

创建 queue 的时候将其设置为持久化 这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。

第二个是发送消息的时候将消息的 deliveryMode 设置为 2 就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

这两个持久化必须要同时设置才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

那光开启 RabbitMQ 持久化机制，能保证消息不丢吗？有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

所以，持久化要跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才通知生产者 ack 了，这样的话哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。

消费者丢数据，主要是因为消费的时候，刚拿到数据，还没处理，结果进程挂了，比如重启了，那么就尴尬了，如果RabbitMQ 认为你消费了，这数据就丢了。

这个时候要用 RabbitMQ 提供的 ack 机制，简单来说，就是必须关闭 RabbitMQ 的自动 ack，通过一个 api 来手动调用就行。每次自己代码处理完的时候，在程序里 ack 一下。这样的话，只要没处理完，就不会 ack ？RabbitMQ 会认为这个消费者还没处理完，这个时候 RabbitMQ 不会把这个消费删掉。

Kakfa如何保证消息的可靠

Kafka丢数据

这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？。

所以此时一般是要求起码设置4 个参数：

1. 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
2. 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower。
3. 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
4. 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。

这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。

生产者丢数据

如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

消费者丢数据

唯一可能导致消费者弄丢数据的情况，就是，消费到了这个消息，然后消费者那边自动提交了 offset，让 Kafka 以为已经消费好了这个消息，但其实消费者才刚准备处理这个消息，还没处理好，自己就挂了，此时这条消息就算丢咯。

这跟 RabbitMQ 其实差不多，因为Kafka 会自动提交 offset，那么只要关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好。

如何保证消息不重复消费（幂等性）？

首先，所有的消息队列都会有重复消费的问题，因为这不是MQ来保证，而是开发者保证的，我们使用Kakfa来讨论。

Kakfa有个offset的概念，就是每个消息写进去都会有一个offset值，代表消费的序号，然后consumer消费了数据之后，默认每隔一段时间会把自己消费过的消息的offset值提交，表示已经消费过了，下次要是重启，就从当前提交的offset处来继续消费。

但是凡事总有意外，比如重启系统时，直接暴力 kill 进程，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset。重启之后，少数消息会再次消费一次。

其实重复消费不可怕，确保对应的数据是正确处理就行，这就要保证消息队列消费的幂等性？

其实还是得结合业务来思考：

1. 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，就别插入了，update 一下就好。
2. 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。

比如不是上面两个场景，那就稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，然后消费过了之后，就将该id对应的处理状态保存起来，保证不重复处理相同的消息即可。

如何保证消息的顺序性？

先看看顺序会错乱的俩场景：

RabbitMQ：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这就明显乱了。

Kafka：比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，消费者里可能会生成多个线程来并发处理消息，而并发，就会打乱顺序。

RabbitMQ解决方案：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，麻烦点。

Kafka解决方案：

一个 topic，一个 partition，一个 consumer，内部单线程消费，但是单线程吞吐量太低，一般不会用这个。

consumer 中 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

如何处理消息推积？

大量消息在 mq 里积压了几个小时了还没解决

一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。

一般这个时候，只能临时紧急扩容，网上的操作步骤和思路如下：

1. 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
2. 新建一个 topic，partition 是原来的 10 倍，也就是临时建立好原先 10 倍的 queue 数量。
3. 然后写一个临时的分发数据的程序，这个程序部署上去消费积压的数据，消费之后不做任何耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
4. 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。

等快速消费完积压数据之后，再恢复原先部署的架构。

最后，稍微介绍下基于MQ的EDA，事件总线是对观察者（发布-订阅）模式的一种实现，它是一种集中式事件处理机制，允许不同的组件之间进行彼此通信而又不需要相互依赖，达到一种解耦的目的。消息队列天生就是实现事件总线的好工具，尤其是RabbitMQ，它的客户端库其实已经引入了EventBus的思想。

OK，我这边对消息队列的讲解就全部结束了。


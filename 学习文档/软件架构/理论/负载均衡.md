# 负载均衡

**分布式设计**

 

**扩展性设计**

 

[**稳定性** **&** **高可用**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#稳定性--高可用)

 

 

 

**负载均衡**

对于数据流量过大的网络中，往往单一设备无法承担，需要多台设备进行数据分流，而负载均衡器就是用来将数据分流到多台设备的一个转发器。

[**负载均衡**](http://network.51cto.com/art/201101/241997.htm)**（****Load Balance****），其意思就是将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。**

在实际应用中，在Web服务器集群之前总会有一台负载均衡服务器，负载均衡设备的任务就是作为Web服务器流量的入口，挑选最合适的一台Web服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。最近几年很火的「云计算」以及分布式架构，本质上也是将后端服务器作为计算资源、存储资源，由某台管理服务器封装成一个服务对外提供，客户端不需要关心真正提供服务的是哪台机器，在它看来，就好像它面对的是一台拥有近乎无限能力的服务器，而本质上，真正提供服务的，是后端的集群。

目前有许多不同的负载均衡技术用以满足不同的应用需求，如软/硬件负载均衡、本地/全局负载均衡、更高网络层负载均衡，以及链路聚合技术。

这里就简单介绍下软负载均衡技术、硬负载均衡器：

**软件负载均衡**

在一台服务器的[操作系统](http://lib.csdn.net/base/operatingsystem)上，安装一个附加软件来实现负载均衡，如Nginx负载均衡。它的优点是基于特定环境、配置简单、使用灵活、成本低廉，可以满足大部分的负载均衡需求。

**LVS**

平时我们说的LVS是Linux Virtual Server。这当然是基于Linux的开源软件了，这就意味着它是免费的。它基本上能支持所有应用，因为lvs工作在4层，所以它可以对几乎所有应用做 负载均衡，包括http、数据库、聊天室等等。同时，若跟硬件负载均衡相比它的缺点也不容忽视，LVS要求技术水平很高，操作上也比较复杂，配置也很繁琐，没有赖以保障的服务支持，稳定性来说也相对较低（人为和网络环境因素更多一些）。

 

**Nginx**

Nginx ("engine x") 是一个高性能的 **HTTP** 和 **反向代理** 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。 可以说Nginx 是目前使用最为广泛的HTTP软负载均衡器，其将源代码以类BSD许可证的形式发布（商业友好），同时因高效的性能、稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名于业界。像腾讯、淘宝、新浪等大型门户及商业网站都采用Nginx进行HTTP网站的数据分流。

Nginx的功能特点

1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构；

2、Nginx对网络的依赖比较小；

3、Nginx安装和配置比较简单，[测试](http://lib.csdn.net/base/softwaretest)起来比较方便；

4、也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发；

5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，www.linuxidc.com 并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；

6、Nginx对请求的异步处理可以帮助节点服务器减轻负载；

7、Nginx能支持http和Email，这样就在适用范围上面小很多；

8、不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡[算法](http://lib.csdn.net/base/datastructure)。

Nginx的原理

Nginx采用的是反向代理技术，代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。

**HAProxy**

使用HAProxy的人非常少，对其了解的也不多。通过官方的了解，HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理（据说是可以工作在4-7层的）。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上。

**HAProxy****用法详解：**http://www.ttlsa.com/linux/haproxy-study-tutorial/

**Haproxy+Keepalived+MySQL****实现读均衡负载：**http://blog.itpub.net/25704976/viewspace-1319781/

 

**硬件负载均衡**

直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器。由于专门的设备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。 一般而言，硬件负载均衡在功能、性能上优于软件方式，不过成本昂贵，比如最常见的就是F5负载均衡器。

**F5 BIG-IP**

F5负载均衡器是应用交付网络的全球领导者F5 Networks公司提供的一个负载均衡器专用设备，F5 BIG-IP LTM 的官方名称叫做本地流量管理器，可以做4-7层负载均衡，具有负载均衡、应用交换、会话交换、状态监控、智能网络地址转换、通用持续性、响应错误处理、IPv6网关、高级路由、智能端口镜像、SSL加速、智能HTTP压缩、TCP优化、第7层速率整形、内容缓冲、内容转换、连接加速、高速缓存、Cookie加密、选择性内容加密、应用攻击过滤、拒绝服务(DoS)攻击和SYN Flood保护、防火墙—包过滤、包消毒等功能。

以下是F5 BIG-IP用作HTTP负载均衡器的主要功能：

　　1、F5 BIG-IP提供12种灵活的算法将所有流量均衡的分配到各个服务器，而面对用户，只是一台虚拟服务器。

　　2、F5 BIG-IP可以确认应用程序能否对请求返回对应的数据。假如F5 BIG-IP后面的某一台服务器发生服务停止、死机等故障，F5会检查出来并将该服务器标识为宕机，从而不将用户的访问请求传送到该台发生故障的服务器上。这样，只要其它的服务器正常，用户的访问就不会受到影响。宕机一旦修复，F5 BIG-IP就会自动查证应用已能对客户请求作出正确响应并恢复向该服务器传送。

　　3、F5 BIG-IP具有动态Session的会话保持功能。

4、F5 BIG-IP的iRules功能可以做HTTP内容过滤，根据不同的域名、URL，将访问请求传送到不同的服务器。

**思科**

思科几乎每个IOS路由器都具有负载均衡功能。这是非常令人激动的，因为我们不必去添加额外的硬件产品，基于现有设备，只需要添加负载均衡规则就可以了。思科是路由器领域的老大，当然负载均衡功能只是其原因中的一个。

思科的IOS包括很多负载均衡功能，比如端口绑定，会话交换，TCP优化，NAT和服务器负载均衡器算法，等等。

思科的服务非常到位，在国外，不少技术人员都说，如果你购买了思科的产品就永远不会被公司解雇。

**Radware****的****AppDirector****系列**

Radware的AppDirector (AD)在服务器负载均衡应用方面可以做到本地的服务器负载均衡(AD)和广域的全局服务器负载均衡(AD -Global)。它的单价比较便宜，并具有高扩展性和智能化服务。同时也拥有网络监控和检测功能，全局负载均衡和缓解一定的DDoS攻击等。

另外，Radware设备还有一些特点是比较容易更新和升级，能够感知应用服务，智能化是其宣传的理念之一，也是这个产品的一大特色。

**梭子鱼负载均衡**

梭子鱼的负载均衡器的最大特点是包含了网络安全功能。它具有入侵防御功能，而不是单单检测入侵。这能够更全面地保护你的网络，即使你错过了一个关键的更新和漏洞的修补，梭子鱼的更新服务也能让你的系统自动地更新起来。

此外，梭子鱼的负载均衡也是Web界面操作的，全局负载以及内容缓存也是它的显著特点。

**方案优缺点对比**

基于硬件的方式(F5)

优点：能够直接通过智能交换机实现，处理能力更强，而且与系统无关，负载性能强更适用于一大堆设备、大访问量、简单应用

缺点：成本高，除设备价格高昂，而且配置冗余．很难想象后面服务器做一个集群，但最关键的负载均衡设备却是单点配置；无法有效掌握服务器及应用状态.

硬件负载均衡，一般都不管实际系统与应用的状态，而只是从网络层来判断，所以有时候系统处理能力已经不行了，但网络可能还来 得及反应（这种情况非常典型，比如应用服务器后面内存已经占用很多，但还没有彻底不行，如果网络传输量不大就未必在网络层能反映出来）

基于软件的方式(Nginx)

优点：基于系统与应用的负载均衡，能够更好地根据系统与应用的状况来分配负载。这对于复杂应用是很重要的，性价比高，实际上如果几台服务器，用F5之类的硬件产品显得有些浪费，而用软件就要合算得多，因为服务器同时还可以跑应用做集群等。

缺点：负载能力受服务器本身性能的影响，性能越好，负载能力越大。

综述：对我们管理系统应用环境来说，由于负载均衡器本身不需要对数据进行处理，性能瓶颈更多的是在于后台服务器，通常采用软负载均衡器已非常够用且其商业友好的软件源码授权使得我们可以非常灵活的设计，无缝的和我们管理系统平台相结合。

[**负载均衡算法**](https://www.cnblogs.com/tianzhiliang/articles/2317808.html)

本地流量管理技术主要有以下几种负载均衡算法：

静态负载均衡算法包括：轮询，比率，优先权

动态负载均衡算法包括: 最少连接数，最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

**静态负载均衡算法**

轮询（Round Robin）：顺序循环将请求一次，顺序循环地连接每个服务器。当其中某个服务器发生第2到第7层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。

比率（Ratio）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第2到第7层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

优先权（Priority）：给所有服务器分组，给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。

**动态**[**负载均衡**](http://www.semptian.com/fzjh/)**算法**

最少的连接方式（Least Connection）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第2到第7层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

最快模式（Fastest）：传递连接给那些响应最快的服务器。当其中某个服务器发生第2到第7层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

观察模式（Observed）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第2到第7层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。

预测模式（Predictive）：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。（被BIG-IP进行检测）

动态性能分配(Dynamic Ratio-APM):BIG-IP收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。

动态服务器补充(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。

服务质量(QoS):按不同的优先级对数据流进行分配。

服务类型(ToS): 按不同的服务类型（在Type of Field中标识）[负载均衡](http://www.semptian.com/fzjh/)对数据流进行分配。

规则模式：针对不同的数据流设置导向规则，用户可自行。

[负载均衡](http://www.semptian.com/fzjh/)对应本地的应用交换，大家可以通过对上述负载均衡算法的理解，结合实际的需求来采用合适你的负载均衡算法，我们常用到的一般是最少连接数、最快反应、或者轮询，决定选用那种算法，主要还是要结合实际的需求。

服务器负载均衡算法有很多（持续性的和非持续性的），包括轮循算法、最少连接算法、响应时间算法、散列算法、最少连接失误算法，链路带宽算法等等。此外实际服务器(Real Server)可以被分配不同的加权值来调整被分配的流量。比如性能高的大型服务器可配置较大的加权值，而为性能较低的小型服务器设置较小的加权值。为了避免服务器因过载而崩溃，可为实际服务器指定最大连接阈值来避免该服务器过载。任何服务器可被指定为另一台服务器的备份服务器或溢出服务器，从而进一步保证了应用可用性。  

**非持续性算法（****Non-Persistent****）**

一个客户端的不同的请求可能被分配到一个实际服务组中的不同的实服务器上进行处理。主要有轮循算法、最少连接算法、响应速度算法等。  

－轮循算法（Round Robin）：

说明：每一次来自网络的请求轮流分配给内部中的每台服务器，从1至N然后重新开始。

举例：此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况；  

－最少连接算法（Least Connection）：

说明：客户端的每一次请求服务在服务器停留的时间都可能会有较大的差异，随着工作时间的加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，这样的结果并不会达到真正的负载均衡。最少连接数均衡算法对内部中有负载的每一台服务器都有一个数据记录，记录的内容是当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。

此种[负载均衡](http://www.semptian.com/fzjh/)算法适合长时间处理的请求服务。  

－响应速度算法（Response Time）：

说明：负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。

举例:此种均衡算法能较好地反映服务器的当前运行状态，但最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。  

**持续性算法（****Persistent****）**

从一个特定的客户端发出的请求都被分配到一个实服务组中的同一个实服务器上进行处理。主要包括：

A．基于IP的算法－Persistent IP (pi)

基于用户IP地址来选择服务器。－Hash IP (hi) 

基于用户IP地址的HASH值，来选择服务器－Consistent Hash IP (chi)

B．基于报头/请求的算法－Hash Header (hh)

基于用户请求报中HTTP报头来选择服务器；－Persistent Hostname (ph) 

基于用户请求报中HTTP报头的Hostname的HASH值，来选择服务器；－Persistent URL (pu)

基于对URI Tag 和值的静态对应关系来选择服务器。－SSL Session ID (sslsid)

基于SSL会话ID来选择服务器。

C．基于Cookie的算法－Persistent Cookie (pc) 

选择服务器基于用户请求包用Cookie Name / Value 的静态对应关系； －Hash Cookie (hc) 

选择服务器基于用户请求包用Cookie Name / Value 的Hash 值对应关系；－Insert Cookie (ic)

选择服务器基于[负载均衡](http://www.semptian.com/fzjh/)器 向服务器响应包中插入Cookie；－Re-write Cookie (rc)

选择服务器基于负载均衡器向服务器响应包中重写Cookie值。（必须为重写指定Cookie值的偏移量）

 

[**限流**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#限流)

 

 

[**应用层容灾**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#应用层容灾)

 

 

[**跨机房容灾**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#跨机房容灾)

 

 

[**容灾演练流程**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#容灾演练流程)

 

 

[**平滑启动**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#平滑启动)

 

 

[**数据库扩展**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#数据库扩展)

 

[**读写分离模式**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#读写分离模式)

 

[**分片模式**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#分片模式)

 

[**服务治理**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#服务治理)

 

[**服务注册与发现**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#服务注册与发现)

 

**服务路由控制**

 

[**分布式一致**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#分布式一致)

 

[**CAP** **与** **BASE** **理论**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#cap-与-base-理论)

 

[**分布式锁**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#分布式锁)

 

[**分布式一致性算法**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#分布式一致性算法)

 

**PAXOS**

 

[**Zab**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#zab)

 

**Raft**

 

**Gossip**

 

**两阶段提交、多阶段提交**

 

[**幂等**](https://github.com/xingshaocheng/architect-awesome/blob/master/README.md#幂等)

 

**分布式一致方案**

 

**分布式** **Leader** **节点选举**

 

**TCC(Try/Confirm/Cancel)** **柔性事务**

 

**分布式文件系统**

 

**唯一****ID** **生成**

数据在分片时，典型的是分库分表，就有一个全局ID生成的问题。

单纯的生成全局ID并不是什么难题，但是生成的ID通常要满足分片的一些要求：

1、不能有单点故障。

2、以时间为序，或者ID里包含时间。这样一是可以少一个索引，二是冷热数据容易分离。

3、可以控制ShardingId。比如某一个用户的文章要放在同一个分片内，这样查询效率高，修改也容易。、

4、不要太长，最好64bit。使用long比较好操作，如果是96bit，那就要各种移位相当的不方便，还有可能有些组件不能支持这么大的ID。

**全局唯一****ID**

**一、****twitter** 

  twitter在把存储系统从MySQL迁移到Cassandra的过程中由于Cassandra没有顺序ID生成机制，于是自己开发了一套全局唯一ID生成服务：Snowflake。

  1、41位的时间序列（精确到毫秒，41位的长度可以使用69年）

  2、10位的机器标识（10位的长度最多支持部署1024个节点） 

  3、12位的计数顺序号（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号），最高位是符号位，始终为0。

  优点：高性能，低延迟；独立的应用；按时间有序。缺点：需要独立的开发和部署。

 

 

 

**一致性****Hash****算法**

 

 

 

 

 

 

 
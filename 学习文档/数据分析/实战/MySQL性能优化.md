# MySQL性能优化

1. 引擎优化
2. 语句优化
   - 查看执行计划



### 查看执行计划

**关键字：explain**

expain出来的信息有10列：

- **id**：选择标识符

  SQL执行的顺序的标识。id相同时，执行顺序由上至下；id值越大，优先级越高，越先执行

- **select_type**：表示查询的类型

  1. **SIMPLE**（简单SELECT，不使用UNION或子查询等）
  2. **PRIMARY**（子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY）
  3. **UNION**（UNION中的第二个或后面的SELECT语句）
  4. **DEPENDENT UNION**（UNION中的第二个或后面的SELECT语句，取决于外面的查询）
  5. **UNION RESULT**（UNION的结果，union语句中第二个select开始后面所有select）
  6. **SUBQUERY**（子查询中的第一个SELECT，结果不依赖于外部查询）
  7. **DEPENDENT SUBQUERY**（子查询中的第一个SELECT，依赖于外部查询）
  8. **DERIVED**（派生表的SELECT, FROM子句的子查询）
  9. **UNCACHEABLE SUBQUERY**（一个子查询的结果不能被缓存，必须重新评估外链接的第一行）

- **table**：输出结果集的表

  显示这一步所访问数据库中表名称（显示这一行的数据是关于哪张表的），有时不是真实的表名字，可能是简称，也可能是第几步执行的结果的简称。

- **partitions**：匹配的分区

- **type**：表示表的连接类型

  对表访问方式，表示MySQL在表中找到所需行的方式，又称**访问类型**。

  常用的类型有：ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好）

  - **ALL**：Full Table Scan，MySQL将遍历全表以找到匹配的行

  - **index**：Full Index Scan，index与ALL区别为index类型只遍历索引树

  - **range**：只检索给定范围的行，使用一个索引来选择行

  - **ref**：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

  - **eq_ref**：类似ref，区别在于使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用 primary key 或者 unique key 作为关联条件

  - **const、system**：当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system

  - **NULL**：MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。

- **possible_keys**：表示查询时，可能使用的索引

  指出 MySQL 能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用（该查询可以利用的索引，如果没有任何索引显示 null）

  该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。

  如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询

- **key**：表示实际使用的索引

  key列显示MySQL实际决定使用的键（索引），必然包含在possible_keys中

  如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。

- **key_len**：索引字段的长度

  表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）。不损失精确性的情况下，长度越短越好 

- **ref**：列与索引的比较

  列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

- **rows**：扫描出的行数（估算的行数）

  估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数

- **filtered**：按表条件过滤的行百分比

- **Extra**：执行情况的描述和说明

  该列包含MySQL解决查询的详细信息,有以下几种情况：

  - Using where：不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤
  - Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by
  - Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为**文件排序**
  - Using join buffer：该值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。
  - Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。
  - Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行
  - No tables used：Query语句中使用from dual 或不含任何from子句

**总结：**

- EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况
- EXPLAIN不考虑各种Cache
- EXPLAIN不能显示MySQL在执行查询时所作的优化工作
- 部分统计信息是估算的，并非精确值
- EXPALIN只能解释SELECT操作，其他操作要重写为SELECT后查看执行计划。

通过收集统计信息不可能存在结果

参考：

- https://www.jianshu.com/p/b3f9007be020

- [杰克思勒](http://www.cnblogs.com/tufujie/)

- [数据库链接池终于搞对了，这次直接从100ms优化到3ms](https://www.jianshu.com/p/c26d1ed16bb4)



### 引擎优化

**1. 内存利用方面**

**innodb_buffer_pool_size**

这个是 Innodb 最重要的参数，和 MyISAM 的 key_buffer_size 有相似之处，但也是有差别的。这个参数主要缓存 innodb 表的索引，数据，插入数据时的缓冲。

该参数分配内存的原则：这个参数默认分配只有8M，可以说是非常小的一个值。如果是一个专用DB服务器，那么他可以占到内存的70%-80%。这个参数不能动态更改，所以分配需多考虑。分配过大，会使 Swap 占用过多，致使 Mysql 的查询特慢。如果你的数据比较小，那么可分配是你的 数据大小+10% 左右做为这个参数的值。

例如：数据大小为50M，那么给这个值分配 innodb_buffer_pool_size＝64M

设置方法，在my.cnf文件里：innodb_buffer_pool_size=4G

> 注意：
>
> 在 Mysql5.7 版本之前，调整 innodb_buffer_pool_size 大小必须在 my.cnf 配置里修改，然后重启 mysql 进程才可以生效。
> 如今到了 Mysql5.7 版本，就可以直接动态调整这个参数，方便了很多。
>
> 尤其是在服务器内存增加之后，运维人员不能粗心大意，要记得调大 Innodb_Buffer_Pool_size 这个参数。数据库配置后，要注意检查 Innodb_Buffer_Pool_size 这个参数的设置是否合理
>
> 需要注意的地方：
>
> 在调整 innodb_buffer_pool_size 期间，用户的请求将会阻塞，直到调整完毕，所以请勿在白天调整，在凌晨3-4点低峰期调整。
> 调整时，内部把数据页移动到一个新的位置，单位是块。如果想增加移动的速度，需要调整 innodb_buffer_pool_chunk_size 参数的大小，默认是128M。

**innodb_additional_mem_pool_size**

用来存放 Innodb 的内部目录，这个值不用分配太大，系统可以自动调。通常设置 16Ｍ 够用了，如果表比较多，可以适当的增大。

设置方法，在 my.cnf 文件里：`innodb_additional_mem_pool_size = 16M`

**2. 关于日志方面**

**innodb_log_file_size**

作用：指定在一个日志组中，每个log的大小。结合 innodb_buffer_pool_size 设置其大小，25%-100%。避免不需要的刷新。

> 注意：这个值分配的大小和数据库的写入速度，事务大小，异常重启后的恢复有很大的关系。一般取256M可以兼顾性能和recovery的速度。

分配原则：几个日值成员大小加起来差不多和你的 innodb_buffer_pool_size 相等。上限为每个日值上限大小为4G。一般控制在几个Log文件相加大小在2G以内为佳。具体情况还需要看你的事务大小，数据大小为依据。

说明：这个值分配的大小和数据库的写入速度，事务大小，异常重启后的恢复有很大的关系。

设置方法：在my.cnf文件里：`innodb_log_file_size = 256M`

**innodb_log_files_in_group**

作用：指定你有几个日值组。

分配原则：一般我们可以用2-3个日值组。默认为两个。

设置方法：在my.cnf文件里：
innodb_log_files_in_group=3

innodb_log_buffer_size：
作用：事务在内存中的缓冲，也就是日志缓冲区的大小， 默认设置即可，具有大量事务的可以考虑设置为16M。
如果这个值增长过快，可以适当的增加innodb_log_buffer_size
另外如果你需要处理大理的TEXT，或是BLOB字段，可以考虑增加这个参数的值。
设置方法：在my.cnf文件里：
innodb_log_buffer_size=3M

innodb_flush_logs_at_trx_commit
作用：控制事务的提交方式,也就是控制log的刷新到磁盘的方式。
分配原则：这个参数只有3个值（0，1，2）.默认为1，性能更高的可以设置为0或是2，这样可以适当的减少磁盘IO（但会丢失一秒钟的事务。），游戏库的MySQL建议设置为0。主库请不要更改了。
其中：
0：log buffer中的数据将以每秒一次的频率写入到log file中，且同时会进行文件系统到磁盘的同步操作，但是每个事务的commit并不会触发任何log buffer 到log file的刷新或者文件系统到磁盘的刷新操作；
1：（默认为1）在每次事务提交的时候将logbuffer 中的数据都会写入到log file，同时也会触发文件系统到磁盘的同步；
2：事务提交会触发log buffer 到log file的刷新，但并不会触发磁盘文件系统到磁盘的同步。此外，每秒会有一次文件系统到磁盘同步操作。
说明：
这个参数的设置对Ｉｎｎｏｄｂ的性能有很大的影响，所以在这里给多说明一下。
当这个值为1时：innodb 的事务LOG在每次提交后写入日值文件，并对日值做刷新到磁盘。这个可以做到不丢任何一个事务。
当这个值为2时：在每个提交，日志缓冲被写到文件，但不对日志文件做到磁盘操作的刷新,在对日志文件的刷新在值为2的情况也每秒发生一次。但需要注意的是，由于进程调用方面的问题，并不能保证每秒１００％的发生。从而在性能上是最快的。但操作系统崩溃或掉电才会删除最后一秒的事务。
当这个值为0时：日志缓冲每秒一次地被写到日志文件，并且对日志文件做到磁盘操作的刷新，但是在一个事务提交不做任何操作。mysqld进程的崩溃会删除崩溃前最后一秒的事务。
从以上分析，当这个值不为１时，可以取得较好的性能，但遇到异常会有损失，所以需要根据自已的情况去衡量。
设置方法：在my.cnf文件里：
innodb_flush_logs_at_trx_commit=1

3）文件IO分配，空间占用方面
innodb_file_per_table
作用：使每个Innodb的表，有自已独立的表空间。如删除文件后可以回收那部分空间。默认是关闭的，建议打开（innodb_file_per_table=1）
分配原则：只有使用不使用。但DB还需要有一个公共的表空间。
设置方法：在my.cnf文件里：
innodb_file_per_table=1

innodb_file_io_threads
作用：文件读写IO数，这个参数只在Windows上起作用。在Linux上只会等于4，默认即可！
设置方法：在my.cnf文件里：
innodb_file_io_threads=4

innodb_open_files
作用：限制Innodb能打开的表的数据。
分配原则：这个值默认是300。如果库里的表特别多的情况，可以适当增大为1000。innodb_open_files的大小对InnoDB效率的影响比较小。但是在InnoDBcrash的情况下，innodb_open_files设置过小会影响recovery的效率。所以用InnoDB的时候还是把innodb_open_files放大一些比较合适。
设置方法：在my.cnf文件里：
innodb_open_files=800

innodb_data_file_path
指定表数据和索引存储的空间，可以是一个或者多个文件。最后一个数据文件必须是自动扩充的，也只有最后一个文件允许自动扩充。这样，当空间用完后，自动扩充数据文件就会自动增长（以8MB为单位）以容纳额外的数据。
例如： innodb_data_file_path=/disk1/ibdata1:900M;/disk2/ibdata2:50M:autoextend 两个数据文件放在不同的磁盘上。数据首先放在ibdata1 中，当达到900M以后，数据就放在ibdata2中。
设置方法，在my.cnf文件里：
innodb_data_file_path =ibdata1:1G;ibdata2:1G;ibdata3:1G;ibdata4:1G;ibdata5:1G;ibdata6:1G:autoextend

innodb_data_home_dir
放置表空间数据的目录，默认在mysql的数据目录，设置到和MySQL安装文件不同的分区可以提高性能。
设置方法，在my.cnf文件里：（比如mysql的数据目录是/data/mysql/data，这里可以设置到不通的分区/home/mysql下）
innodb_data_home_dir = /home/mysql

4）其它相关参数（适当的增加table_cache）
这里说明一个比较重要的参数：
innodb_flush_method
作用：Innodb和系统打交道的一个IO模型
分配原则：
Windows不用设置。
linux可以选择：O_DIRECT
直接写入磁盘，禁止系统Cache了
设置方法：在my.cnf文件里：
innodb_flush_method=O_DIRECT

innodb_max_dirty_pages_pct
作用：在buffer pool缓冲中，允许Innodb的脏页的百分比，值在范围1-100,默认为90，建议保持默认。
这个参数的另一个用处：当Innodb的内存分配过大，致使Swap占用严重时，可以适当的减小调整这个值，使达到Swap空间释放出来。建义：这个值最大在90%，最小在15%。太大，缓存中每次更新需要致换数据页太多，太小，放的数据页太小，更新操作太慢。
设置方法：在my.cnf文件里：
innodb_max_dirty_pages_pct＝90
动态更改需要有管理员权限：
set global innodb_max_dirty_pages_pct=50;

innodb_thread_concurrency
同时在Innodb内核中处理的线程数量。建议默认值。
设置方法，在my.cnf文件里：
innodb_thread_concurrency = 16

5）公共参数调优
skip-external-locking
MyISAM存储引擎也同样会使用这个参数，MySQL4.0之后，这个值默认是开启的。
作用是避免MySQL的外部锁定(老版本的MySQL此参数叫做skip-locking)，减少出错几率增强稳定性。建议默认值。
设置方法，在my.cnf文件里：
skip-external-locking

skip-name-resolve
禁止MySQL对外部连接进行DNS解析（默认是关闭此项设置的，即默认解析DNS），使用这一选项可以消除MySQL进行DNS解析的时间。
但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求！如果需要，可以设置此项。
设置方法，在my.cnf文件里：（我这线上mysql数据库中打开了这一设置）
skip-name-resolve

max_connections
设置最大连接（用户）数，每个连接MySQL的用户均算作一个连接，max_connections的默认值为100。此值需要根据具体的连接数峰值设定。
设置方法，在my.cnf文件里：
max_connections = 3000

query_cache_size
查询缓存大小，如果表的改动非常频繁，或者每次查询都不同，查询缓存的结果会减慢系统性能。可以设置为0。
设置方法，在my.cnf文件里：
query_cache_size = 512M

sort_buffer_size
connection级的参数，排序缓存大小。一般设置为2-4MB即可。
设置方法，在my.cnf文件里：
sort_buffer_size = 1024M

read_buffer_size
connection级的参数。一般设置为2-4MB即可。
设置方法，在my.cnf文件里：
read_buffer_size = 1024M

max_allowed_packet
网络包的大小，为避免出现较大的网络包错误，建议设置为16M
设置方法，在my.cnf文件里：
max_allowed_packet = 16M

table_open_cache
当某一连接访问一个表时，MySQL会检查当前已缓存表的数量。如果该表已经在缓存中打开，则会直接访问缓存中的表，以加快查询速度；如果该表未被缓存，则会将当前的表添加进缓存并进行查询。
通过检查峰值时间的状态值Open_tables和Opened_tables，可以决定是否需要增加table_open_cache的值。
如果发现open_tables等于table_open_cache，并且opened_tables在不断增长，那么就需要增加table_open_cache的值;设置为512即可满足需求。
设置方法，在my.cnf文件里：
table_open_cache = 512

myisam_sort_buffer_size
实际上这个myisam_sort_buffer_size参数意义不大，这是个字面上蒙人的参数，它用于ALTER TABLE, OPTIMIZE TABLE, REPAIR TABLE 等命令时需要的内存。默认值即可。
设置方法，在my.cnf文件里：
myisam_sort_buffer_size = 8M

thread_cache_size
线程缓存，如果一个客户端断开连接，这个线程就会被放到thread_cache_size中（缓冲池未满），SHOW STATUS LIKE 'threads%';如果 Threads_created 不断增大，那么当前值设置要改大，改到 Threads_connected 值左右。（通常情况下，这个值改善性能不大），默认8即可
设置方法，在my.cnf文件里：
thread_cache_size = 8

innodb_thread_concurrency
线程并发数，建议设置为CPU内核数*2
设置方法，在my.cnf文件里：
innodb_thread_concurrency = 8

key_buffer_size
仅作用于 MyISAM存储引擎，用来设置用于缓存 MyISAM存储引擎中索引文件的内存区域大小。如果我们有足够的内存，这个缓存区域最好是能够存放下我们所有的 MyISAM 引擎表的所有索引，以尽可能提高性能。不要设置超过可用内存的30%。即使不用MyISAM表，也要设置该值8-64M，用于临时表。
设置方法，在my.cnf文件里：
key_buffer_size = 8M



### SQL优化

SQL优化主要分4个方向：`SQL语句跟索引`、`表结构`、`系统配置`、`硬件`。

总优化思路就是**最大化利用索引**、**尽可能避免全表扫描**、**减少无效数据的查询**：

> 1、减少数据访问：设置`合理的字段类型`，启用压缩，通过索引访问等减少磁盘 IO。
>
> 2、返回更少的数据：只`返回需要`的字段和数据分页处理，减少磁盘 IO 及网络 IO。
>
> 3、减少交互次数：`批量` DML 操作，函数存储等减少数据连接次数。
>
> 4、减少服务器 CPU 开销：**尽量减少数据库排序操作以及全表查询**，减少 CPU 内存占用 。
>
> 5、分表分区：使用`表分区`，可以增加并行操作，更大限度利用 CPU 资源。

**SQL语句优化大致举例**：

> 1、合理建立覆盖索引：可以有效减少回表。
>
> 2、union，or，in都能命中索引，建议使用in 
>
> 3、负向条件(!=、<>、not in、not exists、not like 等) 索引不会使用索引，建议用in。
>
> 4、在列上进行运算或使用函数会使索引失效，从而进行全表扫描 
>
> 5、小心隐式类型转换，原字符串用整型会触发`CAST`函数导致索引失效。原int用字符串则会走索引。
>
> 6、不建议使用%前缀模糊查询。
>
> 7、多表关联查询时，小表在前，大表在后。在 MySQL 中，执行 from 后的表关联查询是从左往右执行的（Oracle 相反），第一张表会涉及到全表扫描。
>
> 8、调整 Where 字句中的连接顺序，MySQL 采用从左往右，自上而下的顺序解析 where 子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。

**SQL调优大致思路**：

1、先用慢查询日志定位具体需要优化的sql 

2、使用 [explain](https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&mid=2247488546&idx=1&sn=732ca84abf572196ddf76597fe096969&scene=21#wechat_redirect) 执行计划查看索引使用情况 

3、重点关注（一般情况下根据这4列就能找到索引问题）：

> 1、key（查看有没有使用索引） 
>
> 2、key_len（查看索引使用是否充分）
>
> 3、type（查看索引类型） 
>
> 4、Extra（查看附加信息：排序、临时表、where条件为false等）

4、根据上1步找出的索引问题优化sql 5、再回到第2步

![x](D:/WorkingDir/GitLabRepo/Architect/学习文档/数据分析/Resources/db004.PNG)

**表结构优化**：

> 1、尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED 。
>
> 2、VARCHAR的长度只分配真正需要的空间 。
>
> 3、尽量使用TIMESTAMP而非DATETIME 。
>
> 4、单表不要有太多字段，建议在20以内。
>
> 5、避免使用NULL字段，很难查询优化且占用额外索引空间。字符串默认为''。

**读写分离**：

> 只在主服务器上写，只在从服务器上读。对应到数据库集群一般都是一主一从、一主多从。业务服务器把需要写的操作都写到主数据库中，读的操作都去从库查询。主库会同步数据到从库保证数据的一致性。一般 [读写分离](https://mp.weixin.qq.com/s?__biz=MzA5NDIzNzY1OQ==&mid=2735617707&idx=2&sn=6fd038b3385c1175a6efd4ef00543e35&scene=21#wechat_redirect) 的实现方式有两种：`代码封装`跟`数据库中间件`。

**分库分表**：[分库分表](https://mp.weixin.qq.com/s?__biz=MzkzNTEwOTAxMA==&mid=2247484479&idx=1&sn=97358231f0f7086f0056fc5bb4e8afff&scene=21#wechat_redirect)分为垂直和水平两个方式，一般是`先垂直后水平`。

> 1、`垂直分库`：将应用分为若干模块，比如订单模块、用户模块、商品模块、支付模块等等。其实就是微服务的理念。
>
> 2、`垂直分表`：一般将不常用字段跟数据较大的字段做拆分。
>
> 3、`水平分表`：根据场景选择什么字段作分表字段，比如淘宝日订单1000万，用userId作分表字段，数据查询支持到最近6个月的订单，超过6个月的做归档处理，那么6个月的数据量就是18亿，分1024张表，每个表存200W数据，hash(userId)%100找到对应表格。
>
> 4、`ID生成器`：[分布式ID](https://mp.weixin.qq.com/s?__biz=MzI4NjI1OTI4Nw==&mid=2247485459&idx=1&sn=9baf434bdeebe98be60bcde7df702f22&scene=21#wechat_redirect) 需要跨库全局唯一方便查询存储-检索数据，确保唯一性跟数字递增性。

目前主要流行的分库分表工具 就是`Mycat`和`sharding-sphere`。

**TiDB**：开源`分布式`数据库，结合了传统的 RDBMS 和NoSQL 的最佳特性。TiDB 兼容 MySQL，`支持无限的水平扩展`，具备强一致性和高可用性。TiDB 的目标是为 OLTP(Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。TiDB 具备如下核心特点

> 1、支持 MySQL 协议（开发接入成本低）。
>
> 2、100% 支持事务（数据一致性实现简单、可靠）。
>
> 3、无限水平拓展（不必考虑分库分表），不停服务。
>
> 4、TiDB 支持和 MySQL 的互备。
>
> 5、遵循jdbc原则，学习成本低，强关系型，强一致性，不用担心主从配置，不用考虑分库分表，还可以无缝动态扩展。

适合：

> 1、原业务的 MySQL 的业务遇到单机容量或者性能瓶颈时，可以考虑使用 TiDB 无缝替换 MySQL。
>
> 2、大数据量下，MySQL 复杂查询很慢。
>
> 3、大数据量下，数据增长很快，接近单机处理的极限，不想分库分表或者使用数据库中间件等对业务侵入性较大、对业务有约束的 Sharding 方案。
>
> 4、大数据量下，有高并发实时写入、实时查询、实时统计分析的需求。
>
> 5、有分布式事务、多数据中心的数据 100% 强一致性、auto-failover 的高可用的需求。

不适合：

> 1、单机 MySQL 能满足的场景也用不到 TiDB。
>
> 2、数据条数少于 5000w 的场景下通常用不到 TiDB，TiDB 是为大规模的数据场景设计的。
>
> 3、如果你的应用数据量小（所有数据千万级别行以下），且没有高可用、强一致性或者多数据中心复制等要求，那么就不适合使用 TiDB。





**1、为查询缓存优化你的查询**

大多数的 MySQL 服务器都开启了查询缓存。这是提高性最有效的方法之一，而且这是被 MySQL 的数据库引擎处理的。当有很多相同的查询被执行了多次的时候，这些查询结果会被放到一个缓存中，这样，后续的相同的查询就不用操作表而直接访问缓存结果了。

这里最主要的问题是，对于程序员来说，这个事情是很容易被忽略的。因为，我们某些查询语句会让 MySQL 不使用缓存。请看下面的示例：

```php
// 查询缓存不开启
$r = mysql_query("SELECT username FROM user WHERE signup_date >= CURDATE()");

// 开启查询缓存
$today = date("Y-m-d");
$r = mysql_query("SELECT username FROM user WHERE signup_date >= '$today'");
```

上面两条 SQL 语句的差别就是 CURDATE() ，MySQL 的查询缓存对这个函数不起作用。所以，像 NOW() 和 RAND() 或是其它的诸如此类的 SQL 函数都不会开启查询缓存，因为这些函数的返回是不定的。所以，你所需要的就是用一个变量来代替 MySQL 的函数，从而开启缓存。

**2、SQL语句中IN包含的值不应过多**

MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。再例如：select id from t where num in(1,2,3) 对于连续的数值，能用between就不要用in了；再或者使用连接来替换。

**3、当只要一行数据时使用 LIMIT 1**

当你查询表的有些时候，你已经知道结果只会有一条结果，但因为你可能需要去 `fetch` 游标，或是你也许会去检查返回的记录数。

在这种情况下，加上 `LIMIT 1` 可以增加性能。这样一样，MySQL 数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。

**4、为搜索字段建索引**

如果在你的表中，有某个字段你总要会经常用来做搜索，那么，请为其建立索引。

另外，你应该也需要知道什么样的搜索是不能使用正常的索引的。例如，当你需要在一篇大的文章中搜索一个词时，如：`WHERE post_content LIKE '%apple%'`，索引可能是没有意义的。你可能需要使用 MySQL全文索引 或是自己做一个索引（比如说：搜索关键词或是 Tag 什么的）。

**5、在Join表的时候使用相同类型的列，并将其索引**

不同类型字段Join，无法使用索引！对于那些 STRING 类型，还需要有相同的字符集才行。

**6、千万不要 ORDER BY RAND()**

```sql
select id from `dynamic` order by rand() limit 1000;
-- 上面的SQL语句，可优化为：
select id from `dynamic` t1 join (select rand() * (select max(id) from `dynamic`) as nid) t2 on t1.id > t2.nid limit 1000;
```

**7、避免 SELECT *，如果排序字段没有用到索引，就尽量少排序**

**8、永远为每张表设置一个ID**

最好是一个 INT 型的（推荐使用UNSIGNED），并设置上自动增加的 `AUTO_INCREMENT` 标志，使用 VARCHAR 类型来当主键会使用得性能下降。

只有一个情况是例外，那就是“关联表”的“外键”，也就是说，这个表的主键，通过若干个别的表的主键构成，我们把这个情况叫做“外键”。比如：有一个“学生表”有学生的ID，有一个“课程表”有课程ID，那么，“成绩表”就是“关联表”了，其关联了学生表和课程表，在成绩表中，学生ID和课程ID叫“外键”，其共同组成主键。

**9、使用 ENUM 而不是 VARCHAR**

ENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。

**10、从 PROCEDURE ANALYSE() 取得建议**

只有表中有实际的数据，这些建议才会变得有用；数据不够多，决策可能就做得不够准；数据越来越多，建议才会变得准确。一定要记住，你才是最终做决定的人。

**11、尽可能的使用 NOT NULL**

"Empty" 和 "NULL" 有多大的区别（如果是INT，那就是0和NULL）？如果你觉得它们之间没有什么区别，那么你就不要使用NULL。（在 Oracle 里，NULL 和 Empty 的字符串是一样的！)

NULL 也需要额外的空间，并且，在进行比较的时候，程序会更复杂。

当然，这里并不是说不能使用 NULL，现实情况很复杂，依然会有一些情况，需要使用 NULL 值。

**12、Prepared Statements**

Prepared Statements 很像存储过程，是一种运行在后台的 SQL 语句集合，我们可以从使用 prepared statements 获得很多好处，无论是性能问题还是安全问题。

Prepared Statements 可以检查一些你绑定好的变量，这样可以保护你的程序不会受到“SQL注入式”攻击。当然，你也可以手动地检查你的这些变量，然而，手动的检查容易出问题，而且经常会被程序员忘了。当我们使用一些 framework 或是 ORM 的时候，这样的问题会好一些。

在性能方面，当一个相同的查询被使用多次的时候，这会为你带来可观的性能优势。你可以给这些 Prepared Statements 定义一些参数，而 MySQL 只会解析一次。

最新版本的 MySQL 在传输 Prepared Statements 是使用二进制形式，所以这会使得网络传输非常有效率。

当然，也有一些情况下，我们需要避免使用Prepared Statements，因为其不支持查询缓存，但据说版本5.1后支持了。

**13、无缓冲的查询**

正常的情况下，当你在你的脚本中执行一个SQL语句的时候，你的程序会停在那里直到这个SQL语句返回，然后你的程序再往下继续执行。你可以使用无缓冲查询来改变这个行为。

>思考：使用场景？

**14、把 IP 地址存成 UNSIGNED INT**

可以使用 `INET_ATON()` 来把一个字符串 IP 转成一个整形，并使用 `INET_NTOA()` 把一个整形转成一个字符串 IP。

**15、固定长度的表会更快**

如果表中的所有字段都是“固定长度”的，整个表会被认为是 [static 或 fixed-length](http://dev.mysql.com/doc/refman/5.1/en/static-format.html)。例如，表中没有如下类型的字段：VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。

固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。而如果字段不是定长的，那么，每一次要找下一条的话，需要程序找到主键。

并且，固定长度的表也更容易被缓存和重建。不过，唯一的副作用是，固定长度的字段会浪费一些空间，因为定长的字段无论你用不用，他都是要分配那么多的空间。

使用“垂直分割”技术，你可以分割你的表成为两个一个是定长的，一个则是不定长的。

**16、垂直分割**

“垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。

示例一：在 "Users" 表中有一个字段是家庭地址，这个字段是可选字段，而且你在数据库操作的时候除了个人信息外，并不需要经常读取或是改写这个字段。那么，为什么不把他放到另外一张表中呢？ 这样会让你的表有更好的性能。大多数时候，对于用户表来说，只有用户ID，用户名，口令，用户角色等会被经常使用，小一点的表总是会有好的性能。

示例二：你有一个叫 "last_login" 的字段，它会在每次用户登录时被更新。但是，***每次更新时会导致该表的查询缓存被清空***。所以，你可以把这个字段放到另一个表中，这样就不会影响你对用户ID，用户名，用户角色的不停地读取了，因为查询缓存会帮你增加很多性能。

另外，需要注意的是，这些被分出去的字段所形成的表，不需要经常Join，否则，性能会比不分割时还要差，而且，会是指数级的下降。

**17、拆分大的 DELETE 或 INSERT 语句**

如果需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止响应。因为这两个操作是会锁表的，表一锁住，别的操作都进不来了。

Apache 会有很多的子进程或线程。所以，其工作起来相当有效率，而我们的服务器却不希望有太多的子进程，线程和数据库链接，这是极大的占服务器资源的事情，尤其是内存。

如果你把表锁上一段时间，比如30秒钟，那么对于一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让你的WEB服务Crash，还可能会让你的整台服务器挂掉。

所以，如果有这种大的处理，一定要拆分，使用 LIMIT 条件是一个好方法！

**18、越小的列会越快**

对于大多数数据库引擎来说，硬盘操作可能是最大的瓶颈。所以，把数据变得紧凑会非常有帮助，因为这减少了对硬盘的访问。

参看 MySQL 的文档 [Storage Requirements](http://dev.mysql.com/doc/refman/5.0/en/storage-requirements.html) 查看所有的数据类型。

如果一个表只会有几行（比如说字典表，配置表），那么，我们就没有理由使用 INT 来做主键，使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间，使用 DATE 要比 DATETIME 好得多。

当然，你也需要留足够的扩展空间，不然，日后来干这个事，你会死的很难看，参看[Slashdot的例子（2009年11月06日）](http://news.slashdot.org/article.pl?sid=06/11/09/1534204)，一个简单的 ALTER TABLE 语句花了3个多小时，因为里面有一千六百万条数据。

**19、选择正确的存储引擎**

在 MySQL 中常用两个存储引擎 MyISAM 和 InnoDB，每个引擎都有利有弊。酷壳以前文章[《MySQL: InnoDB 还是 MyISAM?》](https://coolshell.cn/articles/652.html)讨论过这个事情。

MyISAM 适合于一些需要大量查询的应用，但其对于大量写操作并不是很友好。甚至你只是需要 update 一个字段，整个表都会被锁起来，而别的进程，就算是读进程都无法操作直到表被释放。不过，MyISAM 对于 `SELECT COUNT(*)` 这类的计算是超快无比的。

InnoDB 是一个非常复杂的存储引擎，它比 MyISAM 还慢，但是它支持“行锁” ，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：事务。

下面是MySQL的手册：

- [The MyISAM Storage Engine](https://dev.mysql.com/doc/refman/8.0/en/myisam-storage-engine.html)

**20、使用一个对象关系映射器（Object Relational Mapper）**

使用 ORM (Object Relational Mapper)，你能够获得可靠的性能增长。一个 ORM 可以做的所有事情，也能被手动的编写出来。但是，这需要一个高级专家。

ORM 的最重要的是 "Lazy Loading"，也就是说，只有在需要去取值的时候才会真正的去做。但你也要小心这种机制的副作用，因为这很可能会去创建很多很多小的查询降低性能。

ORM 还可以把你的 SQL 语句打包成一个事务，这会比单独执行他们快得多得多。

PHP 的 ORM：[Doctrine](http://www.doctrine-project.org/)。

**21、小心“永久链接”**

“永久链接”的目的是用来减少重新创建 MySQL 链接的次数。当一个链接被创建了，它会永远处在连接的状态，就算是数据库操作已经结束了。而且，自从我们的 Apache 开始重用它的子进程后——也就是说，下一次的 HTTP 请求会重用 Apache 的子进程，并重用相同的 MySQL 链接。

PHP手册：[mysql_pconnect()](http://php.net/manual/en/function.mysql-pconnect.php)

在理论上来说，这听起来非常的不错。但是从个人经验上来说，这个功能制造出来的麻烦事更多。因为，你只有有限的链接数，内存问题，文件句柄数，等等。

而且，Apache 运行在极端并行的环境中，会创建很多很多的子进程。这就是为什么这种“永久链接”的机制工作不好的原因。在你决定要使用“永久链接”之前，你需要好好地考虑一下你的整个系统的架构。

**22、如果限制条件中其他字段没有索引，尽量少用or**

or两边的字段中，如果有一个不是索引字段，而其他条件也不是索引字段，会造成该查询不走索引的情况。很多时候使用union all或者是union（必要的时候）的方式来代替“or”会得到更好的效果。

**23、尽量用union all代替union**

union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。

**24、巧用STRAIGHT_JOIN**

inner join是由MySQL选择驱动表，但是有些特殊情况需要选择另个表作为驱动表，比如有group by、order by等「Using filesort」、「Using temporary」时。STRAIGHT_JOIN来强制连接顺序，在STRAIGHT_JOIN左边的表名就是驱动表，右边则是被驱动表。在使用STRAIGHT_JOIN有个前提条件是该查询是内连接，也就是inner join。其他链接不推荐使用STRAIGHT_JOIN，否则可能造成查询结果不准确。

**25、关于JOIN优化**

LEFT JOIN A表为驱动表，INNER JOIN MySQL会自动找出那个数据少的表作用驱动表，RIGHT JOIN B表为驱动表。

**注意：**

**1）MySQL中没有full join，可以用以下方式来解决：**

```sql
select * from A left join B on B.name = A.name where B.name is null union allselect * from B;
```

**2）尽量使用inner join，避免left join：**

参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。

**3）合理利用索引：**

被驱动表的索引字段作为on的限制字段。

**4）利用小表去驱动大表**



**Mysql** **性能优化教程**

# 目录

目录................................................................................................................................. 1

背景及目标...................................................................................................................... 2

Mysql 执行优化............................................................................................................... 2

认识数据索引............................................................................................................ 2

为什么使用数据索引能提高效率......................................................................... 2

如何理解数据索引的结构................................................................................... 2

优化实战范例..................................................................................................... 3

认识影响结果集........................................................................................................ 4

影响结果集的获取.............................................................................................. 4

影响结果集的解读.............................................................................................. 4

常见案例及优化思路.......................................................................................... 5

理解执行状态............................................................................................................ 7

常见关注重点..................................................................................................... 7

执行状态分析..................................................................................................... 8

分析流程............................................................................................................ 9

常见案例解析................................................................................................... 11

总结................................................................................................................. 12

Mysql 运维优化............................................................................................................. 14

存储引擎类型.......................................................................................................... 14

内存使用考量.......................................................................................................... 14

性能与安全性考量................................................................................................... 14

存储/写入压力优化.................................................................................................. 15

运维监控体系.......................................................................................................... 15

Mysql 架构优化............................................................................................................. 17

架构优化目标.......................................................................................................... 17

防止单点隐患................................................................................................... 17

方便系统扩容................................................................................................... 17

安全可控，成本可控........................................................................................ 17

分布式方案............................................................................................................. 18

分库&拆表方案................................................................................................ 18

反范式设计（冗余结构设计）.......................................................................... 20

主从架构.......................................................................................................... 21

故障转移处理................................................................................................... 22

缓存方案................................................................................................................. 22

缓存结合数据库的读取..................................................................................... 22

缓存结合数据库的写入..................................................................................... 23

总结............................................................................................................................... 24

 

 

# 背景及目标

l 厦门游家公司（4399.com）用于员工培训和分享。

l 针对用户群为已经使用过mysql环境，并有一定开发经验的工程师

l 针对高并发，海量数据的互联网环境。

l 本文语言为口语，非学术标准用语。

l 以实战和解决具体问题为主要目标，非应试，非常规教育。友情提醒，在校生学习本教程可能对成绩提高有害无益。

l 非技术挑战，非高端架构师培训，请高手自动忽略。

l 本文档在2011年7月-12月持续更新，加强了影响结果集分析的内容并增补优化实战案例若干。

# Mysql 执行优化

## 认识数据索引

### 为什么使用数据索引能提高效率

n 关系型数据库的数据索引（Btree及常见索引结构）的存储是有序的。

n 在有序的情况下，通过索引查询一个数据是无需遍历索引记录的

n 关系型数据库数据索引的查询效率趋近于二分法查询效率，趋近于 log2(N)。

n 极端情况下（更新请求少，更新实时要求低，查询请求频繁），建立单向有序序列可替代数据索引。

n HASH索引的查询效率是寻址操作，趋近于1次查询，比有序索引查询效率更高，但是不支持比对查询，区间查询，排序等操作，仅支持key-value类型查询。不是本文重点。

### 如何理解数据索引的结构

n 数据索引通常默认采用btree索引，（内存表也使用了hash索引）。

n 仅就有序前提而言，单向有序排序序列是查找效率最高的（二分查找，或者说折半查找），使用树形索引的目的是为了达到快速的更新和增删操作。

n 在极端情况下（比如数据查询需求量非常大，而数据更新需求极少，实时性要求不高，数据规模有限），直接使用单一排序序列，折半查找速度最快。

n 在进行索引分析和SQL优化时，可以将数据索引字段想象为单一有序序列，并以此作为分析的基础。涉及到复合索引情况，复合索引按照索引顺序拼凑成一个字段，想象为单一有序序列，并以此作为分析的基础。

n 一条数据查询只能使用一个索引，索引可以是多个字段合并的复合索引。但是一条数据查询不能使用多个索引。

### 优化实战范例

l 实战范例1： ip地址反查

n 资源： Ip地址对应表，源数据格式为 startip, endip, area 

源数据条数为 10万条左右，呈很大的分散性

n 目标：  需要通过任意ip查询该ip所属地区

性能要求达到每秒1000次以上的查询效率

n 挑战：  如使用 between startip and endip 这样的条件数据库操作，因为涉及两个字段的between and, 无法有效使用索引。

如果每次查询请求需要遍历10万条记录，根本不行。

n 方法：  一次性排序（只在数据准备中进行，数据可存储在内存序列）

​       折半查找（每次请求以折半查找方式进行）

l 实战范例2：目标：查找与访问者同一地区的异性，按照最后登录时间逆序

n 挑战：高访问量社区的高频查询，如何优化。

​       查询SQL: select * from user where area=’$area’ and sex=’$sex’ order by lastlogin desc limit 0,30;

​        建立复合索引并不难， area+sex+lastlogin 三个字段的复合索引,如何理解？

n 解读：首先，忘掉btree，将索引字段理解为一个排序序列。

另外，牢记数据查询只能使用一个索引，每个字段建立独立索引的情况下，也只能有一条索引被使用！

​    如果只使用area会怎样？搜索会把符合area的结果全部找出来，然后在这里面遍历，选择命中sex的并排序。 遍历所有 area=’$area’数据！

如果使用了area+sex，略好，仍然要遍历所有area=’$area’ and sex=’$sex’数据，然后在这个基础上排序！！

​    Area+sex+lastlogin复合索引时（切记lastlogin在最后），该索引基于area+sex+lastlogin 三个字段合并的结果排序，该列表可以想象如下。

​    广州女$时间1

​    广州女$时间2

​    广州女$时间3

​       …

​    广州男

….

​    深圳女

….

数据库很容易命中到 area+sex的边界，并且基于下边界向上追溯30条记录，搞定！在索引中迅速命中所有结果，无需二次遍历！

## 认识影响结果集

### 影响结果集的获取

n 通过Explain 分析SQL，查看 rows 列内容

n 通过慢查询日志的Rows_examined: 后面的数字

n 影响结果集数字是查询优化的重要中间数字，工程师在开发和调试过程中，应随时关注这一数字。

### 影响结果集的解读

n 查询条件与索引的关系决定影响结果集。

u 影响结果集不是输出结果数，不是查询返回的记录数，而是索引所扫描的结果数。

u 范例 select * from user where area=’厦门’ and sex=’女’ 

l 假设 索引为 area

l 假设User表中 area=’厦门’的有 125000条，而搜索返回结果为60233条。

l 影响结果集是125000条，索引先命中125000条厦门用户，再遍历以sex=’女’进行筛选操作，得到60233条结果。

l 如果该SQL 增加 limit 0,30的后缀。查询时，先命中 area=’厦门’，然后依顺序执行 sex=’女’ 筛选操作，直到满足可以返回30条为止，所涉及记录数未知。除非满足条件的结果不足30条，否则不会遍历125000条记录。

l 但是如果SQL中涉及了排序操作，比如 order by lastlogin desc 再有limit 0,30时，排序需要遍历所有area=’厦门’ 的记录，而不是满足即止。

n 影响结果集越趋近于实际输出或操作的目标结果集，索引效率越高。

n 影响结果集与查询开销的关系可以理解为线性相关。减少一半影响结果集，即可提升一倍查询效率！当一条搜索query可以符合多个索引时，选择影响结果集最少的索引。

n SQL的优化，核心就是对结果集的优化，认识索引是增强对结果集的判断，基于索引的认识，可以在编写SQL的时候，对该SQL可能的影响结果集有预判，并做出适当的优化和调整。

n Limit 的影响，需要斟酌对待

u 如果索引与查询条件和排序条件完全命中，影响结果集就是limit后面的数字（$start + $end），比如 limit 200,30 影响结果集是230. 而不是30.

u 如果索引只命中部分查询条件，甚至无命中条件，在无排序条件情况下，会在索引命中的结果集 中遍历到满足所有其他条件为止。比如 select * from user limit 10; 虽然没用到索引，但是因为不涉及二次筛选和排序，系统直接返回前10条结果，影响结果集依然只有10条，就不存在效率影响。

u 如果搜索所包含的排序条件没有被索引命中，则系统会遍历是所有索引所命中的结果，并且排序。例如 Select * from user order by timeline desc limit 10; 如果timeline不是索引，影响结果集是全表，就存在需要全表数据排序，这个效率影响就巨大。再比如 Select * from user where area=’厦门’ order by timeline desc limit 10; 如果area是索引，而area+timeline未建立索引，则影响结果集是所有命中 area=’厦门’的用户，然后在影响结果集内排序。

 

### 常见案例及优化思路

n 毫秒级优化案例

u 某游戏用户进入后显示最新动态，SQL为 select * from userfeed where uid=$uid order by timeline desc limit 20; 主键为$uid 。 该SQL每天执行数百万次之多，高峰时数据库负载较高。 通过 show processlist 显示大量进程处于Sending data状态。没有慢查询记录。 仔细分析发现，因存在较多高频用户访问，命中 uid=$uid的影响结果集通常在几百到几千，在上千条影响结果集情况下，该SQL查询开销通常在0.01秒左右。 建立uid+timeline 复合索引，将排序引入到索引结构中，影响结果集就只有limit 后面的数字，该SQL查询开销锐减至0.001秒，数据库负载骤降。

n Innodb锁表案例

u 某游戏数据库使用了innodb，innodb是行级锁，理论上很少存在锁表情况。出现了一个SQL语句(delete from tabname where xid=…)，这个SQL非常用SQL，仅在特定情况下出现，每天出现频繁度不高（一天仅10次左右），数据表容量百万级，但是这个xid未建立索引，于是悲惨的事情发生了，当执行这条delete 的时候，真正删除的记录非常少，也许一到两条，也许一条都没有；但是！由于这个xid未建立索引，delete操作时遍历全表记录，全表被delete操作锁定，select操作全部被locked，由于百万条记录遍历时间较长，期间大量select被阻塞，数据库连接过多崩溃。

这种非高发请求，操作目标很少的SQL，因未使用索引，连带导致整个数据库的查询阻塞，需要极大提高警觉。

n 实时排名策略优化

u 背景： 用户提交游戏积分，显示实时排名。

u 原方案： 

l 提交积分是插入记录，略， 

l select count(*) from jifen where gameid=$gameid and fenshu>$fenshu

u 问题与挑战

l 即便索引是 gameid+fenshu 复合索引，涉及count操作，当分数较低时，影响结果集巨大，查询效率缓慢，高峰期会导致连接过多。

u 优化思路

l 减少影响结果集，又要取得实时数据，单纯从SQL上考虑，不太有方法。

l 将游戏积分预定义分成数个积分断点，然后分成积分区间，原始状态，每个区间设置一个统计数字项，初始为0。

l 每次积分提交时，先确定该分数属于哪两个区间之间，这个操作非常简单，因为区间是预定义的，而且数量很少，只需遍历即可，找到最该分数符合的区间， 该区间的统计数字项（独立字段，可用内存处理，异步回写数据库或文件）+1。 记录该区间上边界数字为$duandian。

l SQL: select count(*) from jifen where gameid=$gameid and fenshu>$fenshu and fenshu<$duandian，如果处于第一区间，则无需$duandian，这样因为第一区间本身也是最好的成绩，影响结果集不会很多。 通过该SQL获得其在该区间的名次。

l 获取前面区间的总数总和。（该数字是直接从上述提到的区间统计数字获取，不需要进行count操作）将区间内名次+前区间的统计数字和，获得总名次。

l 该方法关键在于，积分区间需要合理定义，保证积分提交成绩能平均散落在不同区间。

l 如涉及较多其他条件，如日排行，总排行，以及其他独立用户去重等，请按照影响结果集思路自行发挥。

u Redis方案

l Redis数据结构包括String,list,dict和Zset四种，在本案例中是非常好的替代数据库的方案，本文档只做简介，不做额外扩展。

l String 哈希索引，key-value结构，主键查询效率极高，不支持排序，比较查询。

l List 队列结构，在数据异步写入处理中可以替代memcache。

l Dict 数组结构，存储结构化，序列化内容，可以针对数组中的特定列进行操作。

l Zset 有序数组结构，分两个子结构，第一是多层树形的存储结构，第二是每个树形节点的计数器，这样类似于前面的分段方式，可以理解为多层分段方式，所以查询效率更高，缺点是更新效率有所增加。

n 论坛翻页优化

u 背景，常见论坛帖子页 SQL: select * from post where tagid=$tagid order by lastpost limit $start, $end 翻页 。索引为 tagid+lastpost 复合索引

u 挑战， 超级热帖，几万回帖，用户频频翻到末页，limit 25770,30 一个操作下来，影响结果集巨大(25770+30)，查询缓慢。

u 解决方法：

l 只涉及上下翻页情况

n 每次查询的时候将该页查询结果中最大的 $lastpost和最小的分别记录为 $minlastpost 和 $maxlastpost ，上翻页查询为 select * from post where tagid=$tagid and lastpost<$minlastpost order by lastpost desc limit 30; 下翻页为 select * from post where tagid=$tagid and lastpost>$maxlastpost order by lastpost limit 30; 使用这种方式，影响结果集只有30条，效率极大提升。

l 涉及跳转到任意页

n 互联网上常见的一个优化方案可以这样表述，select * from post where tagid=$tagid and lastpost>=(select lastpost from post where tagid=$tagid order by lastpost limit $start,1) order by lastpost limit 30; 或者 select * from post where pid in (select pid from post where tagid=$tagid order by lastpost limit $start,30); (第2条S语法在新的mysql版本已经不支持，新版本mysql in的子语句不再支持limit条件，但可以分解为两条SQL实现，原理不变，不做赘述)

n 以上思路在于，子查询的影响结果集仍然是$start +30，但是数据获取的过程（Sending data状态）发生在索引文件中，而不是数据表文件，这样所需要的系统开销就比前一种普通的查询低一个数量级，而主查询的影响结果集只有30条，几乎无开销。但是切记，这里仍然涉及了太多的影响结果集操作。

u 延伸问题：

l 来自于uchome典型查询 SELECT * FROM uchome_thread WHERE tagid='73820' ORDER BY displayorder DESC, lastpost DESC LIMIT $start,30; 

l 如果换用 如上方法，上翻页代码 SELECT * FROM uchome_thread WHERE tagid='73820' and lastpost<$minlastpost ORDER BY displayorder DESC,lastpost DESC LIMIT 0,30; 下翻页代码SELECT * FROM uchome_thread WHERE tagid='73820' and lastpost>$maxlastpost ORDER BY displayorder DESC, lastpost ASC LIMIT 0,30;

l 这里涉及一个order by 索引可用性问题，当order by中 复合索引的字段，一个是ASC，一个是DESC 时，其排序无法在索引中完成。 所以只有上翻页可以正确使用索引，影响结果集为30。下翻页无法在排序中正确使用索引，会命中所有索引内容然后排序，效率低下。

l 总结：

n 基于影响结果集的理解去优化，不论从数据结构，代码，还是涉及产品策略上，都需要贯彻下去。

n 涉及 limit $start,$num的搜索，如果$start巨大，则影响结果集巨大，搜索效率会非常难过低，尽量用其他方式改写为 limit 0,$num； 确系无法改写的情况下，先从索引结构中获得 limit $start,$num 或limit $start,1 ；再用in操作或基于索引序的 limit 0,$num 二次搜索。

n 请注意，我这里永远不会讲关于外键和join的优化，因为在我们的体系里，这是根本不允许的！ 架构优化部分会解释为什么。

## 理解执行状态

### 常见关注重点

l 慢查询日志，关注重点如下

n 是否锁定，及锁定时间

u 如存在锁定，则该慢查询通常是因锁定因素导致，本身无需优化，需解决锁定问题。

n 影响结果集

u 如影响结果集较大，显然是索引项命中存在问题，需要认真对待。

l Explain 操作

n 索引项使用

u 不建议用using index做强制索引，如未如预期使用索引，建议重新斟酌表结构和索引设置。

n 影响结果集

u 这里显示的数字不一定准确，结合之前提到对数据索引的理解来看，还记得嘛？就把索引当作有序序列来理解，反思SQL。

l Set profiling , show profiles for query操作

n 执行开销

u 注意，有问题的SQL如果重复执行，可能在缓存里，这时要注意避免缓存影响。通过这里可以看到。

u 执行时间超过0.005秒的频繁操作SQL建议都分析一下。

u 深入理解数据库执行的过程和开销的分布

l Show processlist 执行状态监控

n 这是在数据库负载波动时经常进行的一项操作

n 具体参见如下

### 执行状态分析

l Sleep 状态 

n 通常代表资源未释放，如果是通过连接池，sleep状态应该恒定在一定数量范围内

n 实战范例： 因前端数据输出时（特别是输出到用户终端）未及时关闭数据库连接，导致因网络连接速度产生大量sleep连接，在网速出现异常时，数据库 too many connections 挂死。

n 简单解读，数据查询和执行通常只需要不到0.01秒，而网络输出通常需要1秒左右甚至更长，原本数据连接在0.01秒即可释放，但是因为前端程序未执行close操作，直接输出结果，那么在结果未展现在用户桌面前，该数据库连接一直维持在sleep状态！

l Waiting for net, reading from net, writing to net

n 偶尔出现无妨

n 如大量出现，迅速检查数据库到前端的网络连接状态和流量

n 案例: 因外挂程序，内网数据库大量读取，内网使用的百兆交换迅速爆满，导致大量连接阻塞在waiting for net，数据库连接过多崩溃

l Locked状态

n 有更新操作锁定

n 通常使用innodb可以很好的减少locked状态的产生，但是切记，更新操作要正确使用索引，即便是低频次更新操作也不能疏忽。如上影响结果集范例所示。

n 在myisam的时代，locked是很多高并发应用的噩梦。所以mysql官方也开始倾向于推荐innodb。

l Copy to tmp table

n 索引及现有结构无法涵盖查询条件，才会建立一个临时表来满足查询要求，产生巨大的恐怖的i/o压力。

n 很可怕的搜索语句会导致这样的情况，如果是数据分析，或者半夜的周期数据清理任务，偶尔出现，可以允许。频繁出现务必优化之。

n Copy to tmp table 通常与连表查询有关，建议逐渐习惯不使用连表查询。

n 实战范例：

u 某社区数据库阻塞，求救，经查，其服务器存在多个数据库应用和网站，其中一个不常用的小网站数据库产生了一个恐怖的copy to tmp table 操作，导致整个硬盘i/o和cpu压力超载。Kill掉该操作一切恢复。

l Sending data

n Sending data 并不是发送数据，别被这个名字所欺骗，这是从物理磁盘获取数据的进程，如果你的影响结果集较多，那么就需要从不同的磁盘碎片去抽取数据，

n 偶尔出现该状态连接无碍。

n 回到上面影响结果集的问题，一般而言，如果sending data连接过多，通常是某查询的影响结果集过大，也就是查询的索引项不够优化。

n 前文提到影响结果集对SQL查询效率线性相关，主要就是针对这个状态的系统开销。

n 如果出现大量相似的SQL语句出现在show proesslist列表中，并且都处于sending data状态，优化查询索引，记住用影响结果集的思路去思考。

l Storing result to query cache

n 出现这种状态，如果频繁出现，使用set profiling分析，如果存在资源开销在SQL整体开销的比例过大（即便是非常小的开销，看比例），则说明query cache碎片较多

n 使用flush query cache 可即时清理，也可以做成定时任务

n Query cache参数可适当酌情设置。

l Freeing items

n 理论上这玩意不会出现很多。偶尔出现无碍

n 如果大量出现，内存，硬盘可能已经出现问题。比如硬盘满或损坏。

n i/o压力过大时，也可能出现Free items执行时间较长的情况。

l Sorting for …

n 和Sending data类似，结果集过大，排序条件没有索引化，需要在内存里排序，甚至需要创建临时结构排序。

l 其他

n 还有很多状态，遇到了，去查查资料。基本上我们遇到其他状态的阻塞较少，所以不关心。

### 分析流程

l 基本流程

n 详细了解问题状况

u Too many connections 是常见表象，有很多种原因。

u 索引损坏的情况在innodb情况下很少出现。

u 如出现其他情况应追溯日志和错误信息。

n 了解基本负载状况和运营状况

u 基本运营状况

l 当前每秒读请求

l 当前每秒写请求

l 当前在线用户

l 当前数据容量

u 基本负载情况

l 学会使用这些指令

n Top 

n Vmstat

n uptime 

n iostat 

n df 

l Cpu负载构成

n 特别关注i/o压力( wa%)

n 多核负载分配

l 内存占用

n Swap分区是否被侵占

n 如Swap分区被侵占，物理内存是否较多空闲

l 磁盘状态

n 硬盘满和inode节点满的情况要迅速定位和迅速处理

n 了解具体连接状况

u 当前连接数 

l Netstat –an|grep 3306|wc –l

l Show processlist

u 当前连接分布 show processlist

l 前端应用请求数据库不要使用root帐号！

n Root帐号比其他普通帐号多一个连接数许可。

n 前端使用普通帐号，在too many connections的时候root帐号仍可以登录数据库查询 show processlist!

n 记住，前端应用程序不要设置一个不叫root的root帐号来糊弄！非root账户是骨子里的，而不是名义上的。

l 状态分布

n 不同状态代表不同的问题，有不同的优化目标。

n 参见如上范例。

l 雷同SQL的分布

n 是否较多雷同SQL出现在同一状态

u 当前是否有较多慢查询日志

l 是否锁定

l 影响结果集

n 频繁度分析

u 写频繁度

l 如果i/o压力高，优先分析写入频繁度

l Mysqlbinlog 输出最新binlog文件，编写脚本拆分

l 最多写入的数据表是哪个

l 最多写入的数据SQL是什么

l 是否存在基于同一主键的数据内容高频重复写入？

n 涉及架构优化部分，参见架构优化-缓存异步更新

u 读取频繁度

l 如果cpu资源较高，而i/o压力不高，优先分析读取频繁度

l 程序中在封装的db类增加抽样日志即可，抽样比例酌情考虑，以不显著影响系统负载压力为底线。

l 最多读取的数据表是哪个

l 最多读取的数据SQL是什么

n 该SQL进行explain 和set profiling判定

n 注意判定时需要避免query cache影响

u 比如，在这个SQL末尾增加一个条件子句 and 1=1 就可以避免从query cache中获取数据，而得到真实的执行状态分析。 

l 是否存在同一个查询短期内频繁出现的情况

n 涉及前端缓存优化

n 抓大放小，解决显著问题

u 不苛求解决所有优化问题，但是应以保证线上服务稳定可靠为目标。

u 解决与评估要同时进行，新的策略或解决方案务必经过评估后上线。

### 常见案例解析

l 现象：服务器出现too many connections 阻塞

n 入手点：

u 查看服务器状态，cpu占用，内存占用，硬盘占用，硬盘i/o压力

u 查看网络流量状态，mysql与应用服务器的输入输出状况

u 通过Show processlist查看当前运行清单

l 注意事项，日常应用程序连接数据库不要使用root账户，保证故障时可以通过root 进入数据库查看 show processlist。

n 状态分析：

u 参见如上执行状态清单，根据连接状态的分布去确定原因。

n 紧急恢复

u 在确定故障原因后，应通过kill掉阻塞进程的方式 立即恢复数据库。

n 善后处理

u 以下针对常见问题简单解读

u Sleep 连接过多导致，应用端及时释放连接，排查关联因素。

u Locked连接过多，如源于myisam表级锁，更innodb引擎;如源于更新操作使用了不恰当的索引或未使用索引，改写更新操作SQL或建立恰当索引。

u Sending data连接过多，用影响结果集的思路优化SQL查询，优化表索引结构。

u Free items连接过多，i/o压力过大 或硬盘故障

u Waiting for net , writing to net 连接过多， mysql与应用服务器连接阻塞。

u 其他仍参见如上执行状态清单所示分析。

u 如涉及不十分严格安全要求的数据内容，可用定期脚本跟踪请求进程，并kill掉僵死进程。如数据安全要求较严格，则不能如此进行。

l 现象：数据库负载过高，响应缓慢。

n 入手点：

u 查看cpu状态，服务器负载构成

n 分支1：i/o占用过高。

u 步骤1： 检查内存是否占用swap分区，排除因内存不足导致的i/o开销。

u 步骤2：通过iostat 指令分析i/o是否集中于数据库硬盘，是否是写入度较高。

u 步骤3：如果压力来自于写，使用mysqlbinlog 解开最新的binlog文件。

u 步骤4：编写日志分析脚本或grep指令，分析每秒写入频度和写入内容。

l 写入频度不高，则说明i/o压力另有原因或数据库配置不合理。

u 步骤5：编写日志分析脚本或grep 指令，分析写入的数据表构成，和写入的目标构成。

u 步骤6：编写日志分析脚本，分析是否存在同一主键的重复写入。 比如出现大量 update post set views=views+1 where tagid=****的操作，假设在一段时间内出现了2万次，而其中不同的tagid有1万次，那么就是有50%的请求是重复update请求，有可以通过异步更新合并的空间。

u 提示一下，以上所提及的日志分析脚本编写，正常情况下不应超过1个小时，而对系统负载分析所提供的数据支持价值是巨大的，对性能优化方案的选择是非常有意义的，如果您认为这项工作是繁冗而且复杂的工作，那么一定是在分析思路和目标把握上出现了偏差。

n 分支2：i/o占用不高，CPU 占用过高

u 步骤1：查看慢查询日志

u 步骤2：不断刷新查看Show processlist清单，并把握可能频繁出现的处于Sending data状态的SQL。

u 步骤3：记录前端执行SQL

l 于前端应用程序执行查询的封装对象内，设置随机采样，记录前端执行的SQL，保证有一定的样本规模，并且不会带来前端i/o负载的激增。

l 基于采样率和记录频率，获得每秒读请求次数数据指标。

l 编写日志分析脚本，分析采样的SQL构成，所操作的数据表，所操作的主键。

l 对频繁重复读取的SQL(完全一致的SQL)进行判定，是否数据存在频繁变动，是否需要实时展现最新数据，如有可能，缓存化，并预估缓存命中率。

l 对频繁读取但不重复的(SQL结构一致，但条件中的数据不一致)SQL进行判定，是否索引足够优化，影响结果集与输出结果是否足够接近。

u 步骤4：将导致慢查询的SQL或频繁出现于show processlist状态的SQL，或采样记录的频繁度SQL进行分析，按照影响结果集的思路和索引理解来优化。

u 步骤5：对如上难以界定问题的SQL进行 set profiling 分析。

u 步骤6：优化后分析继续采样跟踪分析。并跟踪比对结果。

n 善后处理

u 日常跟踪脚本，不断记录一些状态信息。保证每个时间节点都能回溯。

u 确保随时能了解服务器的请求频次，读写请求的分布。

u 记录一些未造成致命影响的隐患点，可暂不解决，但需要记录。

u 如确系服务器请求频次过高，可基于负载分布决定硬件扩容方案，比如i/o压力过高可考虑固态硬盘；内存占用swap可考虑增加内容容量等。用尽可能少的投入实现最好的负载支撑能力，而不是简单的买更多服务器。

### 总结

l 要学会怎样分析问题，而不是单纯拍脑袋优化

l 慢查询只是最基础的东西，要学会优化0.01秒的查询请求。

l 当发生连接阻塞时，不同状态的阻塞有不同的原因，要找到原因，如果不对症下药，就会南辕北辙

n 范例：如果本身系统内存已经超载，已经使用到了swap，而还在考虑加大缓存来优化查询，那就是自寻死路了。

l 影响结果集是非常重要的中间数据和优化指标，学会理解这一概念，理论上影响结果集与查询效率呈现非常紧密的线性相关。

l 监测与跟踪要经常做，而不是出问题才做

n 读取频繁度抽样监测

u 全监测不要搞，i/o吓死人。

u 按照一个抽样比例抽样即可。

u 针对抽样中发现的问题，可以按照特定SQL在特定时间内监测一段全查询记录，但仍要考虑i/o影响。

n 写入频繁度监测

u 基于binlog解开即可，可定时或不定时分析。

n 微慢查询抽样监测

u 高并发情况下，查询请求时间超过0.01秒甚至0.005秒的，建议酌情抽样记录。

n 连接数预警监测

u 连接数超过特定阈值的情况下，虽然数据库没有崩溃，建议记录相关连接状态。

l 学会通过数据和监控发现问题，分析问题，而后解决问题顺理成章。特别是要学会在日常监控中发现隐患，而不是问题爆发了才去处理和解决。

**
**

# Mysql 运维优化

## 存储引擎类型

l Myisam 速度快，响应快。表级锁是致命问题。

l Innodb 目前主流存储引擎

n 行级锁 

u 务必注意影响结果集的定义是什么

u 行级锁会带来更新的额外开销，但是通常情况下是值得的。

n 事务提交 

u 对i/o效率提升的考虑

u 对安全性的考虑

l HEAP 内存引擎

n 频繁更新和海量读取情况下仍会存在锁定状况

## 内存使用考量

l 理论上，内存越大，越多数据读取发生在内存，效率越高

l Query cache的使用

n 如果前端请求重复度不高，或者应用层已经充分缓存重复请求，query cache不必设置很大，甚至可以不设置。

n 如果前端请求重复度较高，无应用层缓存，query cache是一个很好的偷懒选择

u 对于中等以下规模数据库应用，偷懒不是一个坏选择。

u 如果确认使用query cache，记得定时清理碎片，flush query cache.

l 要考虑到现实的硬件资源和瓶颈分布

l 学会理解热点数据，并将热点数据尽可能内存化

n 所谓热点数据，就是最多被访问的数据。

n 通常数据库访问是不平均的，少数数据被频繁读写，而更多数据鲜有读写。

n 学会制定不同的热点数据规则，并测算指标。

u 热点数据规模，理论上，热点数据越少越好，这样可以更好的满足业务的增长趋势。

u 响应满足度，对响应的满足率越高越好。

u 比如依据最后更新时间，总访问量，回访次数等指标定义热点数据，并测算不同定义模式下的热点数据规模

## 性能与安全性考量

l 数据提交方式

n innodb_flush_log_at_trx_commit = 1 每次自动提交，安全性高，i/o压力大

n innodb_flush_log_at_trx_commit = 2 每秒自动提交，安全性略有影响，i/o承载强。

l 日志同步

n Sync-binlog  =1 每条自动更新，安全性高，i/o压力大

n Sync-binlog = 0 根据缓存设置情况自动更新，存在丢失数据和同步延迟风险，i/o承载力强。

n 个人建议保存binlog日志文件，便于追溯 更新操作和系统恢复。

n 如对日志文件的i/o压力有担心，在内存宽裕的情况下，可考虑将binlog 写入到诸如 /dev/shm 这样的内存映射分区，并定时将旧有的binlog转移到物理硬盘。

l 性能与安全本身存在相悖的情况，需要在业务诉求层面决定取舍

n 学会区分什么场合侧重性能，什么场合侧重安全

n 学会将不同安全等级的数据库用不同策略管理

## 存储/写入压力优化

l 顺序读写性能远高于随机读写

l 将顺序写数据和随机读写数据分成不同的物理磁盘进行，有助于i/o压力的疏解

·     数据库文件涉及索引等内容，写入是随即写

·     binlog文件是顺序写

·     淘宝数据库存储优化是这样处理的

l 部分安全要求不高的写入操作可以用 /dev/shm 分区存储，简单变成内存写。

l 多块物理硬盘做raid10，可以提升写入能力

l 关键存储设备优化，善于比对不同存储介质的压力测试数据。

·     例如fusion-io在新浪和淘宝都有较多使用。

l 涉及必须存储较为庞大的数据量时

·     压缩存储，可以通过增加cpu开销（压缩算法）减少i/o压力。前提是你确认cpu相对空闲而i/o压力很大。 新浪微博就是压缩存储的典范。

·     通过md5去重存储，案例是QQ的文件共享，以及dropbox这样的共享服务，如果你上传的是一个别人已有的文件，计算md5后，直接通过md5定位到原有文件，这样可以极大减少存储量。涉及文件共享，头像共享，相册等应用，通过这种方法可以减少超过70%的存储规模，对硬件资源的节省是相当巨大的。缺点是，删除文件需要甄别该md5是否有其他人使用。 去重存储，用户量越多，上传文件越多，效率越高！

·     文件尽量不要存储到数据库内。尽量使用独立的文件系统存储，该话题不展开。

## 运维监控体系

l 系统监控

n 服务器资源监控

u Cpu, 内存，硬盘空间，i/o压力

u 设置阈值报警

n 服务器流量监控

u 外网流量，内网流量

u 设置阈值报警

n 连接状态监控

u Show processlist 设置阈值，每分钟监测，超过阈值记录

l 应用监控

n 慢查询监控

u 慢查询日志

u 如果存在多台数据库服务器，应有汇总查阅机制。

n 请求错误监控

u 高频繁应用中，会出现偶发性数据库连接错误或执行错误，将错误信息记录到日志，查看每日的比例变化。

u 偶发性错误，如果数量极少，可以不用处理，但是需时常监控其趋势。

u 会存在恶意输入内容，输入边界限定缺乏导致执行出错，需基于此防止恶意入侵探测行为。

n 微慢查询监控

u 高并发环境里，超过0.01秒的查询请求都应该关注一下。

n 频繁度监控

u 写操作，基于binlog，定期分析。

u 读操作，在前端db封装代码中增加抽样日志，并输出执行时间。

u 分析请求频繁度是开发架构 进一步优化的基础

u 最好的优化就是减少请求次数！

l 总结：

n 监控与数据分析是一切优化的基础。

n 没有运营数据监测就不要妄谈优化！

n 监控要注意不要产生太多额外的负载，不要因监控带来太多额外系统开销

**
**

# Mysql 架构优化

## 架构优化目标

### 防止单点隐患

l 所谓单点隐患，就是某台设备出现故障，会导致整体系统的不可用，这个设备就是单点隐患。

l 理解连带效应，所谓连带效应，就是一种问题会引发另一种故障，举例而言，memcache+mysql是一种常见缓存组合，在前端压力很大时，如果memcache崩溃，理论上数据会通过mysql读取，不存在系统不可用情况，但是mysql无法对抗如此大的压力冲击，会因此连带崩溃。因A系统问题导致B系统崩溃的连带问题，在运维过程中会频繁出现。

n 实战范例： 在mysql连接不及时释放的应用环境里，当网络环境异常（同机房友邻服务器遭受拒绝服务攻击，出口阻塞），网络延迟加剧，空连接数急剧增加，导致数据库连接过多崩溃。

n 实战范例2：前端代码 通常我们封装 mysql_connect和memcache_connect，二者的顺序不同，会产生不同的连带效应。如果mysql_connect在前，那么一旦memcache连接阻塞，会连带mysql空连接过多崩溃。

n 连带效应是常见的系统崩溃，日常分析崩溃原因的时候需要认真考虑连带效应的影响，头疼医头，脚疼医脚是不行的。

### 方便系统扩容

l 数据容量增加后，要考虑能够将数据分布到不同的服务器上。

l 请求压力增加时，要考虑将请求压力分布到不同服务器上。

l 扩容设计时需要考虑防止单点隐患。

### 安全可控，成本可控

l 数据安全，业务安全

l 人力资源成本>带宽流量成本>硬件成本

n 成本与流量的关系曲线应低于线性增长（流量为横轴，成本为纵轴）。

n 规模优势

l 本教程仅就与数据库有关部分讨论，与数据库无关部门请自行参阅其他学习资料。

​    

## 分布式方案

### 分库&拆表方案

l 基本认识

n 用分库&拆表是解决数据库容量问题的唯一途径。

n 分库&拆表也是解决性能压力的最优选择。

n 分库 – 不同的数据表放到不同的数据库服务器中（也可能是虚拟服务器）

n 拆表 – 一张数据表拆成多张数据表，可能位于同一台服务器，也可能位于多台服务器（含虚拟服务器）。

l 去关联化原则

n 摘除数据表之间的关联，是分库的基础工作。

n 摘除关联的目的是，当数据表分布到不同服务器时，查询请求容易分发和处理。

n 学会理解反范式数据结构设计，所谓反范式，第一要点是不用外键，不允许Join操作，不允许任何需要跨越两个表的查询请求。第二要点是适度冗余减少查询请求，比如说，信息表，fromuid, touid, message字段外，还需要一个fromuname字段记录用户名，这样查询者通过touid查询后，能够立即得到发信人的用户名，而无需进行另一个数据表的查询。

n 去关联化处理会带来额外的考虑，比如说，某一个数据表内容的修改，对另一个数据表的影响。这一点需要在程序或其他途径去考虑。

l 分库方案

n 安全性拆分

u 将高安全性数据与低安全性数据分库，这样的好处第一是便于维护，第二是高安全性数据的数据库参数配置可以以安全优先，而低安全性数据的参数配置以性能优先。参见运维优化相关部分。

n 基于业务逻辑拆分

u 根据数据表的内容构成，业务逻辑拆分，便于日常维护和前端调用。

u 基于业务逻辑拆分，可以减少前端应用请求发送到不同数据库服务器的频次，从而减少链接开销。

u 基于业务逻辑拆分，可保留部分数据关联，前端web工程师可在限度范围内执行关联查询。

n 基于负载压力拆分

u 基于负载压力对数据结构拆分，便于直接将负载分担给不同的服务器。

u 基于负载压力拆分，可能拆分后的数据库包含不同业务类型的数据表，日常维护会有一定的烦恼。

n 混合拆分组合

u 基于安全与业务拆分为数据库实例，但是可以使用不同端口放在同一个服务器上。

u 基于负载可以拆分为更多数据库实例分布在不同数据库上

u 例如，

l 基于安全拆分出A数据库实例，

l 基于业务拆分出B,C数据库实例，

l C数据库存在较高负载，基于负载拆分为C1,C2,C3,C4等 实例。

l 数据库服务器完全可以做到 A+B+C1 为一台，C2,C3,C4各单独一台。

 

l 分表方案

n 数据量过大或者访问压力过大的数据表需要切分

n 纵向分表（常见为忙闲分表）

u 单数据表字段过多，可将频繁更新的整数数据与非频繁更新的字符串数据切分

u 范例 user表 ，个人简介，地址，QQ号，联系方式，头像 这些字段为字符串类型，更新请求少； 最后登录时间，在线时常，访问次数，信件数这些字段为整数型字段，更新频繁，可以将后面这些更新频繁的字段独立拆出一张数据表，表内容变少，索引结构变少，读写请求变快。

n 横向切表

u 等分切表，如哈希切表或其他基于对某数字取余的切表。等分切表的优点是负载很方便的分布到不同服务器；缺点是当容量继续增加时无法方便的扩容，需要重新进行数据的切分或转表。而且一些关键主键不易处理。

u 递增切表，比如每1kw用户开一个新表，优点是可以适应数据的自增趋势；缺点是往往新数据负载高，压力分配不平均。

u 日期切表，适用于日志记录式数据，优缺点等同于递增切表。

u 个人倾向于递增切表，具体根据应用场景决定。

n 热点数据分表

u 将数据量较大的数据表中将读写频繁的数据抽取出来，形成热点数据表。通常一个庞大数据表经常被读写的内容往往具有一定的集中性，如果这些集中数据单独处理，就会极大减少整体系统的负载。

u 热点数据表与旧有数据关系

l 可以是一张冗余表，即该表数据丢失不会妨碍使用，因源数据仍存在于旧有结构中。优点是安全性高，维护方便，缺点是写压力不能分担，仍需要同步写回原系统。

l 可以是非冗余表，即热点数据的内容原有结构不再保存，优点是读写效率全部优化；缺点是当热点数据发生变化时，维护量较大。

l 具体方案选择需要根据读写比例决定，在读频率远高于写频率情况下，优先考虑冗余表方案。

u 热点数据表可以用单独的优化的硬件存储，比如昂贵的闪存卡或大内存系统。

u 热点数据表的重要指标

l 热点数据的定义需要根据业务模式自行制定策略，常见策略为，按照最新的操作时间；按照内容丰富度等等。

l 数据规模，比如从1000万条数据，抽取出100万条热点数据。

l 热点命中率，比如查询10次，多少次命中在热点数据内。

l 理论上，数据规模越小，热点命中率越高，说明效果越好。需要根据业务自行评估。

u 热点数据表的动态维护

l 加载热点数据方案选择

n 定时从旧有数据结构中按照新的策略获取

n 在从旧有数据结构读取时动态加载到热点数据

l 剔除热点数据方案选择

n 基于特定策略，定时将热点数据中访问频次较少的数据剔除

n 如热点数据是冗余表，则直接删除即可，如不是冗余表，需要回写给旧有数据结构。

u 通常，热点数据往往是基于缓存或者key-value 方案冗余存储，所以这里提到的热点数据表，其实更多是理解思路，用到的场合可能并不多….

### 反范式设计（冗余结构设计）

l 反范式设计的概念

n 无外键，无连表查询。

n 便于分布式设计，允许适度冗余，为了容量扩展允许适度开销。

n 基于业务自由优化，基于i/o 或查询设计，无须遵循范式结构设计。

l 冗余结构设计所面临的典型场景

n 原有展现程序涉及多个表的查询，希望精简查询程序

n 数据表拆分往往基于主键，而原有数据表往往存在非基于主键的关键查询，无法在分表结构中完成。

n 存在较多数据统计需求（count, sum等），效率低下。

l 冗余设计方案

n 基于展现的冗余设计

u 为了简化展现程序，在一些数据表中往往存在冗余字段

u 举例，信息表  message，存在字段 fromuid,touid,msg,sendtime  四个字段，其中 touid+sendtime是复合索引。存在查询为 select * from message where touid=$uid order by sendtime desc limit 0,30;

u 展示程序需要显示发送者姓名，此时通常会在message表中增加字段fromusername，甚至有的会增加fromusersex，从而无需连表查询直接输出信息的发送者姓名和性别。这就是一种简单的，为了避免连表查询而使用的冗余字段设计。

n 基于查询的冗余设计

u 涉及分表操作后，一些常见的索引查询可能需要跨表，带来不必要的麻烦。确认查询请求远大于写入请求时，应设置便于查询项的冗余表。

u 冗余表要点

l 数据一致性，简单说，同增，同删，同更新。

l 可以做全冗余，或者只做主键关联的冗余，比如通过用户名查询uid，再基于uid查询源表。

u 实战范例1

l 用户分表，将用户库分成若干数据表

l 基于用户名的查询和基于uid的查询都是高并发请求。

l 用户分表基于uid分成数据表，同时基于用户名做对应冗余表。

l 如果允许多方式登陆，可以有如下设计方法

n uid,passwd,用户信息等等，主数据表，基于uid 分表

n ukey,ukeytype,uid 基于ukey分表，便于用户登陆的查询。分解成如下两个SQL。

u select uid from ulist_key_13 where ukey=’$username’ and ukeytype=‘login’;

u select * from ulist_uid_23 where uid=$uid and passwd=’$passwd’;

n ukeytype定义用户的登陆依据，比如用户名，手机号，邮件地址，网站昵称等。 Ukey+ukeytype 必须唯一。

n 此种方式需要登陆密码统一，对于第三方connect接入模式，可以通过引申额外字段完成。

u 实战范例2：用户游戏积分排名

l 表结构 uid,gameid,score 参见前文实时积分排行。表内容巨大，需要拆表。

l 需求1：基于游戏id查询积分排行

l 需求2：基于用户id查询游戏积分记录

l 解决方案：建立完全相同的两套表结构，其一以uid为拆表主键，其二以gameid为拆表主键，用户提交积分时，向两个数据结构同时提交。

u 实战范例3：全冗余查询结构

l 主信息表仅包括 主键及备注memo 字段（text类型），只支持主键查询，可以基于主键拆表。所以需要展现和存储的内容均在memo字段重体现。

l 对每一个查询条件，建立查询冗余表，以查询条件字段为主键，以主信息表主键id 为内容。

l 日常查询只基于查询冗余表，然后通过in的方式从主信息表获得内容。

l 优点是结构扩展非常方便，只需要扩展新的查询信息表即可，核心思路是，只有查询才需要独立的索引结构，展现无需独立字段。

l 缺点是只适合于相对固定的查询架构，对于更加灵活的组合查询束手无策。

n 基于统计的冗余结构

u 为了减少会涉及大规模影响结果集的表数据操作，比如count，sum操作。应将一些统计类数据通过冗余数据结构保存。

u 冗余数据结构可能以字段方式存在，也可能以独立数据表结构存在，但是都应能通过源数据表恢复。

u 实战范例：

l 论坛板块的发帖量，回帖量，每日新增数据等。

l 网站每日新增用户数等。

l 参见Discuz论坛系统数据结构，有较多相关结构。

l 参见前文分段积分结构，是典型用于统计的冗余结构。

l 后台可以通过源数据表更新该数字。

l Redis的Zset类型可以理解为存在一种冗余统计结构。

n 历史数据表

u 历史数据表对应于热点数据表，将需求较少又不能丢弃的数据存入，仅在少数情况下被访问。

### 主从架构

l 基本认识

n 读写分离对负载的减轻远远不如分库分表来的直接。

n 写压力会传递给从表，只读从库一样有写压力，一样会产生读写锁！

n 一主多从结构下，主库是单点隐患，很难解决（如主库当机，从库可以响应读写，但是无法自动担当主库的分发功能）

n 主从延迟也是重大问题。一旦有较大写入问题，如表结构更新，主从会产生巨大延迟。

l 应用场景

n 在线热备

n 异地分布

u 写分布，读统一。

u 仍然困难重重，受限于网络环境问题巨多！

n 自动障碍转移

u 主崩溃，从自动接管

n 个人建议，负载均衡主要使用分库方案，主从主要用于热备和障碍转移。

l 潜在优化点

n 为了减少写压力，有些人建议主不建索引提升i/o性能，从建立索引满足查询要求。个人认为这样维护较为麻烦。而且从本身会继承主的i/o压力，因此优化价值有限。该思路特此分享，不做推荐。

### 故障转移处理

l 要点

n 程序与数据库的连接，基于虚地址而非真实ip，由负载均衡系统监控。

n 保持主从结构的简单化，否则很难做到故障点摘除。

l 思考方式

n 遍历对服务器集群的任何一台服务器，前端web，中间件，监控，缓存，db等等，假设该服务器出现故障，系统是否会出现异常？用户访问是否会出现异常。

n 目标：任意一台服务器崩溃，负载和数据操作均会很短时间内自动转移到其他服务器，不会影响业务的正常进行。不会造成恶性的数据丢失。（哪些是可以丢失的，哪些是不能丢失的）

## 缓存方案

### 缓存结合数据库的读取

l Memcached是最常用的缓存系统

l Mysql 最新版本已经开始支持memcache插件，但据牛人分析，尚不成熟，暂不推荐。

l 数据读取

n 并不是所有数据都适合被缓存，也并不是进入了缓存就意味着效率提升。

n 命中率是第一要评估的数据。

n 如何评估进入缓存的数据规模，以及命中率优化，是非常需要细心分析的。

l 实景分析： 前端请求先连接缓存，缓存未命中连接数据库，进行查询，未命中状态比单纯连接数据库查询多了一次连接和查询的操作；如果缓存命中率很低，则这个额外的操作非但不能提高查询效率，反而为系统带来了额外的负载和复杂性，得不偿失。

n 相关评估类似于热点数据表的介绍。

n 善于利用内存，请注意数据存储的格式及压缩算法。

l Key-value 方案繁多，本培训文档暂不展开。

### 缓存结合数据库的写入

l 利用缓存不但可以减少数据读取请求，还可以减少数据库写入i/o压力

l 缓存实时更新，数据库异步更新

n 缓存实时更新数据，并将更新记录写入队列

n 可以使用类似mq的队列产品，自行建立队列请注意使用increment来维持队列序号。

n 不建议使用 get 后处理数据再set的方式维护队列

l 测试范例：

l 范例1 

$var=Memcache_get($memcon,”var”);

 $var++;

memcache_set($memcon,”var”,$var);

这样一个脚本，使用apache ab去跑，100个并发，跑10000次，然后输出缓存存取的数据，很遗憾，并不是1000，而是5000多，6000多这样的数字，中间的数字全在 get & set的过程中丢掉了。

原因，读写间隔中其他并发写入，导致数据丢失。

l 范例2

用memcache_increment来做这个操作，同样跑测试

会得到完整的10000，一条数据不会丢。

l 结论： 用increment存储队列编号，用标记+编号作为key存储队列内容。

n 后台基于缓存队列读取更新数据并更新数据库

l 基于队列读取后可以合并更新

l 更新合并率是重要指标

l 实战范例：

某论坛热门贴，前端不断有views=views+1数据更新请求。

缓存实时更新该状态

后台任务对数据库做异步更新时，假设执行周期是5分钟，那么五分钟可能会接收到这样的请求多达数十次乃至数百次，合并更新后只执行一次update即可。

类似操作还包括游戏打怪，生命和经验的变化；个人主页访问次数的变化等。

n 异步更新风险

l 前后端同时写，可能导致覆盖风险。

l 使用后端异步更新，则前端应用程序就不要写数据库，否则可能造成写入冲突。一种兼容的解决方案是，前端和后端不要写相同的字段。

l 实战范例：

用户在线上时，后台异步更新用户状态。

管理员后台屏蔽用户是直接更新数据库。

结果管理员屏蔽某用户操作完成后，因该用户在线有操作，后台异步更新程序再次基于缓存更新用户状态，用户状态被复活，屏蔽失效。

l 缓存数据丢失或服务崩溃可能导致数据丢失风险。

l 如缓存中间出现故障，则缓存队列数据不会回写到数据库，而用户会认为已经完成，此时会带来比较明显的用户体验问题。

l 一个不彻底的解决方案是，确保高安全性，高重要性数据实时数据更新，而低安全性数据通过缓存异步回写方式完成。此外，使用相对数值操作而不是绝对数值操作更安全。

n 范例：支付信息，道具的购买与获得，一旦丢失会对用户造成极大的伤害。而经验值，访问数字，如果只丢失了很少时间的内容，用户还是可以容忍的。

n 范例：如果使用 Views=Views+…的操作，一旦出现数据格式错误，从binlog中反推是可以进行数据还原，但是如果使用Views=特定值的操作，一旦缓存中数据有错误，则直接被赋予了一个错误数据，无法回溯！

l 异步更新如出现队列阻塞可能导致数据丢失风险。

l 异步更新通常是使用缓存队列后，在后台由cron或其他守护进程写入数据库。

l 如果队列生成的速度>后台更新写入数据库的速度，就会产生阻塞，导致数据越累计越多，数据库响应迟缓，而缓存队列无法迅速执行，导致溢出或者过期失效。

n 建议使用内存队列产品而不使用memcache 来进行缓存异步更新。

# 总结

- 第一步，完成数据库查询的优化，需要理解索引结构，才能学会判断影响结果集。而影响结果集对查询效率线性相关，掌握这一点，编写数据查询语句就很容易判断系统开销，了解业务压力趋势。
- 第二步，在SQL语句已经足够优化的基础上，学会对数据库整体状况的分析，能够对异常和负载的波动有正确的认识和解读；能够对系统资源的分配和瓶颈有正确的认识。
- 学会通过监控和数据来进行系统的评估和优化方案设计，杜绝拍脑袋，学会抓大放小，把握要点的处理方法。
- 第三步，在彻底掌握数据库语句优化和运维优化的基础上，学会分布式架构设计，掌握复杂，大容量数据库系统的搭建方法。
- 最后，分享一句话，学会把问题简单化，正如Caoz 常说的，你如果认为这个问题很复杂，你一定想错了。
- 感谢您的阅读，如对您有帮助，请在百度文库给本文五分好评，并推荐给您的朋友，多谢。





### MySQL监控

一、监控采集依据：主要基于show global status对数据进行采集

二、对用户进行授权，然后使用show global status进行采集分析

mysql -uroot -p”xxxx” -e "show global status" ###查看所有的值

监控项注释：

Aborted_clients ##客户端不能正常连接，失败的连接数量。

Aborted_connects ##客户端中断数量，可能有恶意连接。

\###吞吐量

Bytes_received ##从所有客户端接收到的字节数。

Bytes_sent ##发送给所有客户端的字节数。

\###com admin 语句执行数量

Com_commit ##统计提交语句次数

com_delete ##统计删除语句

com_delete_multi ##最小

com_insert ##统计插入语句

com_rollback ##事务回滚

Connections ##不管是否成功连接到mysql的个数

\###临时表数量

Created_tmp_disk_tables ##服务器创建的临时表数量

Created_tmp_files ##已经创建的临时文件数量

Created_tmp_tables ##服务器执行语句时自动创建的内存中的临时表的数量。如果Created_tmp_disk_tables较大，你可能要增加tmp_table_size值使临时表基于内存而不基于硬盘。

\##后台预读线程读取到Innodb缓冲池的页的数量

Innodb_buffer_pool_reads ##不能满足InnoDB必须单页读取的缓冲池中的逻辑读数量。

Innodb_buffer_pool_read_ahead ##预读的次数

Innodb_buffer_pool_read_requests ##从缓冲池中读取的页的次数

*缓冲池的命中率=

innodb_buffer_pool_read_requests/(innodb_buffer_pool_read_requests+innodb_buffer_pool_read_ahead+innodb_buffer_pool_reads)

innodb_data_read 总共读入的字节数；

innodb_data_reads 发起读取请求的次数，每次读取可能需要读取多个页。

*平均每次读取的字节数=innodb_data_read/innodb_data_reads

Innodb_rows_deleted ##执行deleted操作的次数

Innodb_rows_inserted ##执行insert操作的次数

Innodb_rows_read ##执行select操作的次数

Innodb_rows_updated ##执行update操作的次数

\###针对MyISAM引擎：

key_buffer_size ##缓冲池大小

Key_blocks_unused ##未使用的缓存簇(blocks)数

Key_blocks_used ##表示曾经用到的最大的blocks数

\* 这台服务器，所有的缓存都用到了，要么增加key_buffer_size，要么就是过渡索引了，把缓存占满了，理想设置：

Key_blocks_used / (Key_blocks_unused + Key_blocks_used) * 100% ≈ 80%

Key_reads ##在内存中没有找到直接从硬盘读取索引

Key_read_requests ##一共索引请求

\* 计算索引未名字概率：

key_cache_miss_rate = Key_reads / Key_read_requests * 100%

\###Qcache查询缓冲区：

Qcache_free_blocks ##Query Cache 中目前还有多少剩余的blocks

Qcache_free_memory ##Query Cache 剩余的内存大小

Qcache_hits ##多少次命中

Qcache_inserts ##多少次未命中的插入： Qcache_hits / ( Qcache_hits + Qcache_inserts )

Qcache_lowmem_prunes ##多少条Query 因为内存不足而被清除出Query Cache

Qcache_not_cached ##因为query_cache_type 的设置或者不能被cache 的Query 的数量；

Qcache_queries_in_cache ##当前Query Cache中的cache 的Query数量

Slow_queries ##慢查询

Sort_range ##通过range scan 完成的排序总次数

Sort_rows ##排序总行数

Sort_scan ##通过扫描完成的排序总次数

Table_locks_immediate ##可以立即获取锁的查询次数。

Table_locks_waited ##不能立即获取锁的查询次数。

Uptime ##mysql 运行时长

**三、****zabbix agnet****自定义key：**

UserParameter=mysql[*],mysql -uroot -pxxx -e "show global status"|grep "$1" | cut -f2

Mysql[Uptime]

Grep uptime | cut -f2

Myslq[Table_locks_waited]

注释：通过key传回的值，$1筛选出我们要的值。



## 缓存池

参考：

1. https://www.cnblogs.com/FengGeBlog/p/10144768.html
2. https://www.cnblogs.com/chengyunblogs/p/11929040.html
3. https://blog.csdn.net/n88lpo/article/details/86486263
4. https://blog.csdn.net/weixin_33882452/article/details/94318658

![x](E:/WorkingDir/Office/Resources/tbms0029.png)

应用系统分层架构，为了加速数据访问，会把最常访问的数据，放在缓存(cache)里，避免每次都去访问数据库。操作系统，会有缓冲池(buffer pool)机制，避免每次访问磁盘，以加速数据的访问。MySQL作为一个存储系统，同样具有缓冲池(buffer pool)机制，以避免每次查询数据都进行磁盘IO，主要作用：

> 1、存在的意义是加速查询 
>
> 2、缓冲池(buffer pool) 是一种常见的**降低磁盘访问** 的机制；
>
> 3、缓冲池通常以页(page **16K**)为单位缓存数据；
>
> 4、缓冲池的常见管理算法是**LRU**，memcache，OS，InnoDB都使用了这种算法；
>
> 5、InnoDB对普通LRU进行了优化：将缓冲池分为`老生代`和`新生代`，入缓冲池的页，优先进入老生代，该页被访问，才进入新生代，以解决预读失效的问题页被访问。且在老生代**停留时间超过配置阈值**的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题

**预读失效**：

> 由于预读(Read-Ahead)，提前把页放入了缓冲池，但最终MySQL并没有从页中读取数据，称为预读失效

![x](E:/WorkingDir/Office/Resources/tbms0030.png)

**缓冲池污染**：

> 当某一个SQL语句，要批量扫描大量数据时，可能导致把缓冲池的所有页都替换出去，导致大量热数据被换出，MySQL性能急剧下降，这种情况叫缓冲池污染。解决办法：加入`老生代停留时间窗口`策略后，短时间内被大量加载的页，并不会立刻插入新生代头部，而是优先淘汰那些，短期内仅仅访问了一次的页。



### 查询效率

先列出sql语句的执行顺序：

```markdown
FROM
<left_table>

ON
<join_condition>

<join_type>
 JOIN
<right_table>

WHERE
<where_condition>

GROUP BY
<group_by_list>

HAVING
<having_condition>

SELECT

DISTINCT
<select_list>

ORDER BY
<order_by_condition>

LIMIT
<limit_number>
```

#### 1、LIMIT 语句

分页查询是最常用的场景之一，但也通常也是最容易出问题的地方。比如对于下面简单的语句，一般 DBA 想到的办法是在 type, name, create_time 字段上加组合索引。这样条件排序都能有效的利用到索引，性能迅速提升。

```
SELECT *
FROM   operation
WHERE  type = 'SQLStats'
       AND name = 'SlowLog'
ORDER  BY create_time
LIMIT  1000, 10;
```

好吧，可能90%以上的 DBA 解决该问题就到此为止。但当 LIMIT 子句变成 “LIMIT 1000000,10” 时，程序员仍然会抱怨：我只取10条记录为什么还是慢？

要知道数据库也并不知道第1000000条记录从什么地方开始，即使有索引也需要从头计算一次。出现这种性能问题，多数情形下是程序员偷懒了。

在前端数据浏览翻页，或者大数据分批导出等场景下，是可以将上一页的最大值当成参数作为查询条件的。SQL 重新设计如下：

```
SELECT   *
FROM     operation
WHERE    type = 'SQLStats'
AND      name = 'SlowLog'
AND      create_time > '2017-03-16 14:00:00'
ORDER BY create_time limit 10;
```

在新设计下查询时间基本固定，不会随着数据量的增长而发生变化。

#### 2、隐式转换

SQL语句中查询变量和字段定义类型不匹配是另一个常见的错误。比如下面的语句：

```
mysql> explain extended SELECT *
     > FROM   my_balance b
     > WHERE  b.bpn = 14000000123
     >       AND b.isverified IS NULL ;
mysql> show warnings;
| Warning | 1739 | Cannot use ref access on index 'bpn' due to type or collation conversion on field 'bpn'
```

其中字段 bpn 的定义为 varchar(20)，MySQL 的策略是将字符串转换为数字之后再比较。函数作用于表字段，索引失效。

上述情况可能是应用程序框架自动填入的参数，而不是程序员的原意。现在应用框架很多很繁杂，使用方便的同时也小心它可能给自己挖坑。

#### 3、关联更新、删除

虽然 MySQL5.6 引入了物化特性，但需要特别注意它目前仅仅针对查询语句的优化。对于更新或删除需要手工重写成 JOIN。

比如下面 UPDATE 语句，MySQL 实际执行的是循环/嵌套子查询（DEPENDENT SUBQUERY)，其执行时间可想而知。

```
UPDATE operation o
SET    status = 'applying'
WHERE  o.id IN (SELECT id
                FROM   (SELECT o.id,
                               o.status
                        FROM   operation o
                        WHERE  o.group = 123
                               AND o.status NOT IN ( 'done' )
                        ORDER  BY o.parent,
                                  o.id
                        LIMIT  1) t);
```

执行计划：

```
+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+
| id | select_type        | table | type  | possible_keys | key     | key_len | ref   | rows | Extra                                               |
+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+
| 1  | PRIMARY            | o     | index |               | PRIMARY | 8       |       | 24   | Using where; Using temporary                        |
| 2  | DEPENDENT SUBQUERY |       |       |               |         |         |       |      | Impossible WHERE noticed after reading const tables |
| 3  | DERIVED            | o     | ref   | idx_2,idx_5   | idx_5   | 8       | const | 1    | Using where; Using filesort                         |
+----+--------------------+-------+-------+---------------+---------+---------+-------+------+-----------------------------------------------------+
```

重写为 JOIN 之后，子查询的选择模式从 DEPENDENT SUBQUERY 变成 DERIVED，执行速度大大加快，从7秒降低到2毫秒。

```
UPDATE operation o
       JOIN  (SELECT o.id,
                            o.status
                     FROM   operation o
                     WHERE  o.group = 123
                            AND o.status NOT IN ( 'done' )
                     ORDER  BY o.parent,
                               o.id
                     LIMIT  1) t
         ON o.id = t.id
SET    status = 'applying'
```

执行计划简化为：

```
+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+
| id | select_type | table | type | possible_keys | key   | key_len | ref   | rows | Extra                                               |
+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+
| 1  | PRIMARY     |       |      |               |       |         |       |      | Impossible WHERE noticed after reading const tables |
| 2  | DERIVED     | o     | ref  | idx_2,idx_5   | idx_5 | 8       | const | 1    | Using where; Using filesort                         |
+----+-------------+-------+------+---------------+-------+---------+-------+------+-----------------------------------------------------+
```

#### 4、混合排序

MySQL 不能利用索引进行混合排序。但在某些场景，还是有机会使用特殊方法提升性能的。

```
SELECT *
FROM   my_order o
       INNER JOIN my_appraise a ON a.orderid = o.id
ORDER  BY a.is_reply ASC,
          a.appraise_time DESC
LIMIT  0, 20
```

执行计划显示为全表扫描：

```
+----+-------------+-------+--------+-------------+---------+---------+---------------+---------+-+
| id | select_type | table | type   | possible_keys     | key     | key_len | ref      | rows    | Extra
+----+-------------+-------+--------+-------------+---------+---------+---------------+---------+-+
|  1 | SIMPLE      | a     | ALL    | idx_orderid | NULL    | NULL    | NULL    | 1967647 | Using filesort |
|  1 | SIMPLE      | o     | eq_ref | PRIMARY     | PRIMARY | 122     | a.orderid |       1 | NULL           |
+----+-------------+-------+--------+---------+---------+---------+-----------------+---------+-+
```

由于 is_reply 只有0和1两种状态，我们按照下面的方法重写后，执行时间从1.58秒降低到2毫秒。

```
SELECT *
FROM   ((SELECT *
         FROM   my_order o
                INNER JOIN my_appraise a
                        ON a.orderid = o.id
                           AND is_reply = 0
         ORDER  BY appraise_time DESC
         LIMIT  0, 20)
        UNION ALL
        (SELECT *
         FROM   my_order o
                INNER JOIN my_appraise a
                        ON a.orderid = o.id
                           AND is_reply = 1
         ORDER  BY appraise_time DESC
         LIMIT  0, 20)) t
ORDER  BY  is_reply ASC,
          appraisetime DESC
LIMIT  20;
```

#### 5、EXISTS语句

MySQL 对待 EXISTS 子句时，仍然采用嵌套子查询的执行方式。如下面的 SQL 语句：

```
SELECT *
FROM   my_neighbor n
       LEFT JOIN my_neighbor_apply sra
              ON n.id = sra.neighbor_id
                 AND sra.user_id = 'xxx'
WHERE  n.topic_status < 4
       AND EXISTS(SELECT 1
                  FROM   message_info m
                  WHERE  n.id = m.neighbor_id
                         AND m.inuser = 'xxx')
       AND n.topic_type <> 5
```

执行计划为：

```
+----+--------------------+-------+------+-----+------------------------------------------+---------+-------+---------+ -----+
| id | select_type        | table | type | possible_keys     | key   | key_len | ref   | rows    | Extra   |
+----+--------------------+-------+------+ -----+------------------------------------------+---------+-------+---------+ -----+
|  1 | PRIMARY            | n     | ALL  |  | NULL     | NULL    | NULL  | 1086041 | Using where                   |
|  1 | PRIMARY            | sra   | ref  |  | idx_user_id | 123     | const |       1 | Using where          |
|  2 | DEPENDENT SUBQUERY | m     | ref  |  | idx_message_info   | 122     | const |       1 | Using index condition; Using where |
+----+--------------------+-------+------+ -----+------------------------------------------+---------+-------+---------+ -----+
```

去掉 exists 更改为 join，能够避免嵌套子查询，将执行时间从1.93秒降低为1毫秒。

```
SELECT *
FROM   my_neighbor n
       INNER JOIN message_info m
               ON n.id = m.neighbor_id
                  AND m.inuser = 'xxx'
       LEFT JOIN my_neighbor_apply sra
              ON n.id = sra.neighbor_id
                 AND sra.user_id = 'xxx'
WHERE  n.topic_status < 4
       AND n.topic_type <> 5
```

新的执行计划：

```
+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+
| id | select_type | table | type   | possible_keys     | key       | key_len | ref   | rows | Extra                 |
+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+
|  1 | SIMPLE      | m     | ref    | | idx_message_info   | 122     | const    |    1 | Using index condition |
|  1 | SIMPLE      | n     | eq_ref | | PRIMARY   | 122     | ighbor_id |    1 | Using where      |
|  1 | SIMPLE      | sra   | ref    | | idx_user_id | 123     | const     |    1 | Using where           |
+----+-------------+-------+--------+ -----+------------------------------------------+---------+ -----+------+ -----+
```

#### 6、条件下推

外部查询条件不能够下推到复杂的视图或子查询的情况有：

1、聚合子查询；2、含有 LIMIT 的子查询；3、UNION 或 UNION ALL 子查询；4、输出字段中的子查询；

如下面的语句，从执行计划可以看出其条件作用于聚合子查询之后：

```
SELECT *
FROM   (SELECT target,
               Count(*)
        FROM   operation
        GROUP  BY target) t
WHERE  target = 'rm-xxxx'
+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+
| id | select_type | table      | type  | possible_keys | key         | key_len | ref   | rows | Extra       |
+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+
|  1 | PRIMARY     | <derived2> | ref   | <auto_key0>   | <auto_key0> | 514     | const |    2 | Using where |
|  2 | DERIVED     | operation  | index | idx_4         | idx_4       | 519     | NULL  |   20 | Using index |
+----+-------------+------------+-------+---------------+-------------+---------+-------+------+-------------+
```

确定从语义上查询条件可以直接下推后，重写如下：

```
SELECT target,
       Count(*)
FROM   operation
WHERE  target = 'rm-xxxx'
GROUP  BY target
```

执行计划变为：

```
+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+
| 1 | SIMPLE | operation | ref | idx_4 | idx_4 | 514 | const | 1 | Using where; Using index |
+----+-------------+-----------+------+---------------+-------+---------+-------+------+--------------------+
```

关于 MySQL 外部条件不能下推的详细解释说明请参考以前文章：MySQL · 性能优化 · 条件下推到物化表http://mysql.taobao.org/monthly/2016/07/08

#### 7、提前缩小范围

先上初始 SQL 语句：

```
SELECT *
FROM   my_order o
       LEFT JOIN my_userinfo u
              ON o.uid = u.uid
       LEFT JOIN my_productinfo p
              ON o.pid = p.pid
WHERE  ( o.display = 0 )
       AND ( o.ostaus = 1 )
ORDER  BY o.selltime DESC
LIMIT  0, 15
```

该SQL语句原意是：先做一系列的左连接，然后排序取前15条记录。从执行计划也可以看出，最后一步估算排序记录数为90万，时间消耗为12秒。

```
+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+
| id | select_type | table | type   | possible_keys | key     | key_len | ref             | rows   | Extra                                              |
+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+
|  1 | SIMPLE      | o     | ALL    | NULL          | NULL    | NULL    | NULL            | 909119 | Using where; Using temporary; Using filesort       |
|  1 | SIMPLE      | u     | eq_ref | PRIMARY       | PRIMARY | 4       | o.uid |      1 | NULL                                               |
|  1 | SIMPLE      | p     | ALL    | PRIMARY       | NULL    | NULL    | NULL            |      6 | Using where; Using join buffer (Block Nested Loop) |
+----+-------------+-------+--------+---------------+---------+---------+-----------------+--------+----------------------------------------------------+
```

由于最后 WHERE 条件以及排序均针对最左主表，因此可以先对 my_order 排序提前缩小数据量再做左连接。SQL 重写后如下，执行时间缩小为1毫秒左右。

```
SELECT *
FROM (
SELECT *
FROM   my_order o
WHERE  ( o.display = 0 )
       AND ( o.ostaus = 1 )
ORDER  BY o.selltime DESC
LIMIT  0, 15
) o
     LEFT JOIN my_userinfo u
              ON o.uid = u.uid
     LEFT JOIN my_productinfo p
              ON o.pid = p.pid
ORDER BY  o.selltime DESC
limit 0, 15
```

再检查执行计划：子查询物化后（select_type=DERIVED)参与 JOIN。虽然估算行扫描仍然为90万，但是利用了索引以及 LIMIT 子句后，实际执行时间变得很小。

```
+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+
| id | select_type | table      | type   | possible_keys | key     | key_len | ref   | rows   | Extra                                              |
+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+
|  1 | PRIMARY     | <derived2> | ALL    | NULL          | NULL    | NULL    | NULL  |     15 | Using temporary; Using filesort                    |
|  1 | PRIMARY     | u          | eq_ref | PRIMARY       | PRIMARY | 4       | o.uid |      1 | NULL                                               |
|  1 | PRIMARY     | p          | ALL    | PRIMARY       | NULL    | NULL    | NULL  |      6 | Using where; Using join buffer (Block Nested Loop) |
|  2 | DERIVED     | o          | index  | NULL          | idx_1   | 5       | NULL  | 909112 | Using where                                        |
+----+-------------+------------+--------+---------------+---------+---------+-------+--------+----------------------------------------------------+
```

#### 8、中间结果集下推

再来看下面这个已经初步优化过的例子(左连接中的主表优先作用查询条件)：

```
SELECT    a.*,
          c.allocated
FROM      (
              SELECT   resourceid
              FROM     my_distribute d
                   WHERE    isdelete = 0
                   AND      cusmanagercode = '1234567'
                   ORDER BY salecode limit 20) a
LEFT JOIN
          (
              SELECT   resourcesid， sum(ifnull(allocation, 0) * 12345) allocated
              FROM     my_resources
                   GROUP BY resourcesid) c
ON        a.resourceid = c.resourcesid
```

那么该语句还存在其它问题吗？不难看出子查询 c 是全表聚合查询，在表数量特别大的情况下会导致整个语句的性能下降。

其实对于子查询 c，左连接最后结果集只关心能和主表 resourceid 能匹配的数据。因此我们可以重写语句如下，执行时间从原来的2秒下降到2毫秒。

```
SELECT    a.*,
          c.allocated
FROM      (
                   SELECT   resourceid
                   FROM     my_distribute d
                   WHERE    isdelete = 0
                   AND      cusmanagercode = '1234567'
                   ORDER BY salecode limit 20) a
LEFT JOIN
          (
                   SELECT   resourcesid， sum(ifnull(allocation, 0) * 12345) allocated
                   FROM     my_resources r,
                            (
                                     SELECT   resourceid
                                     FROM     my_distribute d
                                     WHERE    isdelete = 0
                                     AND      cusmanagercode = '1234567'
                                     ORDER BY salecode limit 20) a
                   WHERE    r.resourcesid = a.resourcesid
                   GROUP BY resourcesid) c
ON        a.resourceid = c.resourcesid
```

但是子查询 a 在我们的SQL语句中出现了多次。这种写法不仅存在额外的开销，还使得整个语句显的繁杂。使用 WITH 语句再次重写：

```
WITH a AS
(
         SELECT   resourceid
         FROM     my_distribute d
         WHERE    isdelete = 0
         AND      cusmanagercode = '1234567'
         ORDER BY salecode limit 20)
SELECT    a.*,
          c.allocated
FROM      a
LEFT JOIN
          (
                   SELECT   resourcesid， sum(ifnull(allocation, 0) * 12345) allocated
                   FROM     my_resources r,
                            a
                   WHERE    r.resourcesid = a.resourcesid
                   GROUP BY resourcesid) c
ON        a.resourceid = c.resourcesid
```

#### 总结

数据库编译器产生执行计划，决定着SQL的实际执行方式。但是编译器只是尽力服务，所有数据库的编译器都不是尽善尽美的。

上述提到的多数场景，在其它数据库中也存在性能问题。了解数据库编译器的特性，才能避规其短处，写出高性能的SQL语句。

程序员在设计数据模型以及编写SQL语句时，要把算法的思想或意识带进来。

编写复杂SQL语句要养成使用 WITH 语句的习惯。简洁且思路清晰的SQL语句也能减小数据库的负担 。



### where 1=1 是什么鬼？

动态SQL中连接AND条件

where 1=1 是为了避免where 关键字后面的第一个词直接就是 “and”而导致语法错误。

where后面总要有语句，加上了1=1后就可以保证语法不会出错!

select * from table where 1=1

因为table中根本就没有名称为1的字段，所以该SQL等效于select * from table，

这个SQL语句很明显是全表扫描，需要大量的IO操作，数据量越大越慢，

建议查询时增加必输项，即where 1=1后面追加一些常用的必选条件，并且将这些必选条件建立适当的索引，效率会大大提高

**「拷贝表」**

create table table_name  as  select  *  from  Source_table  where  1=1;

**「复制表结构」**

create table table_name  as  select  *  from  Source_table  where  1 <> 1;



### 参考

1. SQL基础：https://juejin.im/post/6844903790571700231
2. SQL面试：https://sowhat.blog.csdn.net/article/details/71158104
3. MySQL拷问：https://www.jianshu.com/nb/22933318
4. [顺丰面试：MySQL十连击](https://mp.weixin.qq.com/s/ZoCZLG3o3AZBDSO1y3nbmw)
5. [Innodb重要参数优化](https://www.cnblogs.com/chengyunblogs/p/11929040.html)
6. https://www.cnblogs.com/assistants/p/11958998.html
7. https://www.cnblogs.com/wy123/p/12724252.html
8. https://www.cnblogs.com/hanwuxing/p/10367147.html
9. https://www.cnblogs.com/zejin2008/p/5262751.html
10. https://www.cnblogs.com/out8/p/4222166.html
11. https://www.cnblogs.com/zhuyeshen/p/12084845.html
12. https://www.cnblogs.com/mintsd/p/13062308.html
13. https://blog.csdn.net/zdhsoft/article/details/89373364
14. https://www.ddpool.cn/article/56666.html
15. https://www.cnblogs.com/csj2018/p/9955405.html
16. https://www.jb51.net/article/159737.htm
17. https://www.cnblogs.com/wintersoft/p/10787474.html
18. https://blog.csdn.net/qq_27607965/article/details/79925288
19. https://www.cnblogs.com/cyun/p/4308960.html
20. https://www.cnblogs.com/liaojie970/p/6824773.html
21. [MySQL 8.0能彻底解决困扰运维的复制延迟问题！](http://blog.itpub.net/31547898/viewspace-2200045/)
22. https://www.cnblogs.com/python-daxiong/p/12310564.html

- https://mp.weixin.qq.com/s?__biz=MzA5ODM5MDU3MA==&mid=2650865582&idx=1&sn=381e7af2e0d9d1b090e79ef26dce2aa0&chksm=8b6618ebbc1191fdfc68aaccfc0b28c797523bcf6f58e9391b53ca8df5dd5c304b3e397f6f78&scene=21#wechat_redirect

- https://www.jianshu.com/p/db6fba9019b4